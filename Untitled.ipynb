{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b665d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from example import *\n",
    "import lstm_vae.vae_with_uncertainty\n",
    "from lstm_vae.vae_with_uncertainty import create_lstm_uvae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3eb4beb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.framework.ops import disable_eager_execution\n",
    "disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9b88c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50056686",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32192, 9)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw = pd.read_table(\"short_doc_ocr_features0.tsv\")\n",
    "raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6b3b99c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31512, 9)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw2 = pd.read_table(\"short_doc_ocr_features.tsv\")\n",
    "raw2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4926092",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = pd.concat([raw,raw2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7bebcffc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63704, 9)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5fba2608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['file_id', 'page', 'len', 'left', 'offset', 'height', 'width',\n",
      "       'confidence', 'near_bottom'],\n",
      "      dtype='object')\n",
      "file_id                               page\n",
      "2a3d4901-01f0-47d3-aa54-e0267e3854cf  3       309\n",
      "39ec3eed-a0a0-406c-a5a8-6d199edd68c8  10      295\n",
      "296a5d9d-02ad-4fb6-b5a0-e60b51bda426  2       294\n",
      "25d58b75-c3d0-4ac8-9104-1fb2b56d0d1a  4       281\n",
      "07109dd9-5b1f-40eb-92c4-8141b288df5b  2       280\n",
      "                                             ... \n",
      "384d0cff-3c86-431c-86b1-ed14104bfff8  15        2\n",
      "1d94165b-dca2-4508-b313-049e25ac656c  8         1\n",
      "                                      6         1\n",
      "090bd27c-68a3-4c28-9f9b-1208cedc3a1e  1         1\n",
      "2b5682c8-e7b5-47bb-a17c-5bbdd75acf39  6         1\n",
      "Length: 1164, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "104"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(raw.columns)\n",
    "block_counts = raw.groupby([\"file_id\", \"page\"]).size()\n",
    "block_counts = block_counts.sort_values(ascending=False)\n",
    "print(block_counts)\n",
    "block_counts[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91b5e011",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1190"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages = list()\n",
    "page = list()\n",
    "cur_id = \"\"\n",
    "cur_pnum = -1\n",
    "for row in raw.itertuples():\n",
    "    if row.file_id != cur_id or row.page != cur_pnum:\n",
    "        #print(f\"{row.file_id} {row.page}\")\n",
    "        if page:\n",
    "            pages.append(page)\n",
    "            page = list()\n",
    "        cur_id = row.file_id\n",
    "        cur_pnum = row.page\n",
    "    page.append([np.log(row.len) / 4,row.left,row.offset,row.height,row.width,row.confidence / 100,row.near_bottom])\n",
    "    \n",
    "len(pages)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5bfdc6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(lstm_vae.vae_with_uncertainty)\n",
    "from lstm_vae.vae_with_uncertainty import create_lstm_uvae, pad_page_to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9d63a11e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1190, 30, 7)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded = [pad_page_to(page,30) for page in pages]\n",
    "\n",
    "x = np.array(padded)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9a620337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0134379165247082 0.0134379165247082\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1190, 30, 7)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_backwards = np.flip(x, axis=1)\n",
    "print(x_backwards[3,-1,3], x[3,0,3])\n",
    "x_backwards.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3503bc80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "WARNING:tensorflow:Output {0} missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder_mean.\n",
      "WARNING:tensorflow:Output {0} missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder_logit_sigma.\n",
      "Train on 1190 samples\n",
      "Epoch 1/300\n",
      "1190/1190 [==============================] - 3s 3ms/sample - loss: 1.3053 - combined_decoder_loss: 1.2984\n",
      "Epoch 2/300\n",
      "1190/1190 [==============================] - 1s 779us/sample - loss: 0.8217 - combined_decoder_loss: 0.8191\n",
      "Epoch 3/300\n",
      "1190/1190 [==============================] - 1s 786us/sample - loss: 0.6503 - combined_decoder_loss: 0.6477\n",
      "Epoch 4/300\n",
      "1190/1190 [==============================] - 1s 779us/sample - loss: 0.5263 - combined_decoder_loss: 0.5263\n",
      "Epoch 5/300\n",
      "1190/1190 [==============================] - 1s 788us/sample - loss: 0.4629 - combined_decoder_loss: 0.4677\n",
      "Epoch 6/300\n",
      "1190/1190 [==============================] - 1s 779us/sample - loss: 0.4407 - combined_decoder_loss: 0.4398\n",
      "Epoch 7/300\n",
      "1190/1190 [==============================] - 1s 764us/sample - loss: 0.4217 - combined_decoder_loss: 0.4205\n",
      "Epoch 8/300\n",
      "1190/1190 [==============================] - 1s 771us/sample - loss: 0.3810 - combined_decoder_loss: 0.3839\n",
      "Epoch 9/300\n",
      "1190/1190 [==============================] - 1s 796us/sample - loss: 0.3827 - combined_decoder_loss: 0.3831\n",
      "Epoch 10/300\n",
      "1190/1190 [==============================] - 1s 779us/sample - loss: 0.3702 - combined_decoder_loss: 0.3716\n",
      "Epoch 11/300\n",
      "1190/1190 [==============================] - 1s 786us/sample - loss: 0.3713 - combined_decoder_loss: 0.3718\n",
      "Epoch 12/300\n",
      "1190/1190 [==============================] - 1s 771us/sample - loss: 0.3525 - combined_decoder_loss: 0.3524\n",
      "Epoch 13/300\n",
      "1190/1190 [==============================] - 1s 762us/sample - loss: 0.3391 - combined_decoder_loss: 0.3389\n",
      "Epoch 14/300\n",
      "1190/1190 [==============================] - 1s 779us/sample - loss: 0.3261 - combined_decoder_loss: 0.3267\n",
      "Epoch 15/300\n",
      "1190/1190 [==============================] - 1s 786us/sample - loss: 0.3480 - combined_decoder_loss: 0.3482\n",
      "Epoch 16/300\n",
      "1190/1190 [==============================] - 1s 770us/sample - loss: 0.3387 - combined_decoder_loss: 0.3372\n",
      "Epoch 17/300\n",
      "1190/1190 [==============================] - 1s 771us/sample - loss: 0.3294 - combined_decoder_loss: 0.3281\n",
      "Epoch 18/300\n",
      "1190/1190 [==============================] - 1s 779us/sample - loss: 0.3228 - combined_decoder_loss: 0.3216\n",
      "Epoch 19/300\n",
      "1190/1190 [==============================] - 1s 771us/sample - loss: 0.3303 - combined_decoder_loss: 0.3306\n",
      "Epoch 20/300\n",
      "1190/1190 [==============================] - 1s 764us/sample - loss: 0.3219 - combined_decoder_loss: 0.3212\n",
      "Epoch 21/300\n",
      "1190/1190 [==============================] - 1s 779us/sample - loss: 0.3089 - combined_decoder_loss: 0.3083\n",
      "Epoch 22/300\n",
      "1190/1190 [==============================] - 1s 771us/sample - loss: 0.3390 - combined_decoder_loss: 0.3393\n",
      "Epoch 23/300\n",
      "1190/1190 [==============================] - 1s 779us/sample - loss: 0.3323 - combined_decoder_loss: 0.3313\n",
      "Epoch 24/300\n",
      "1190/1190 [==============================] - 1s 779us/sample - loss: 0.3318 - combined_decoder_loss: 0.3331\n",
      "Epoch 25/300\n",
      "1190/1190 [==============================] - 1s 781us/sample - loss: 0.3090 - combined_decoder_loss: 0.3087\n",
      "Epoch 26/300\n",
      "1190/1190 [==============================] - 1s 788us/sample - loss: 0.3092 - combined_decoder_loss: 0.3104\n",
      "Epoch 27/300\n",
      "1190/1190 [==============================] - 1s 777us/sample - loss: 0.3278 - combined_decoder_loss: 0.3268\n",
      "Epoch 28/300\n",
      "1190/1190 [==============================] - 1s 777us/sample - loss: 0.2949 - combined_decoder_loss: 0.2964\n",
      "Epoch 29/300\n",
      "1190/1190 [==============================] - 1s 771us/sample - loss: 0.2979 - combined_decoder_loss: 0.2975\n",
      "Epoch 30/300\n",
      "1190/1190 [==============================] - 1s 786us/sample - loss: 0.2999 - combined_decoder_loss: 0.2992\n",
      "Epoch 31/300\n",
      "1190/1190 [==============================] - 1s 779us/sample - loss: 0.2932 - combined_decoder_loss: 0.2923\n",
      "Epoch 32/300\n",
      "1190/1190 [==============================] - 1s 771us/sample - loss: 0.2903 - combined_decoder_loss: 0.2909\n",
      "Epoch 33/300\n",
      "1190/1190 [==============================] - 1s 779us/sample - loss: 0.2847 - combined_decoder_loss: 0.2837\n",
      "Epoch 34/300\n",
      "1190/1190 [==============================] - 1s 786us/sample - loss: 0.2831 - combined_decoder_loss: 0.2819\n",
      "Epoch 35/300\n",
      "1190/1190 [==============================] - 1s 771us/sample - loss: 0.2849 - combined_decoder_loss: 0.2854\n",
      "Epoch 36/300\n",
      "1190/1190 [==============================] - 1s 763us/sample - loss: 0.2839 - combined_decoder_loss: 0.2837\n",
      "Epoch 37/300\n",
      "1190/1190 [==============================] - 1s 779us/sample - loss: 0.2801 - combined_decoder_loss: 0.2802\n",
      "Epoch 38/300\n",
      "1190/1190 [==============================] - 1s 771us/sample - loss: 0.2786 - combined_decoder_loss: 0.2776\n",
      "Epoch 39/300\n",
      "1190/1190 [==============================] - 1s 779us/sample - loss: 0.2784 - combined_decoder_loss: 0.2781\n",
      "Epoch 40/300\n",
      "1190/1190 [==============================] - 1s 779us/sample - loss: 0.2794 - combined_decoder_loss: 0.2785\n",
      "Epoch 41/300\n",
      "1190/1190 [==============================] - 1s 772us/sample - loss: 0.2750 - combined_decoder_loss: 0.2744\n",
      "Epoch 42/300\n",
      "1190/1190 [==============================] - 1s 771us/sample - loss: 0.2738 - combined_decoder_loss: 0.2731\n",
      "Epoch 43/300\n",
      "1190/1190 [==============================] - 1s 771us/sample - loss: 0.2722 - combined_decoder_loss: 0.2719\n",
      "Epoch 44/300\n",
      "1190/1190 [==============================] - 1s 762us/sample - loss: 0.2701 - combined_decoder_loss: 0.2694\n",
      "Epoch 45/300\n",
      "1190/1190 [==============================] - 1s 764us/sample - loss: 0.2672 - combined_decoder_loss: 0.2670\n",
      "Epoch 46/300\n",
      "1190/1190 [==============================] - 1s 779us/sample - loss: 0.2729 - combined_decoder_loss: 0.2726\n",
      "Epoch 47/300\n",
      "1190/1190 [==============================] - 1s 787us/sample - loss: 0.2711 - combined_decoder_loss: 0.2701\n",
      "Epoch 48/300\n",
      "1190/1190 [==============================] - 1s 773us/sample - loss: 0.2709 - combined_decoder_loss: 0.2705\n",
      "Epoch 49/300\n",
      "1190/1190 [==============================] - 1s 779us/sample - loss: 0.2662 - combined_decoder_loss: 0.2667\n",
      "Epoch 50/300\n",
      "1190/1190 [==============================] - 1s 778us/sample - loss: 0.2646 - combined_decoder_loss: 0.2650\n",
      "Epoch 51/300\n",
      "1190/1190 [==============================] - 1s 762us/sample - loss: 0.2652 - combined_decoder_loss: 0.2653\n",
      "Epoch 52/300\n",
      "1190/1190 [==============================] - 1s 771us/sample - loss: 0.2671 - combined_decoder_loss: 0.2664\n",
      "Epoch 53/300\n",
      "1152/1190 [============================>.] - ETA: 0s - loss: 0.2681 - combined_decoder_loss: 0.2681"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 13\u001b[0m\n\u001b[0;32m      3\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m      5\u001b[0m vae, enc, gen \u001b[38;5;241m=\u001b[39m create_lstm_uvae(input_dim, \n\u001b[0;32m      6\u001b[0m     timesteps\u001b[38;5;241m=\u001b[39mtimesteps, \n\u001b[0;32m      7\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size, \n\u001b[0;32m      8\u001b[0m     intermediate_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m,\n\u001b[0;32m      9\u001b[0m     latent_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m,\n\u001b[0;32m     10\u001b[0m     epsilon_std\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.\u001b[39m)\n\u001b[1;32m---> 13\u001b[0m \u001b[43mvae\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m300\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m preds \u001b[38;5;241m=\u001b[39m vae\u001b[38;5;241m.\u001b[39mpredict(x, batch_size\u001b[38;5;241m=\u001b[39mbatch_size)\n",
      "File \u001b[1;32m~\\tf\\Lib\\site-packages\\keras\\engine\\training_v1.py:856\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    853\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_call_args(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    855\u001b[0m func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_training_loop(x)\n\u001b[1;32m--> 856\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    857\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    858\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    859\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    861\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    863\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    864\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_split\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    865\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    866\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    867\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    868\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    869\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    870\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    871\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    872\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    873\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\tf\\Lib\\site-packages\\keras\\engine\\training_arrays_v1.py:734\u001b[0m, in \u001b[0;36mArrayLikeTrainingLoop.fit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[0;32m    728\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    729\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`validation_steps` should not be specified if \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    730\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`validation_data` is None.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    731\u001b[0m         )\n\u001b[0;32m    732\u001b[0m     val_x, val_y, val_sample_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 734\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    735\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    736\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtargets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    738\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    742\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    744\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_targets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    745\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_sample_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_sample_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    747\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    748\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    749\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    750\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    751\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msteps_per_epoch\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    752\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\tf\\Lib\\site-packages\\keras\\engine\\training_arrays_v1.py:421\u001b[0m, in \u001b[0;36mmodel_iteration\u001b[1;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    416\u001b[0m callbacks\u001b[38;5;241m.\u001b[39m_call_batch_hook(\n\u001b[0;32m    417\u001b[0m     mode, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbegin\u001b[39m\u001b[38;5;124m\"\u001b[39m, batch_index, batch_logs\n\u001b[0;32m    418\u001b[0m )\n\u001b[0;32m    420\u001b[0m \u001b[38;5;66;03m# Get outputs.\u001b[39;00m\n\u001b[1;32m--> 421\u001b[0m batch_outs \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mins_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(batch_outs, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m    423\u001b[0m     batch_outs \u001b[38;5;241m=\u001b[39m [batch_outs]\n",
      "File \u001b[1;32m~\\tf\\Lib\\site-packages\\keras\\backend.py:4608\u001b[0m, in \u001b[0;36mGraphExecutionFunction.__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   4598\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   4599\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_callable_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   4600\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m feed_arrays \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_feed_arrays\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4604\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m session \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_session\n\u001b[0;32m   4605\u001b[0m ):\n\u001b[0;32m   4606\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_callable(feed_arrays, feed_symbols, symbol_vals, session)\n\u001b[1;32m-> 4608\u001b[0m fetched \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_callable_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43marray_vals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4609\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_fetch_callbacks(fetched[\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fetches) :])\n\u001b[0;32m   4610\u001b[0m output_structure \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mpack_sequence_as(\n\u001b[0;32m   4611\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_outputs_structure,\n\u001b[0;32m   4612\u001b[0m     fetched[: \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutputs)],\n\u001b[0;32m   4613\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   4614\u001b[0m )\n",
      "File \u001b[1;32m~\\tf\\Lib\\site-packages\\tensorflow\\python\\client\\session.py:1481\u001b[0m, in \u001b[0;36mBaseSession._Callable.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1479\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1480\u001b[0m   run_metadata_ptr \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_NewBuffer() \u001b[38;5;28;01mif\u001b[39;00m run_metadata \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1481\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mtf_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTF_SessionRunCallable\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_session\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1482\u001b[0m \u001b[43m                                         \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1483\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mrun_metadata_ptr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1484\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m run_metadata:\n\u001b[0;32m   1485\u001b[0m     proto_data \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_GetBuffer(run_metadata_ptr)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "input_dim = x.shape[-1] # 13\n",
    "timesteps = x.shape[1] # 3\n",
    "batch_size = 1\n",
    "\n",
    "vae, enc, gen = create_lstm_uvae(input_dim, \n",
    "    timesteps=timesteps, \n",
    "    batch_size=batch_size, \n",
    "    intermediate_dim=15,\n",
    "    latent_dim=30,\n",
    "    epsilon_std=1.)\n",
    "\n",
    "\n",
    "vae.fit(x, x, epochs=300)\n",
    "\n",
    "preds = vae.predict(x, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b22164c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "WARNING:tensorflow:Output {0} missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder_mean.\n",
      "WARNING:tensorflow:Output {0} missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder_logit_sigma.\n",
      "Train on 1190 samples\n",
      "Epoch 1/3000\n",
      "1190/1190 [==============================] - 3s 3ms/sample - loss: 1.1350 - combined_decoder_loss: 1.1242\n",
      "Epoch 2/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.4700 - combined_decoder_loss: 0.4691\n",
      "Epoch 3/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.3903 - combined_decoder_loss: 0.3904\n",
      "Epoch 4/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.4007 - combined_decoder_loss: 0.4005\n",
      "Epoch 5/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.3771 - combined_decoder_loss: 0.3767\n",
      "Epoch 6/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.3521 - combined_decoder_loss: 0.3524\n",
      "Epoch 7/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.3453 - combined_decoder_loss: 0.3459\n",
      "Epoch 8/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.3446 - combined_decoder_loss: 0.3437\n",
      "Epoch 9/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.3498 - combined_decoder_loss: 0.3486\n",
      "Epoch 10/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.3175 - combined_decoder_loss: 0.3178\n",
      "Epoch 11/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.3140 - combined_decoder_loss: 0.3131\n",
      "Epoch 12/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.3213 - combined_decoder_loss: 0.3214\n",
      "Epoch 13/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.3082 - combined_decoder_loss: 0.3083\n",
      "Epoch 14/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.3164 - combined_decoder_loss: 0.3152\n",
      "Epoch 15/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.3256 - combined_decoder_loss: 0.3254\n",
      "Epoch 16/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.3026 - combined_decoder_loss: 0.3016\n",
      "Epoch 17/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.3584 - combined_decoder_loss: 0.3577\n",
      "Epoch 18/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.3489 - combined_decoder_loss: 0.3480\n",
      "Epoch 19/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.2997 - combined_decoder_loss: 0.2994\n",
      "Epoch 20/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.2940 - combined_decoder_loss: 0.2938\n",
      "Epoch 21/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.2878 - combined_decoder_loss: 0.2878\n",
      "Epoch 22/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.3034 - combined_decoder_loss: 0.3036\n",
      "Epoch 23/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.2980 - combined_decoder_loss: 0.2976\n",
      "Epoch 24/3000\n",
      "1190/1190 [==============================] - 1s 854us/sample - loss: 0.3195 - combined_decoder_loss: 0.3205\n",
      "Epoch 25/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.2894 - combined_decoder_loss: 0.2894\n",
      "Epoch 26/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.2931 - combined_decoder_loss: 0.2921\n",
      "Epoch 27/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.2899 - combined_decoder_loss: 0.2900\n",
      "Epoch 28/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.2891 - combined_decoder_loss: 0.2885\n",
      "Epoch 29/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.2775 - combined_decoder_loss: 0.2774\n",
      "Epoch 30/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.2861 - combined_decoder_loss: 0.2852\n",
      "Epoch 31/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.2746 - combined_decoder_loss: 0.2744\n",
      "Epoch 32/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.2803 - combined_decoder_loss: 0.2794\n",
      "Epoch 33/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.2824 - combined_decoder_loss: 0.2825\n",
      "Epoch 34/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.2758 - combined_decoder_loss: 0.2754\n",
      "Epoch 35/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.2714 - combined_decoder_loss: 0.2703\n",
      "Epoch 36/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.2709 - combined_decoder_loss: 0.2702\n",
      "Epoch 37/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.2693 - combined_decoder_loss: 0.2685\n",
      "Epoch 38/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.2761 - combined_decoder_loss: 0.2762\n",
      "Epoch 39/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.2679 - combined_decoder_loss: 0.2681\n",
      "Epoch 40/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.2761 - combined_decoder_loss: 0.2764\n",
      "Epoch 41/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.2680 - combined_decoder_loss: 0.2684\n",
      "Epoch 42/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.2744 - combined_decoder_loss: 0.2741\n",
      "Epoch 43/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.2656 - combined_decoder_loss: 0.2656\n",
      "Epoch 44/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.2736 - combined_decoder_loss: 0.2736\n",
      "Epoch 45/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.2629 - combined_decoder_loss: 0.2629\n",
      "Epoch 46/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.2623 - combined_decoder_loss: 0.2616\n",
      "Epoch 47/3000\n",
      "1190/1190 [==============================] - 1s 831us/sample - loss: 0.2654 - combined_decoder_loss: 0.2650\n",
      "Epoch 48/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.2639 - combined_decoder_loss: 0.2653\n",
      "Epoch 49/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.2620 - combined_decoder_loss: 0.2618\n",
      "Epoch 50/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.2582 - combined_decoder_loss: 0.2574\n",
      "Epoch 51/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.2620 - combined_decoder_loss: 0.2611\n",
      "Epoch 52/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.2617 - combined_decoder_loss: 0.2616\n",
      "Epoch 53/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.2535 - combined_decoder_loss: 0.2544\n",
      "Epoch 54/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.2631 - combined_decoder_loss: 0.2632\n",
      "Epoch 55/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.2862 - combined_decoder_loss: 0.2851\n",
      "Epoch 56/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.2547 - combined_decoder_loss: 0.2546\n",
      "Epoch 57/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.2538 - combined_decoder_loss: 0.2546\n",
      "Epoch 58/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.2621 - combined_decoder_loss: 0.2624\n",
      "Epoch 59/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.2545 - combined_decoder_loss: 0.2541\n",
      "Epoch 60/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.2515 - combined_decoder_loss: 0.2507\n",
      "Epoch 61/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.2514 - combined_decoder_loss: 0.2513\n",
      "Epoch 62/3000\n",
      "1190/1190 [==============================] - 1s 833us/sample - loss: 0.2603 - combined_decoder_loss: 0.2600\n",
      "Epoch 63/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.2516 - combined_decoder_loss: 0.2516\n",
      "Epoch 64/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.2532 - combined_decoder_loss: 0.2529\n",
      "Epoch 65/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.2477 - combined_decoder_loss: 0.2474\n",
      "Epoch 66/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.2476 - combined_decoder_loss: 0.2481\n",
      "Epoch 67/3000\n",
      "1190/1190 [==============================] - 1s 821us/sample - loss: 0.2605 - combined_decoder_loss: 0.2593\n",
      "Epoch 68/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.2469 - combined_decoder_loss: 0.2467\n",
      "Epoch 69/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.2507 - combined_decoder_loss: 0.2505\n",
      "Epoch 70/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.2540 - combined_decoder_loss: 0.2536\n",
      "Epoch 71/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.2462 - combined_decoder_loss: 0.2457\n",
      "Epoch 72/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.2461 - combined_decoder_loss: 0.2461\n",
      "Epoch 73/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.2445 - combined_decoder_loss: 0.2444\n",
      "Epoch 74/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.2449 - combined_decoder_loss: 0.2444\n",
      "Epoch 75/3000\n",
      "1190/1190 [==============================] - 1s 846us/sample - loss: 0.2452 - combined_decoder_loss: 0.2455\n",
      "Epoch 76/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.2450 - combined_decoder_loss: 0.2453\n",
      "Epoch 77/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.2438 - combined_decoder_loss: 0.2440\n",
      "Epoch 78/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.2432 - combined_decoder_loss: 0.2427\n",
      "Epoch 79/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.2435 - combined_decoder_loss: 0.2443\n",
      "Epoch 80/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.2451 - combined_decoder_loss: 0.2449\n",
      "Epoch 81/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.2373 - combined_decoder_loss: 0.2367\n",
      "Epoch 82/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.2413 - combined_decoder_loss: 0.2409\n",
      "Epoch 83/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.2415 - combined_decoder_loss: 0.2406\n",
      "Epoch 84/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.2395 - combined_decoder_loss: 0.2392\n",
      "Epoch 85/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.2428 - combined_decoder_loss: 0.2427\n",
      "Epoch 86/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.2396 - combined_decoder_loss: 0.2388\n",
      "Epoch 87/3000\n",
      "1190/1190 [==============================] - 1s 855us/sample - loss: 0.2373 - combined_decoder_loss: 0.2368\n",
      "Epoch 88/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.2366 - combined_decoder_loss: 0.2378\n",
      "Epoch 89/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.2402 - combined_decoder_loss: 0.2398\n",
      "Epoch 90/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.2427 - combined_decoder_loss: 0.2430\n",
      "Epoch 91/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.2382 - combined_decoder_loss: 0.2378\n",
      "Epoch 92/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.2351 - combined_decoder_loss: 0.2349\n",
      "Epoch 93/3000\n",
      "1190/1190 [==============================] - 1s 851us/sample - loss: 0.2353 - combined_decoder_loss: 0.2349\n",
      "Epoch 94/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.2327 - combined_decoder_loss: 0.2324\n",
      "Epoch 95/3000\n",
      "1190/1190 [==============================] - 1s 836us/sample - loss: 0.2307 - combined_decoder_loss: 0.2325\n",
      "Epoch 96/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.2317 - combined_decoder_loss: 0.2314\n",
      "Epoch 97/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.2333 - combined_decoder_loss: 0.2329\n",
      "Epoch 98/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.2315 - combined_decoder_loss: 0.2317\n",
      "Epoch 99/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.2284 - combined_decoder_loss: 0.2285\n",
      "Epoch 100/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.2322 - combined_decoder_loss: 0.2322\n",
      "Epoch 101/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.2325 - combined_decoder_loss: 0.2332\n",
      "Epoch 102/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.2308 - combined_decoder_loss: 0.2315\n",
      "Epoch 103/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.2330 - combined_decoder_loss: 0.2354\n",
      "Epoch 104/3000\n",
      "1190/1190 [==============================] - 1s 828us/sample - loss: 0.2309 - combined_decoder_loss: 0.2324\n",
      "Epoch 105/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.2283 - combined_decoder_loss: 0.2286\n",
      "Epoch 106/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.2315 - combined_decoder_loss: 0.2313\n",
      "Epoch 107/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.2279 - combined_decoder_loss: 0.2277\n",
      "Epoch 108/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.2278 - combined_decoder_loss: 0.2277\n",
      "Epoch 109/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.2268 - combined_decoder_loss: 0.2271\n",
      "Epoch 110/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.2280 - combined_decoder_loss: 0.2277\n",
      "Epoch 111/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.2253 - combined_decoder_loss: 0.2258\n",
      "Epoch 112/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.2242 - combined_decoder_loss: 0.2235\n",
      "Epoch 113/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.2320 - combined_decoder_loss: 0.2319\n",
      "Epoch 114/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.2284 - combined_decoder_loss: 0.2285\n",
      "Epoch 115/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.2281 - combined_decoder_loss: 0.2282\n",
      "Epoch 116/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.2271 - combined_decoder_loss: 0.2267\n",
      "Epoch 117/3000\n",
      "1190/1190 [==============================] - 1s 842us/sample - loss: 0.2276 - combined_decoder_loss: 0.2281\n",
      "Epoch 118/3000\n",
      "1190/1190 [==============================] - 1s 835us/sample - loss: 0.2299 - combined_decoder_loss: 0.2294\n",
      "Epoch 119/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.2280 - combined_decoder_loss: 0.2275\n",
      "Epoch 120/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.2285 - combined_decoder_loss: 0.2285\n",
      "Epoch 121/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.2251 - combined_decoder_loss: 0.2252\n",
      "Epoch 122/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.2215 - combined_decoder_loss: 0.2211\n",
      "Epoch 123/3000\n",
      "1190/1190 [==============================] - 1s 831us/sample - loss: 0.2283 - combined_decoder_loss: 0.2283\n",
      "Epoch 124/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.2244 - combined_decoder_loss: 0.2244\n",
      "Epoch 125/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.2255 - combined_decoder_loss: 0.2259\n",
      "Epoch 126/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.2244 - combined_decoder_loss: 0.2242\n",
      "Epoch 127/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.2249 - combined_decoder_loss: 0.2245\n",
      "Epoch 128/3000\n",
      "1190/1190 [==============================] - 1s 874us/sample - loss: 0.2213 - combined_decoder_loss: 0.2215\n",
      "Epoch 129/3000\n",
      "1190/1190 [==============================] - 1s 862us/sample - loss: 0.2232 - combined_decoder_loss: 0.2239\n",
      "Epoch 130/3000\n",
      "1190/1190 [==============================] - 1s 855us/sample - loss: 0.2242 - combined_decoder_loss: 0.2251\n",
      "Epoch 131/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.2216 - combined_decoder_loss: 0.2213\n",
      "Epoch 132/3000\n",
      "1190/1190 [==============================] - 1s 889us/sample - loss: 0.2206 - combined_decoder_loss: 0.2205\n",
      "Epoch 133/3000\n",
      "1190/1190 [==============================] - 1s 936us/sample - loss: 0.2229 - combined_decoder_loss: 0.2229\n",
      "Epoch 134/3000\n",
      "1190/1190 [==============================] - 1s 898us/sample - loss: 0.2200 - combined_decoder_loss: 0.2195\n",
      "Epoch 135/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.2188 - combined_decoder_loss: 0.2183\n",
      "Epoch 136/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.2202 - combined_decoder_loss: 0.2196\n",
      "Epoch 137/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.2203 - combined_decoder_loss: 0.2199\n",
      "Epoch 138/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.2163 - combined_decoder_loss: 0.2159\n",
      "Epoch 139/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.2234 - combined_decoder_loss: 0.2230\n",
      "Epoch 140/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.2176 - combined_decoder_loss: 0.2183\n",
      "Epoch 141/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.2160 - combined_decoder_loss: 0.2158\n",
      "Epoch 142/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.2218 - combined_decoder_loss: 0.2217\n",
      "Epoch 143/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.2190 - combined_decoder_loss: 0.2185\n",
      "Epoch 144/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.2203 - combined_decoder_loss: 0.2198\n",
      "Epoch 145/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.2185 - combined_decoder_loss: 0.2181\n",
      "Epoch 146/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.2215 - combined_decoder_loss: 0.2210\n",
      "Epoch 147/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.2190 - combined_decoder_loss: 0.2186\n",
      "Epoch 148/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.2162 - combined_decoder_loss: 0.2158\n",
      "Epoch 149/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.2168 - combined_decoder_loss: 0.2163\n",
      "Epoch 150/3000\n",
      "1190/1190 [==============================] - 1s 849us/sample - loss: 0.2153 - combined_decoder_loss: 0.2152\n",
      "Epoch 151/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.2172 - combined_decoder_loss: 0.2169\n",
      "Epoch 152/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.2167 - combined_decoder_loss: 0.2165\n",
      "Epoch 153/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.2109 - combined_decoder_loss: 0.2104\n",
      "Epoch 154/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.2173 - combined_decoder_loss: 0.2167\n",
      "Epoch 155/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.2164 - combined_decoder_loss: 0.2162\n",
      "Epoch 156/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.2117 - combined_decoder_loss: 0.2118\n",
      "Epoch 157/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.2168 - combined_decoder_loss: 0.2167\n",
      "Epoch 158/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.2144 - combined_decoder_loss: 0.2162\n",
      "Epoch 159/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.2140 - combined_decoder_loss: 0.2139\n",
      "Epoch 160/3000\n",
      "1190/1190 [==============================] - 1s 831us/sample - loss: 0.2148 - combined_decoder_loss: 0.2146\n",
      "Epoch 161/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.2153 - combined_decoder_loss: 0.2152\n",
      "Epoch 162/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.2123 - combined_decoder_loss: 0.2124\n",
      "Epoch 163/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.2135 - combined_decoder_loss: 0.2132\n",
      "Epoch 164/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.2103 - combined_decoder_loss: 0.2103\n",
      "Epoch 165/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.2141 - combined_decoder_loss: 0.2140\n",
      "Epoch 166/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.2126 - combined_decoder_loss: 0.2120\n",
      "Epoch 167/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.2123 - combined_decoder_loss: 0.2126\n",
      "Epoch 168/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.2096 - combined_decoder_loss: 0.2102\n",
      "Epoch 169/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.2132 - combined_decoder_loss: 0.2131\n",
      "Epoch 170/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.2108 - combined_decoder_loss: 0.2107\n",
      "Epoch 171/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.2096 - combined_decoder_loss: 0.2097\n",
      "Epoch 172/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.2096 - combined_decoder_loss: 0.2099\n",
      "Epoch 173/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.2085 - combined_decoder_loss: 0.2078\n",
      "Epoch 174/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.2103 - combined_decoder_loss: 0.2100\n",
      "Epoch 175/3000\n",
      "1190/1190 [==============================] - 1s 836us/sample - loss: 0.2077 - combined_decoder_loss: 0.2086\n",
      "Epoch 176/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.2079 - combined_decoder_loss: 0.2074\n",
      "Epoch 177/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.2093 - combined_decoder_loss: 0.2091\n",
      "Epoch 178/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.2076 - combined_decoder_loss: 0.2075\n",
      "Epoch 179/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.2071 - combined_decoder_loss: 0.2067\n",
      "Epoch 180/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.2070 - combined_decoder_loss: 0.2068\n",
      "Epoch 181/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.2076 - combined_decoder_loss: 0.2073\n",
      "Epoch 182/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.2054 - combined_decoder_loss: 0.2056\n",
      "Epoch 183/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.2058 - combined_decoder_loss: 0.2056\n",
      "Epoch 184/3000\n",
      "1190/1190 [==============================] - 1s 843us/sample - loss: 0.2082 - combined_decoder_loss: 0.2082\n",
      "Epoch 185/3000\n",
      "1190/1190 [==============================] - 1s 836us/sample - loss: 0.2037 - combined_decoder_loss: 0.2040\n",
      "Epoch 186/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.2058 - combined_decoder_loss: 0.2056\n",
      "Epoch 187/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.2023 - combined_decoder_loss: 0.2024\n",
      "Epoch 188/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.2082 - combined_decoder_loss: 0.2079\n",
      "Epoch 189/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.2049 - combined_decoder_loss: 0.2048\n",
      "Epoch 190/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.2041 - combined_decoder_loss: 0.2037\n",
      "Epoch 191/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.2029 - combined_decoder_loss: 0.2028\n",
      "Epoch 192/3000\n",
      "1190/1190 [==============================] - 1s 835us/sample - loss: 0.2050 - combined_decoder_loss: 0.2052\n",
      "Epoch 193/3000\n",
      "1190/1190 [==============================] - 1s 834us/sample - loss: 0.2028 - combined_decoder_loss: 0.2029\n",
      "Epoch 194/3000\n",
      "1190/1190 [==============================] - 1s 846us/sample - loss: 0.2055 - combined_decoder_loss: 0.2050\n",
      "Epoch 195/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.2034 - combined_decoder_loss: 0.2037\n",
      "Epoch 196/3000\n",
      "1190/1190 [==============================] - 1s 833us/sample - loss: 0.2048 - combined_decoder_loss: 0.2064\n",
      "Epoch 197/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1190/1190 [==============================] - 1s 853us/sample - loss: 0.2038 - combined_decoder_loss: 0.2036\n",
      "Epoch 198/3000\n",
      "1190/1190 [==============================] - 1s 849us/sample - loss: 0.2029 - combined_decoder_loss: 0.2030\n",
      "Epoch 199/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.2045 - combined_decoder_loss: 0.2046\n",
      "Epoch 200/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.2020 - combined_decoder_loss: 0.2023\n",
      "Epoch 201/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.2023 - combined_decoder_loss: 0.2028\n",
      "Epoch 202/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.2023 - combined_decoder_loss: 0.2030\n",
      "Epoch 203/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.2031 - combined_decoder_loss: 0.2026\n",
      "Epoch 204/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.2010 - combined_decoder_loss: 0.2005\n",
      "Epoch 205/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.2019 - combined_decoder_loss: 0.2016\n",
      "Epoch 206/3000\n",
      "1190/1190 [==============================] - 1s 855us/sample - loss: 0.2017 - combined_decoder_loss: 0.2017\n",
      "Epoch 207/3000\n",
      "1190/1190 [==============================] - 1s 843us/sample - loss: 0.2051 - combined_decoder_loss: 0.2051\n",
      "Epoch 208/3000\n",
      "1190/1190 [==============================] - 1s 872us/sample - loss: 0.2030 - combined_decoder_loss: 0.2032\n",
      "Epoch 209/3000\n",
      "1190/1190 [==============================] - 1s 862us/sample - loss: 0.2003 - combined_decoder_loss: 0.1999\n",
      "Epoch 210/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.2010 - combined_decoder_loss: 0.2012\n",
      "Epoch 211/3000\n",
      "1190/1190 [==============================] - 1s 855us/sample - loss: 0.2015 - combined_decoder_loss: 0.2010\n",
      "Epoch 212/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.2006 - combined_decoder_loss: 0.2000\n",
      "Epoch 213/3000\n",
      "1190/1190 [==============================] - 1s 849us/sample - loss: 0.2009 - combined_decoder_loss: 0.2014\n",
      "Epoch 214/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1990 - combined_decoder_loss: 0.1988\n",
      "Epoch 215/3000\n",
      "1190/1190 [==============================] - 1s 862us/sample - loss: 0.2002 - combined_decoder_loss: 0.2008\n",
      "Epoch 216/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.2010 - combined_decoder_loss: 0.2011\n",
      "Epoch 217/3000\n",
      "1190/1190 [==============================] - 1s 848us/sample - loss: 0.2020 - combined_decoder_loss: 0.2017\n",
      "Epoch 218/3000\n",
      "1190/1190 [==============================] - 1s 856us/sample - loss: 0.2010 - combined_decoder_loss: 0.2009\n",
      "Epoch 219/3000\n",
      "1190/1190 [==============================] - 1s 855us/sample - loss: 0.2002 - combined_decoder_loss: 0.2004\n",
      "Epoch 220/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1986 - combined_decoder_loss: 0.1987\n",
      "Epoch 221/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.2031 - combined_decoder_loss: 0.2027\n",
      "Epoch 222/3000\n",
      "1190/1190 [==============================] - 1s 855us/sample - loss: 0.2003 - combined_decoder_loss: 0.2004\n",
      "Epoch 223/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1977 - combined_decoder_loss: 0.1982\n",
      "Epoch 224/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.2013 - combined_decoder_loss: 0.2010\n",
      "Epoch 225/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.2028 - combined_decoder_loss: 0.2024\n",
      "Epoch 226/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1987 - combined_decoder_loss: 0.1990\n",
      "Epoch 227/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1978 - combined_decoder_loss: 0.1983\n",
      "Epoch 228/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1978 - combined_decoder_loss: 0.1976\n",
      "Epoch 229/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1997 - combined_decoder_loss: 0.1996\n",
      "Epoch 230/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1965 - combined_decoder_loss: 0.1962\n",
      "Epoch 231/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.1999 - combined_decoder_loss: 0.2005\n",
      "Epoch 232/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.1993 - combined_decoder_loss: 0.1989\n",
      "Epoch 233/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1993 - combined_decoder_loss: 0.1989\n",
      "Epoch 234/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1985 - combined_decoder_loss: 0.1983\n",
      "Epoch 235/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1973 - combined_decoder_loss: 0.1970\n",
      "Epoch 236/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.2009 - combined_decoder_loss: 0.2005\n",
      "Epoch 237/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.2003 - combined_decoder_loss: 0.2001\n",
      "Epoch 238/3000\n",
      "1190/1190 [==============================] - 1s 856us/sample - loss: 0.1972 - combined_decoder_loss: 0.1971\n",
      "Epoch 239/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1999 - combined_decoder_loss: 0.1996\n",
      "Epoch 240/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1994 - combined_decoder_loss: 0.1991\n",
      "Epoch 241/3000\n",
      "1190/1190 [==============================] - 1s 841us/sample - loss: 0.2015 - combined_decoder_loss: 0.2009\n",
      "Epoch 242/3000\n",
      "1190/1190 [==============================] - 1s 854us/sample - loss: 0.1970 - combined_decoder_loss: 0.1971\n",
      "Epoch 243/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1975 - combined_decoder_loss: 0.1976\n",
      "Epoch 244/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1994 - combined_decoder_loss: 0.1992\n",
      "Epoch 245/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1993 - combined_decoder_loss: 0.1997\n",
      "Epoch 246/3000\n",
      "1190/1190 [==============================] - 1s 855us/sample - loss: 0.1982 - combined_decoder_loss: 0.1986\n",
      "Epoch 247/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.2003 - combined_decoder_loss: 0.2002\n",
      "Epoch 248/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.2018 - combined_decoder_loss: 0.2018\n",
      "Epoch 249/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1971 - combined_decoder_loss: 0.1974\n",
      "Epoch 250/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1972 - combined_decoder_loss: 0.1972\n",
      "Epoch 251/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1994 - combined_decoder_loss: 0.1990\n",
      "Epoch 252/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1946 - combined_decoder_loss: 0.1941\n",
      "Epoch 253/3000\n",
      "1190/1190 [==============================] - 1s 848us/sample - loss: 0.2001 - combined_decoder_loss: 0.2002\n",
      "Epoch 254/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1967 - combined_decoder_loss: 0.1964\n",
      "Epoch 255/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1979 - combined_decoder_loss: 0.1978\n",
      "Epoch 256/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1964 - combined_decoder_loss: 0.1963\n",
      "Epoch 257/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1979 - combined_decoder_loss: 0.1976\n",
      "Epoch 258/3000\n",
      "1190/1190 [==============================] - 1s 848us/sample - loss: 0.1958 - combined_decoder_loss: 0.1956\n",
      "Epoch 259/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1961 - combined_decoder_loss: 0.1964\n",
      "Epoch 260/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1993 - combined_decoder_loss: 0.1994\n",
      "Epoch 261/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1975 - combined_decoder_loss: 0.1977\n",
      "Epoch 262/3000\n",
      "1190/1190 [==============================] - 1s 831us/sample - loss: 0.1964 - combined_decoder_loss: 0.1964\n",
      "Epoch 263/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1948 - combined_decoder_loss: 0.1944\n",
      "Epoch 264/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1964 - combined_decoder_loss: 0.1964\n",
      "Epoch 265/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1938 - combined_decoder_loss: 0.1935\n",
      "Epoch 266/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1966 - combined_decoder_loss: 0.1967\n",
      "Epoch 267/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1946 - combined_decoder_loss: 0.1948\n",
      "Epoch 268/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.2029 - combined_decoder_loss: 0.2032\n",
      "Epoch 269/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1983 - combined_decoder_loss: 0.1984\n",
      "Epoch 270/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1941 - combined_decoder_loss: 0.1938\n",
      "Epoch 271/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.2020 - combined_decoder_loss: 0.2026\n",
      "Epoch 272/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1991 - combined_decoder_loss: 0.1989\n",
      "Epoch 273/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1957 - combined_decoder_loss: 0.1954\n",
      "Epoch 274/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.2001 - combined_decoder_loss: 0.1998\n",
      "Epoch 275/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1959 - combined_decoder_loss: 0.1964\n",
      "Epoch 276/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1983 - combined_decoder_loss: 0.1981\n",
      "Epoch 277/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1962 - combined_decoder_loss: 0.1971\n",
      "Epoch 278/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1943 - combined_decoder_loss: 0.1947\n",
      "Epoch 279/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1962 - combined_decoder_loss: 0.1958\n",
      "Epoch 280/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1970 - combined_decoder_loss: 0.1977\n",
      "Epoch 281/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1966 - combined_decoder_loss: 0.1968\n",
      "Epoch 282/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1948 - combined_decoder_loss: 0.1953\n",
      "Epoch 283/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1940 - combined_decoder_loss: 0.1941\n",
      "Epoch 284/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1955 - combined_decoder_loss: 0.1952\n",
      "Epoch 285/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.1950 - combined_decoder_loss: 0.1946\n",
      "Epoch 286/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1962 - combined_decoder_loss: 0.1964\n",
      "Epoch 287/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1956 - combined_decoder_loss: 0.1957\n",
      "Epoch 288/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1964 - combined_decoder_loss: 0.1962\n",
      "Epoch 289/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1962 - combined_decoder_loss: 0.1957\n",
      "Epoch 290/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.2046 - combined_decoder_loss: 0.2040\n",
      "Epoch 291/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1970 - combined_decoder_loss: 0.1968\n",
      "Epoch 292/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1966 - combined_decoder_loss: 0.1965\n",
      "Epoch 293/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1961 - combined_decoder_loss: 0.1957\n",
      "Epoch 294/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1954 - combined_decoder_loss: 0.1954\n",
      "Epoch 295/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1958 - combined_decoder_loss: 0.1960\n",
      "Epoch 296/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1959 - combined_decoder_loss: 0.1955\n",
      "Epoch 297/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1976 - combined_decoder_loss: 0.1969\n",
      "Epoch 298/3000\n",
      "1190/1190 [==============================] - 1s 823us/sample - loss: 0.1949 - combined_decoder_loss: 0.1954\n",
      "Epoch 299/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1955 - combined_decoder_loss: 0.1958\n",
      "Epoch 300/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1955 - combined_decoder_loss: 0.1955\n",
      "Epoch 301/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1926 - combined_decoder_loss: 0.1924\n",
      "Epoch 302/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1936 - combined_decoder_loss: 0.1938\n",
      "Epoch 303/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1968 - combined_decoder_loss: 0.1970\n",
      "Epoch 304/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1923 - combined_decoder_loss: 0.1920\n",
      "Epoch 305/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1935 - combined_decoder_loss: 0.1932\n",
      "Epoch 306/3000\n",
      "1190/1190 [==============================] - 1s 849us/sample - loss: 0.2032 - combined_decoder_loss: 0.2030\n",
      "Epoch 307/3000\n",
      "1190/1190 [==============================] - 1s 855us/sample - loss: 0.1917 - combined_decoder_loss: 0.1914\n",
      "Epoch 308/3000\n",
      "1190/1190 [==============================] - 1s 855us/sample - loss: 0.1948 - combined_decoder_loss: 0.1949\n",
      "Epoch 309/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.1939 - combined_decoder_loss: 0.1934\n",
      "Epoch 310/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1982 - combined_decoder_loss: 0.1981\n",
      "Epoch 311/3000\n",
      "1190/1190 [==============================] - 1s 855us/sample - loss: 0.1954 - combined_decoder_loss: 0.1954\n",
      "Epoch 312/3000\n",
      "1190/1190 [==============================] - 1s 855us/sample - loss: 0.1948 - combined_decoder_loss: 0.1948\n",
      "Epoch 313/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1954 - combined_decoder_loss: 0.1950\n",
      "Epoch 314/3000\n",
      "1190/1190 [==============================] - 1s 855us/sample - loss: 0.1940 - combined_decoder_loss: 0.1947\n",
      "Epoch 315/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1929 - combined_decoder_loss: 0.1927\n",
      "Epoch 316/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1924 - combined_decoder_loss: 0.1922\n",
      "Epoch 317/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1944 - combined_decoder_loss: 0.1945\n",
      "Epoch 318/3000\n",
      "1190/1190 [==============================] - 1s 875us/sample - loss: 0.2004 - combined_decoder_loss: 0.2007\n",
      "Epoch 319/3000\n",
      "1190/1190 [==============================] - 1s 855us/sample - loss: 0.1944 - combined_decoder_loss: 0.1944\n",
      "Epoch 320/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1957 - combined_decoder_loss: 0.1954\n",
      "Epoch 321/3000\n",
      "1190/1190 [==============================] - 1s 866us/sample - loss: 0.1958 - combined_decoder_loss: 0.1958\n",
      "Epoch 322/3000\n",
      "1190/1190 [==============================] - 1s 909us/sample - loss: 0.1992 - combined_decoder_loss: 0.1985\n",
      "Epoch 323/3000\n",
      "1190/1190 [==============================] - 1s 962us/sample - loss: 0.1957 - combined_decoder_loss: 0.1953\n",
      "Epoch 324/3000\n",
      "1190/1190 [==============================] - 1s 903us/sample - loss: 0.1934 - combined_decoder_loss: 0.1936\n",
      "Epoch 325/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1920 - combined_decoder_loss: 0.1919\n",
      "Epoch 326/3000\n",
      "1190/1190 [==============================] - 1s 846us/sample - loss: 0.1940 - combined_decoder_loss: 0.1935\n",
      "Epoch 327/3000\n",
      "1190/1190 [==============================] - 1s 848us/sample - loss: 0.1960 - combined_decoder_loss: 0.1958\n",
      "Epoch 328/3000\n",
      "1190/1190 [==============================] - 1s 886us/sample - loss: 0.1949 - combined_decoder_loss: 0.1947\n",
      "Epoch 329/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1190/1190 [==============================] - 1s 893us/sample - loss: 0.1936 - combined_decoder_loss: 0.1934\n",
      "Epoch 330/3000\n",
      "1190/1190 [==============================] - 1s 850us/sample - loss: 0.1929 - combined_decoder_loss: 0.1928\n",
      "Epoch 331/3000\n",
      "1190/1190 [==============================] - 1s 860us/sample - loss: 0.1935 - combined_decoder_loss: 0.1935\n",
      "Epoch 332/3000\n",
      "1190/1190 [==============================] - 1s 858us/sample - loss: 0.1921 - combined_decoder_loss: 0.1919\n",
      "Epoch 333/3000\n",
      "1190/1190 [==============================] - 1s 857us/sample - loss: 0.2003 - combined_decoder_loss: 0.2000\n",
      "Epoch 334/3000\n",
      "1190/1190 [==============================] - 1s 850us/sample - loss: 0.1914 - combined_decoder_loss: 0.1912\n",
      "Epoch 335/3000\n",
      "1190/1190 [==============================] - 1s 865us/sample - loss: 0.1939 - combined_decoder_loss: 0.1936\n",
      "Epoch 336/3000\n",
      "1190/1190 [==============================] - 1s 858us/sample - loss: 0.1921 - combined_decoder_loss: 0.1925\n",
      "Epoch 337/3000\n",
      "1190/1190 [==============================] - 1s 858us/sample - loss: 0.1958 - combined_decoder_loss: 0.1961\n",
      "Epoch 338/3000\n",
      "1190/1190 [==============================] - 1s 857us/sample - loss: 0.1916 - combined_decoder_loss: 0.1912\n",
      "Epoch 339/3000\n",
      "1190/1190 [==============================] - 1s 873us/sample - loss: 0.1954 - combined_decoder_loss: 0.1950\n",
      "Epoch 340/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1929 - combined_decoder_loss: 0.1927\n",
      "Epoch 341/3000\n",
      "1190/1190 [==============================] - 1s 852us/sample - loss: 0.1951 - combined_decoder_loss: 0.1949\n",
      "Epoch 342/3000\n",
      "1190/1190 [==============================] - 1s 857us/sample - loss: 0.1937 - combined_decoder_loss: 0.1935\n",
      "Epoch 343/3000\n",
      "1190/1190 [==============================] - 1s 865us/sample - loss: 0.1918 - combined_decoder_loss: 0.1918\n",
      "Epoch 344/3000\n",
      "1190/1190 [==============================] - 1s 848us/sample - loss: 0.1944 - combined_decoder_loss: 0.1951\n",
      "Epoch 345/3000\n",
      "1190/1190 [==============================] - 1s 849us/sample - loss: 0.1919 - combined_decoder_loss: 0.1918\n",
      "Epoch 346/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.1908 - combined_decoder_loss: 0.1908\n",
      "Epoch 347/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1956 - combined_decoder_loss: 0.1960\n",
      "Epoch 348/3000\n",
      "1190/1190 [==============================] - 1s 856us/sample - loss: 0.1951 - combined_decoder_loss: 0.1948\n",
      "Epoch 349/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1939 - combined_decoder_loss: 0.1938\n",
      "Epoch 350/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1891 - combined_decoder_loss: 0.1894\n",
      "Epoch 351/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1954 - combined_decoder_loss: 0.1955\n",
      "Epoch 352/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.1962 - combined_decoder_loss: 0.1964\n",
      "Epoch 353/3000\n",
      "1190/1190 [==============================] - 1s 856us/sample - loss: 0.1925 - combined_decoder_loss: 0.1922\n",
      "Epoch 354/3000\n",
      "1190/1190 [==============================] - 1s 871us/sample - loss: 0.1937 - combined_decoder_loss: 0.1935\n",
      "Epoch 355/3000\n",
      "1190/1190 [==============================] - 1s 856us/sample - loss: 0.1925 - combined_decoder_loss: 0.1924\n",
      "Epoch 356/3000\n",
      "1190/1190 [==============================] - 1s 855us/sample - loss: 0.1910 - combined_decoder_loss: 0.1911\n",
      "Epoch 357/3000\n",
      "1190/1190 [==============================] - 1s 853us/sample - loss: 0.1946 - combined_decoder_loss: 0.1944\n",
      "Epoch 358/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1952 - combined_decoder_loss: 0.1954\n",
      "Epoch 359/3000\n",
      "1190/1190 [==============================] - 1s 846us/sample - loss: 0.1926 - combined_decoder_loss: 0.1923\n",
      "Epoch 360/3000\n",
      "1190/1190 [==============================] - 1s 848us/sample - loss: 0.1961 - combined_decoder_loss: 0.1957\n",
      "Epoch 361/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1924 - combined_decoder_loss: 0.1926\n",
      "Epoch 362/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1941 - combined_decoder_loss: 0.1938\n",
      "Epoch 363/3000\n",
      "1190/1190 [==============================] - 1s 822us/sample - loss: 0.1971 - combined_decoder_loss: 0.1977\n",
      "Epoch 364/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1916 - combined_decoder_loss: 0.1918\n",
      "Epoch 365/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1910 - combined_decoder_loss: 0.1917\n",
      "Epoch 366/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1909 - combined_decoder_loss: 0.1914\n",
      "Epoch 367/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1984 - combined_decoder_loss: 0.1985\n",
      "Epoch 368/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1915 - combined_decoder_loss: 0.1913\n",
      "Epoch 369/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1909 - combined_decoder_loss: 0.1908\n",
      "Epoch 370/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1915 - combined_decoder_loss: 0.1922\n",
      "Epoch 371/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1962 - combined_decoder_loss: 0.1956\n",
      "Epoch 372/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1935 - combined_decoder_loss: 0.1939\n",
      "Epoch 373/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1911 - combined_decoder_loss: 0.1906\n",
      "Epoch 374/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1946 - combined_decoder_loss: 0.1943\n",
      "Epoch 375/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1909 - combined_decoder_loss: 0.1907\n",
      "Epoch 376/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1908 - combined_decoder_loss: 0.1906\n",
      "Epoch 377/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1921 - combined_decoder_loss: 0.1917\n",
      "Epoch 378/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1947 - combined_decoder_loss: 0.1947\n",
      "Epoch 379/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.1910 - combined_decoder_loss: 0.1908\n",
      "Epoch 380/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1901 - combined_decoder_loss: 0.1901\n",
      "Epoch 381/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1951 - combined_decoder_loss: 0.1954\n",
      "Epoch 382/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1903 - combined_decoder_loss: 0.1905\n",
      "Epoch 383/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1937 - combined_decoder_loss: 0.1942\n",
      "Epoch 384/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.1918 - combined_decoder_loss: 0.1918\n",
      "Epoch 385/3000\n",
      "1190/1190 [==============================] - 1s 831us/sample - loss: 0.1912 - combined_decoder_loss: 0.1913\n",
      "Epoch 386/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1939 - combined_decoder_loss: 0.1939\n",
      "Epoch 387/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1911 - combined_decoder_loss: 0.1907\n",
      "Epoch 388/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1943 - combined_decoder_loss: 0.1940\n",
      "Epoch 389/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1927 - combined_decoder_loss: 0.1929\n",
      "Epoch 390/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1946 - combined_decoder_loss: 0.1945\n",
      "Epoch 391/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1902 - combined_decoder_loss: 0.1903\n",
      "Epoch 392/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.1926 - combined_decoder_loss: 0.1925\n",
      "Epoch 393/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1909 - combined_decoder_loss: 0.1910\n",
      "Epoch 394/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1900 - combined_decoder_loss: 0.1896\n",
      "Epoch 395/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1958 - combined_decoder_loss: 0.1956\n",
      "Epoch 396/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1930 - combined_decoder_loss: 0.1929\n",
      "Epoch 397/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1904 - combined_decoder_loss: 0.1902\n",
      "Epoch 398/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1896 - combined_decoder_loss: 0.1895\n",
      "Epoch 399/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1919 - combined_decoder_loss: 0.1915\n",
      "Epoch 400/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1895 - combined_decoder_loss: 0.1896\n",
      "Epoch 401/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1892 - combined_decoder_loss: 0.1896\n",
      "Epoch 402/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1920 - combined_decoder_loss: 0.1922\n",
      "Epoch 403/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1909 - combined_decoder_loss: 0.1909\n",
      "Epoch 404/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1915 - combined_decoder_loss: 0.1916\n",
      "Epoch 405/3000\n",
      "1190/1190 [==============================] - 1s 849us/sample - loss: 0.1904 - combined_decoder_loss: 0.1901\n",
      "Epoch 406/3000\n",
      "1190/1190 [==============================] - 1s 858us/sample - loss: 0.1876 - combined_decoder_loss: 0.1878\n",
      "Epoch 407/3000\n",
      "1190/1190 [==============================] - 1s 849us/sample - loss: 0.1921 - combined_decoder_loss: 0.1922\n",
      "Epoch 408/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1905 - combined_decoder_loss: 0.1901\n",
      "Epoch 409/3000\n",
      "1190/1190 [==============================] - 1s 842us/sample - loss: 0.1887 - combined_decoder_loss: 0.1884\n",
      "Epoch 410/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1882 - combined_decoder_loss: 0.1878\n",
      "Epoch 411/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1887 - combined_decoder_loss: 0.1885\n",
      "Epoch 412/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1887 - combined_decoder_loss: 0.1883\n",
      "Epoch 413/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.1938 - combined_decoder_loss: 0.1936\n",
      "Epoch 414/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1903 - combined_decoder_loss: 0.1903\n",
      "Epoch 415/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1882 - combined_decoder_loss: 0.1881\n",
      "Epoch 416/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1882 - combined_decoder_loss: 0.1880\n",
      "Epoch 417/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1873 - combined_decoder_loss: 0.1872\n",
      "Epoch 418/3000\n",
      "1190/1190 [==============================] - 1s 854us/sample - loss: 0.1937 - combined_decoder_loss: 0.1934\n",
      "Epoch 419/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1917 - combined_decoder_loss: 0.1914\n",
      "Epoch 420/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1895 - combined_decoder_loss: 0.1894\n",
      "Epoch 421/3000\n",
      "1190/1190 [==============================] - 1s 854us/sample - loss: 0.1881 - combined_decoder_loss: 0.1883\n",
      "Epoch 422/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1898 - combined_decoder_loss: 0.1897\n",
      "Epoch 423/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1871 - combined_decoder_loss: 0.1870\n",
      "Epoch 424/3000\n",
      "1190/1190 [==============================] - 1s 865us/sample - loss: 0.1889 - combined_decoder_loss: 0.1890\n",
      "Epoch 425/3000\n",
      "1190/1190 [==============================] - 1s 864us/sample - loss: 0.1881 - combined_decoder_loss: 0.1882\n",
      "Epoch 426/3000\n",
      "1190/1190 [==============================] - 1s 863us/sample - loss: 0.1889 - combined_decoder_loss: 0.1892\n",
      "Epoch 427/3000\n",
      "1190/1190 [==============================] - 1s 880us/sample - loss: 0.1918 - combined_decoder_loss: 0.1918\n",
      "Epoch 428/3000\n",
      "1190/1190 [==============================] - 1s 872us/sample - loss: 0.1880 - combined_decoder_loss: 0.1880\n",
      "Epoch 429/3000\n",
      "1190/1190 [==============================] - 1s 853us/sample - loss: 0.1863 - combined_decoder_loss: 0.1863\n",
      "Epoch 430/3000\n",
      "1190/1190 [==============================] - 1s 856us/sample - loss: 0.1891 - combined_decoder_loss: 0.1888\n",
      "Epoch 431/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1886 - combined_decoder_loss: 0.1892\n",
      "Epoch 432/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1889 - combined_decoder_loss: 0.1884\n",
      "Epoch 433/3000\n",
      "1190/1190 [==============================] - 1s 855us/sample - loss: 0.1867 - combined_decoder_loss: 0.1863\n",
      "Epoch 434/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1888 - combined_decoder_loss: 0.1889\n",
      "Epoch 435/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1891 - combined_decoder_loss: 0.1890\n",
      "Epoch 436/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1929 - combined_decoder_loss: 0.1924\n",
      "Epoch 437/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1879 - combined_decoder_loss: 0.1879\n",
      "Epoch 438/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1881 - combined_decoder_loss: 0.1888\n",
      "Epoch 439/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1880 - combined_decoder_loss: 0.1875\n",
      "Epoch 440/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1882 - combined_decoder_loss: 0.1878\n",
      "Epoch 441/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1897 - combined_decoder_loss: 0.1900\n",
      "Epoch 442/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1913 - combined_decoder_loss: 0.1910\n",
      "Epoch 443/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1880 - combined_decoder_loss: 0.1878\n",
      "Epoch 444/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1911 - combined_decoder_loss: 0.1910\n",
      "Epoch 445/3000\n",
      "1190/1190 [==============================] - 1s 846us/sample - loss: 0.1915 - combined_decoder_loss: 0.1911\n",
      "Epoch 446/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1883 - combined_decoder_loss: 0.1882\n",
      "Epoch 447/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1871 - combined_decoder_loss: 0.1869\n",
      "Epoch 448/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1875 - combined_decoder_loss: 0.1871\n",
      "Epoch 449/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.1881 - combined_decoder_loss: 0.1880\n",
      "Epoch 450/3000\n",
      "1190/1190 [==============================] - 1s 848us/sample - loss: 0.1869 - combined_decoder_loss: 0.1871\n",
      "Epoch 451/3000\n",
      "1190/1190 [==============================] - 1s 841us/sample - loss: 0.1928 - combined_decoder_loss: 0.1934\n",
      "Epoch 452/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1854 - combined_decoder_loss: 0.1852\n",
      "Epoch 453/3000\n",
      "1190/1190 [==============================] - 1s 856us/sample - loss: 0.1879 - combined_decoder_loss: 0.1875\n",
      "Epoch 454/3000\n",
      "1190/1190 [==============================] - 1s 859us/sample - loss: 0.1911 - combined_decoder_loss: 0.1911\n",
      "Epoch 455/3000\n",
      "1190/1190 [==============================] - 1s 855us/sample - loss: 0.1852 - combined_decoder_loss: 0.1851\n",
      "Epoch 456/3000\n",
      "1190/1190 [==============================] - 1s 852us/sample - loss: 0.1882 - combined_decoder_loss: 0.1883\n",
      "Epoch 457/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1850 - combined_decoder_loss: 0.1849\n",
      "Epoch 458/3000\n",
      "1190/1190 [==============================] - 1s 854us/sample - loss: 0.1873 - combined_decoder_loss: 0.1873\n",
      "Epoch 459/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.1874 - combined_decoder_loss: 0.1877\n",
      "Epoch 460/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1888 - combined_decoder_loss: 0.1890\n",
      "Epoch 461/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1874 - combined_decoder_loss: 0.1875\n",
      "Epoch 462/3000\n",
      "1190/1190 [==============================] - 1s 849us/sample - loss: 0.1863 - combined_decoder_loss: 0.1862\n",
      "Epoch 463/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.1852 - combined_decoder_loss: 0.1853\n",
      "Epoch 464/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1866 - combined_decoder_loss: 0.1864\n",
      "Epoch 465/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1848 - combined_decoder_loss: 0.1849\n",
      "Epoch 466/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1836 - combined_decoder_loss: 0.1837\n",
      "Epoch 467/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.1885 - combined_decoder_loss: 0.1890\n",
      "Epoch 468/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.1857 - combined_decoder_loss: 0.1863\n",
      "Epoch 469/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.1863 - combined_decoder_loss: 0.1871\n",
      "Epoch 470/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1867 - combined_decoder_loss: 0.1863\n",
      "Epoch 471/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1871 - combined_decoder_loss: 0.1872\n",
      "Epoch 472/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.1841 - combined_decoder_loss: 0.1839\n",
      "Epoch 473/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.1890 - combined_decoder_loss: 0.1889\n",
      "Epoch 474/3000\n",
      "1190/1190 [==============================] - 1s 846us/sample - loss: 0.1854 - combined_decoder_loss: 0.1851\n",
      "Epoch 475/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1851 - combined_decoder_loss: 0.1851\n",
      "Epoch 476/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1849 - combined_decoder_loss: 0.1850\n",
      "Epoch 477/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1861 - combined_decoder_loss: 0.1859\n",
      "Epoch 478/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1947 - combined_decoder_loss: 0.1944\n",
      "Epoch 479/3000\n",
      "1190/1190 [==============================] - 1s 846us/sample - loss: 0.1866 - combined_decoder_loss: 0.1865\n",
      "Epoch 480/3000\n",
      "1190/1190 [==============================] - 1s 846us/sample - loss: 0.1907 - combined_decoder_loss: 0.1905\n",
      "Epoch 481/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1844 - combined_decoder_loss: 0.1846\n",
      "Epoch 482/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1867 - combined_decoder_loss: 0.1863\n",
      "Epoch 483/3000\n",
      "1190/1190 [==============================] - 1s 841us/sample - loss: 0.1858 - combined_decoder_loss: 0.1860\n",
      "Epoch 484/3000\n",
      "1190/1190 [==============================] - 1s 856us/sample - loss: 0.1863 - combined_decoder_loss: 0.1872\n",
      "Epoch 485/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1861 - combined_decoder_loss: 0.1863\n",
      "Epoch 486/3000\n",
      "1190/1190 [==============================] - 1s 841us/sample - loss: 0.1839 - combined_decoder_loss: 0.1836\n",
      "Epoch 487/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1857 - combined_decoder_loss: 0.1859\n",
      "Epoch 488/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1852 - combined_decoder_loss: 0.1856\n",
      "Epoch 489/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1858 - combined_decoder_loss: 0.1859\n",
      "Epoch 490/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1846 - combined_decoder_loss: 0.1843\n",
      "Epoch 491/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1843 - combined_decoder_loss: 0.1843\n",
      "Epoch 492/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1853 - combined_decoder_loss: 0.1848\n",
      "Epoch 493/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1838 - combined_decoder_loss: 0.1835\n",
      "Epoch 494/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1907 - combined_decoder_loss: 0.1906\n",
      "Epoch 495/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1849 - combined_decoder_loss: 0.1847\n",
      "Epoch 496/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1867 - combined_decoder_loss: 0.1868\n",
      "Epoch 497/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1855 - combined_decoder_loss: 0.1853\n",
      "Epoch 498/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1864 - combined_decoder_loss: 0.1864\n",
      "Epoch 499/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1852 - combined_decoder_loss: 0.1855\n",
      "Epoch 500/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.1826 - combined_decoder_loss: 0.1823\n",
      "Epoch 501/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1860 - combined_decoder_loss: 0.1860\n",
      "Epoch 502/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1847 - combined_decoder_loss: 0.1848\n",
      "Epoch 503/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1908 - combined_decoder_loss: 0.1904\n",
      "Epoch 504/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1862 - combined_decoder_loss: 0.1862\n",
      "Epoch 505/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1880 - combined_decoder_loss: 0.1884\n",
      "Epoch 506/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1848 - combined_decoder_loss: 0.1846\n",
      "Epoch 507/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1837 - combined_decoder_loss: 0.1838\n",
      "Epoch 508/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1839 - combined_decoder_loss: 0.1836\n",
      "Epoch 509/3000\n",
      "1190/1190 [==============================] - 1s 831us/sample - loss: 0.1856 - combined_decoder_loss: 0.1854\n",
      "Epoch 510/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1862 - combined_decoder_loss: 0.1858\n",
      "Epoch 511/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1831 - combined_decoder_loss: 0.1831\n",
      "Epoch 512/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1850 - combined_decoder_loss: 0.1851\n",
      "Epoch 513/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1837 - combined_decoder_loss: 0.1836\n",
      "Epoch 514/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.1886 - combined_decoder_loss: 0.1883\n",
      "Epoch 515/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1834 - combined_decoder_loss: 0.1831\n",
      "Epoch 516/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1839 - combined_decoder_loss: 0.1838\n",
      "Epoch 517/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1855 - combined_decoder_loss: 0.1859\n",
      "Epoch 518/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1845 - combined_decoder_loss: 0.1848\n",
      "Epoch 519/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1839 - combined_decoder_loss: 0.1839\n",
      "Epoch 520/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1833 - combined_decoder_loss: 0.1838\n",
      "Epoch 521/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.1836 - combined_decoder_loss: 0.1838\n",
      "Epoch 522/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1809 - combined_decoder_loss: 0.1806\n",
      "Epoch 523/3000\n",
      "1190/1190 [==============================] - 1s 846us/sample - loss: 0.1829 - combined_decoder_loss: 0.1823\n",
      "Epoch 524/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1851 - combined_decoder_loss: 0.1851\n",
      "Epoch 525/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.1847 - combined_decoder_loss: 0.1845\n",
      "Epoch 526/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1829 - combined_decoder_loss: 0.1833\n",
      "Epoch 527/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1840 - combined_decoder_loss: 0.1914\n",
      "Epoch 528/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.1833 - combined_decoder_loss: 0.1833\n",
      "Epoch 529/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1813 - combined_decoder_loss: 0.1814\n",
      "Epoch 530/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1828 - combined_decoder_loss: 0.1830\n",
      "Epoch 531/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1841 - combined_decoder_loss: 0.1841\n",
      "Epoch 532/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1824 - combined_decoder_loss: 0.1821\n",
      "Epoch 533/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1831 - combined_decoder_loss: 0.1830\n",
      "Epoch 534/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1837 - combined_decoder_loss: 0.1838\n",
      "Epoch 535/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1855 - combined_decoder_loss: 0.1857\n",
      "Epoch 536/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1907 - combined_decoder_loss: 0.1902\n",
      "Epoch 537/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1851 - combined_decoder_loss: 0.1846\n",
      "Epoch 538/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.1833 - combined_decoder_loss: 0.1831\n",
      "Epoch 539/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1857 - combined_decoder_loss: 0.1857\n",
      "Epoch 540/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1827 - combined_decoder_loss: 0.1826\n",
      "Epoch 541/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1858 - combined_decoder_loss: 0.1857\n",
      "Epoch 542/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1849 - combined_decoder_loss: 0.1847\n",
      "Epoch 543/3000\n",
      "1190/1190 [==============================] - 1s 856us/sample - loss: 0.1836 - combined_decoder_loss: 0.1834\n",
      "Epoch 544/3000\n",
      "1190/1190 [==============================] - 1s 846us/sample - loss: 0.1848 - combined_decoder_loss: 0.1846\n",
      "Epoch 545/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1821 - combined_decoder_loss: 0.1818\n",
      "Epoch 546/3000\n",
      "1190/1190 [==============================] - 1s 855us/sample - loss: 0.1838 - combined_decoder_loss: 0.1839\n",
      "Epoch 547/3000\n",
      "1190/1190 [==============================] - 1s 856us/sample - loss: 0.1840 - combined_decoder_loss: 0.1838\n",
      "Epoch 548/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1893 - combined_decoder_loss: 0.1892\n",
      "Epoch 549/3000\n",
      "1190/1190 [==============================] - 1s 849us/sample - loss: 0.1841 - combined_decoder_loss: 0.1842\n",
      "Epoch 550/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1837 - combined_decoder_loss: 0.1836\n",
      "Epoch 551/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1833 - combined_decoder_loss: 0.1835\n",
      "Epoch 552/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.1879 - combined_decoder_loss: 0.1878\n",
      "Epoch 553/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1813 - combined_decoder_loss: 0.1814\n",
      "Epoch 554/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1829 - combined_decoder_loss: 0.1826\n",
      "Epoch 555/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1832 - combined_decoder_loss: 0.1831\n",
      "Epoch 556/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1875 - combined_decoder_loss: 0.1868\n",
      "Epoch 557/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.1825 - combined_decoder_loss: 0.1829\n",
      "Epoch 558/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1825 - combined_decoder_loss: 0.1823\n",
      "Epoch 559/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1830 - combined_decoder_loss: 0.1830\n",
      "Epoch 560/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1831 - combined_decoder_loss: 0.1827\n",
      "Epoch 561/3000\n",
      "1190/1190 [==============================] - 1s 846us/sample - loss: 0.1886 - combined_decoder_loss: 0.1882\n",
      "Epoch 562/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1819 - combined_decoder_loss: 0.1822\n",
      "Epoch 563/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1803 - combined_decoder_loss: 0.1804\n",
      "Epoch 564/3000\n",
      "1190/1190 [==============================] - 1s 849us/sample - loss: 0.1909 - combined_decoder_loss: 0.1906\n",
      "Epoch 565/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1795 - combined_decoder_loss: 0.1798\n",
      "Epoch 566/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1853 - combined_decoder_loss: 0.1852\n",
      "Epoch 567/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1825 - combined_decoder_loss: 0.1826\n",
      "Epoch 568/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1809 - combined_decoder_loss: 0.1807\n",
      "Epoch 569/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1825 - combined_decoder_loss: 0.1822\n",
      "Epoch 570/3000\n",
      "1190/1190 [==============================] - 1s 849us/sample - loss: 0.1805 - combined_decoder_loss: 0.1809\n",
      "Epoch 571/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1826 - combined_decoder_loss: 0.1827\n",
      "Epoch 572/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1846 - combined_decoder_loss: 0.1842\n",
      "Epoch 573/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1849 - combined_decoder_loss: 0.1849\n",
      "Epoch 574/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1809 - combined_decoder_loss: 0.1805\n",
      "Epoch 575/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1816 - combined_decoder_loss: 0.1821\n",
      "Epoch 576/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1821 - combined_decoder_loss: 0.1827\n",
      "Epoch 577/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1819 - combined_decoder_loss: 0.1819\n",
      "Epoch 578/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.1834 - combined_decoder_loss: 0.1832\n",
      "Epoch 579/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1808 - combined_decoder_loss: 0.1803\n",
      "Epoch 580/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1836 - combined_decoder_loss: 0.1831\n",
      "Epoch 581/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1831 - combined_decoder_loss: 0.1835\n",
      "Epoch 582/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1826 - combined_decoder_loss: 0.1826\n",
      "Epoch 583/3000\n",
      "1190/1190 [==============================] - 1s 856us/sample - loss: 0.1872 - combined_decoder_loss: 0.1876\n",
      "Epoch 584/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1816 - combined_decoder_loss: 0.1813\n",
      "Epoch 585/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1813 - combined_decoder_loss: 0.1817\n",
      "Epoch 586/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1846 - combined_decoder_loss: 0.1844\n",
      "Epoch 587/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.1910 - combined_decoder_loss: 0.1904\n",
      "Epoch 588/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1842 - combined_decoder_loss: 0.1845\n",
      "Epoch 589/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.1823 - combined_decoder_loss: 0.1823\n",
      "Epoch 590/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1805 - combined_decoder_loss: 0.1802\n",
      "Epoch 591/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1813 - combined_decoder_loss: 0.1811\n",
      "Epoch 592/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1815 - combined_decoder_loss: 0.1821\n",
      "Epoch 593/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1190/1190 [==============================] - 1s 846us/sample - loss: 0.1841 - combined_decoder_loss: 0.1840\n",
      "Epoch 594/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1876 - combined_decoder_loss: 0.1875\n",
      "Epoch 595/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1822 - combined_decoder_loss: 0.1821\n",
      "Epoch 596/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1823 - combined_decoder_loss: 0.1827\n",
      "Epoch 597/3000\n",
      "1190/1190 [==============================] - 1s 849us/sample - loss: 0.1812 - combined_decoder_loss: 0.1814\n",
      "Epoch 598/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1812 - combined_decoder_loss: 0.1813\n",
      "Epoch 599/3000\n",
      "1190/1190 [==============================] - 1s 849us/sample - loss: 0.1842 - combined_decoder_loss: 0.1841\n",
      "Epoch 600/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1800 - combined_decoder_loss: 0.1795\n",
      "Epoch 601/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1826 - combined_decoder_loss: 0.1824\n",
      "Epoch 602/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1834 - combined_decoder_loss: 0.1833\n",
      "Epoch 603/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1833 - combined_decoder_loss: 0.1832\n",
      "Epoch 604/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1855 - combined_decoder_loss: 0.1855\n",
      "Epoch 605/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1832 - combined_decoder_loss: 0.1836\n",
      "Epoch 606/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.1799 - combined_decoder_loss: 0.1801\n",
      "Epoch 607/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1843 - combined_decoder_loss: 0.1838\n",
      "Epoch 608/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1822 - combined_decoder_loss: 0.1822\n",
      "Epoch 609/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.1841 - combined_decoder_loss: 0.1837\n",
      "Epoch 610/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1828 - combined_decoder_loss: 0.1828\n",
      "Epoch 611/3000\n",
      "1190/1190 [==============================] - 1s 856us/sample - loss: 0.1840 - combined_decoder_loss: 0.1839\n",
      "Epoch 612/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.1838 - combined_decoder_loss: 0.1846\n",
      "Epoch 613/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.1805 - combined_decoder_loss: 0.1802\n",
      "Epoch 614/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1811 - combined_decoder_loss: 0.1811\n",
      "Epoch 615/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1822 - combined_decoder_loss: 0.1817\n",
      "Epoch 616/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1799 - combined_decoder_loss: 0.1800\n",
      "Epoch 617/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1829 - combined_decoder_loss: 0.1828\n",
      "Epoch 618/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1838 - combined_decoder_loss: 0.1846\n",
      "Epoch 619/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.1798 - combined_decoder_loss: 0.1798\n",
      "Epoch 620/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1803 - combined_decoder_loss: 0.1806\n",
      "Epoch 621/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1814 - combined_decoder_loss: 0.1810\n",
      "Epoch 622/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1815 - combined_decoder_loss: 0.1816\n",
      "Epoch 623/3000\n",
      "1190/1190 [==============================] - 1s 858us/sample - loss: 0.1806 - combined_decoder_loss: 0.1804\n",
      "Epoch 624/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1860 - combined_decoder_loss: 0.1859\n",
      "Epoch 625/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1847 - combined_decoder_loss: 0.1844\n",
      "Epoch 626/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1808 - combined_decoder_loss: 0.1808\n",
      "Epoch 627/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1801 - combined_decoder_loss: 0.1800\n",
      "Epoch 628/3000\n",
      "1190/1190 [==============================] - 1s 846us/sample - loss: 0.1863 - combined_decoder_loss: 0.1861\n",
      "Epoch 629/3000\n",
      "1190/1190 [==============================] - 1s 848us/sample - loss: 0.1812 - combined_decoder_loss: 0.1812\n",
      "Epoch 630/3000\n",
      "1190/1190 [==============================] - 1s 872us/sample - loss: 0.1827 - combined_decoder_loss: 0.1823\n",
      "Epoch 631/3000\n",
      "1190/1190 [==============================] - 1s 872us/sample - loss: 0.1820 - combined_decoder_loss: 0.1818\n",
      "Epoch 632/3000\n",
      "1190/1190 [==============================] - 1s 855us/sample - loss: 0.1847 - combined_decoder_loss: 0.1844\n",
      "Epoch 633/3000\n",
      "1190/1190 [==============================] - 1s 848us/sample - loss: 0.1800 - combined_decoder_loss: 0.1805\n",
      "Epoch 634/3000\n",
      "1190/1190 [==============================] - 1s 862us/sample - loss: 0.1806 - combined_decoder_loss: 0.1806\n",
      "Epoch 635/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1852 - combined_decoder_loss: 0.1848\n",
      "Epoch 636/3000\n",
      "1190/1190 [==============================] - 1s 870us/sample - loss: 0.1823 - combined_decoder_loss: 0.1825\n",
      "Epoch 637/3000\n",
      "1190/1190 [==============================] - 1s 868us/sample - loss: 0.1821 - combined_decoder_loss: 0.1821\n",
      "Epoch 638/3000\n",
      "1190/1190 [==============================] - 1s 857us/sample - loss: 0.1829 - combined_decoder_loss: 0.1827\n",
      "Epoch 639/3000\n",
      "1190/1190 [==============================] - 1s 873us/sample - loss: 0.1814 - combined_decoder_loss: 0.1813\n",
      "Epoch 640/3000\n",
      "1190/1190 [==============================] - 1s 858us/sample - loss: 0.1837 - combined_decoder_loss: 0.1858\n",
      "Epoch 641/3000\n",
      "1190/1190 [==============================] - 1s 841us/sample - loss: 0.1901 - combined_decoder_loss: 0.1899\n",
      "Epoch 642/3000\n",
      "1190/1190 [==============================] - 1s 857us/sample - loss: 0.1824 - combined_decoder_loss: 0.1824\n",
      "Epoch 643/3000\n",
      "1190/1190 [==============================] - 1s 849us/sample - loss: 0.1820 - combined_decoder_loss: 0.1830\n",
      "Epoch 644/3000\n",
      "1190/1190 [==============================] - 1s 857us/sample - loss: 0.1877 - combined_decoder_loss: 0.1876\n",
      "Epoch 645/3000\n",
      "1190/1190 [==============================] - 1s 855us/sample - loss: 0.1805 - combined_decoder_loss: 0.1811\n",
      "Epoch 646/3000\n",
      "1190/1190 [==============================] - 1s 858us/sample - loss: 0.1871 - combined_decoder_loss: 0.1867\n",
      "Epoch 647/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1829 - combined_decoder_loss: 0.1833\n",
      "Epoch 648/3000\n",
      "1190/1190 [==============================] - 1s 701us/sample - loss: 0.1814 - combined_decoder_loss: 0.1814\n",
      "Epoch 649/3000\n",
      "1190/1190 [==============================] - 1s 798us/sample - loss: 0.1809 - combined_decoder_loss: 0.1808\n",
      "Epoch 650/3000\n",
      "1190/1190 [==============================] - 1s 852us/sample - loss: 0.1842 - combined_decoder_loss: 0.1844\n",
      "Epoch 651/3000\n",
      "1190/1190 [==============================] - 1s 844us/sample - loss: 0.1811 - combined_decoder_loss: 0.1814\n",
      "Epoch 652/3000\n",
      "1190/1190 [==============================] - 1s 843us/sample - loss: 0.1950 - combined_decoder_loss: 0.1954\n",
      "Epoch 653/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1882 - combined_decoder_loss: 0.1879\n",
      "Epoch 654/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1876 - combined_decoder_loss: 0.1876\n",
      "Epoch 655/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1816 - combined_decoder_loss: 0.1820\n",
      "Epoch 656/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1822 - combined_decoder_loss: 0.1826\n",
      "Epoch 657/3000\n",
      "1190/1190 [==============================] - 1s 864us/sample - loss: 0.1811 - combined_decoder_loss: 0.1818\n",
      "Epoch 658/3000\n",
      "1190/1190 [==============================] - 1s 861us/sample - loss: 0.1898 - combined_decoder_loss: 0.1894\n",
      "Epoch 659/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1818 - combined_decoder_loss: 0.1826\n",
      "Epoch 660/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1849 - combined_decoder_loss: 0.1853\n",
      "Epoch 661/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1847 - combined_decoder_loss: 0.1840\n",
      "Epoch 662/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1864 - combined_decoder_loss: 0.1859\n",
      "Epoch 663/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.1817 - combined_decoder_loss: 0.1817\n",
      "Epoch 664/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1823 - combined_decoder_loss: 0.1823\n",
      "Epoch 665/3000\n",
      "1190/1190 [==============================] - 1s 854us/sample - loss: 0.1811 - combined_decoder_loss: 0.1805\n",
      "Epoch 666/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1838 - combined_decoder_loss: 0.1834\n",
      "Epoch 667/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1802 - combined_decoder_loss: 0.1801\n",
      "Epoch 668/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1815 - combined_decoder_loss: 0.1817\n",
      "Epoch 669/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1819 - combined_decoder_loss: 0.1813\n",
      "Epoch 670/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1860 - combined_decoder_loss: 0.1865\n",
      "Epoch 671/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1816 - combined_decoder_loss: 0.1817\n",
      "Epoch 672/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.1803 - combined_decoder_loss: 0.1801\n",
      "Epoch 673/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.1805 - combined_decoder_loss: 0.1804\n",
      "Epoch 674/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1830 - combined_decoder_loss: 0.1831\n",
      "Epoch 675/3000\n",
      "1190/1190 [==============================] - 1s 849us/sample - loss: 0.1835 - combined_decoder_loss: 0.1836\n",
      "Epoch 676/3000\n",
      "1190/1190 [==============================] - 1s 846us/sample - loss: 0.1893 - combined_decoder_loss: 0.1891\n",
      "Epoch 677/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1803 - combined_decoder_loss: 0.1803\n",
      "Epoch 678/3000\n",
      "1190/1190 [==============================] - 1s 857us/sample - loss: 0.1821 - combined_decoder_loss: 0.1824\n",
      "Epoch 679/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1902 - combined_decoder_loss: 0.1900\n",
      "Epoch 680/3000\n",
      "1190/1190 [==============================] - 1s 871us/sample - loss: 0.1819 - combined_decoder_loss: 0.1817\n",
      "Epoch 681/3000\n",
      "1190/1190 [==============================] - 1s 873us/sample - loss: 0.1813 - combined_decoder_loss: 0.1813\n",
      "Epoch 682/3000\n",
      "1190/1190 [==============================] - 1s 915us/sample - loss: 0.1813 - combined_decoder_loss: 0.1812\n",
      "Epoch 683/3000\n",
      "1190/1190 [==============================] - 1s 863us/sample - loss: 0.1798 - combined_decoder_loss: 0.1797\n",
      "Epoch 684/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1805 - combined_decoder_loss: 0.1803\n",
      "Epoch 685/3000\n",
      "1190/1190 [==============================] - 1s 851us/sample - loss: 0.1896 - combined_decoder_loss: 0.1891\n",
      "Epoch 686/3000\n",
      "1190/1190 [==============================] - 1s 863us/sample - loss: 0.1900 - combined_decoder_loss: 0.1899\n",
      "Epoch 687/3000\n",
      "1190/1190 [==============================] - 1s 849us/sample - loss: 0.1820 - combined_decoder_loss: 0.1824\n",
      "Epoch 688/3000\n",
      "1190/1190 [==============================] - 1s 843us/sample - loss: 0.1820 - combined_decoder_loss: 0.1816\n",
      "Epoch 689/3000\n",
      "1190/1190 [==============================] - 1s 853us/sample - loss: 0.1826 - combined_decoder_loss: 0.1822\n",
      "Epoch 690/3000\n",
      "1190/1190 [==============================] - 1s 858us/sample - loss: 0.1794 - combined_decoder_loss: 0.1795\n",
      "Epoch 691/3000\n",
      "1190/1190 [==============================] - 1s 876us/sample - loss: 0.1812 - combined_decoder_loss: 0.1811\n",
      "Epoch 692/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1817 - combined_decoder_loss: 0.1815\n",
      "Epoch 693/3000\n",
      "1190/1190 [==============================] - 1s 850us/sample - loss: 0.1854 - combined_decoder_loss: 0.1850\n",
      "Epoch 694/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1843 - combined_decoder_loss: 0.1887\n",
      "Epoch 695/3000\n",
      "1190/1190 [==============================] - 1s 848us/sample - loss: 0.1861 - combined_decoder_loss: 0.1869\n",
      "Epoch 696/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1874 - combined_decoder_loss: 0.1872\n",
      "Epoch 697/3000\n",
      "1190/1190 [==============================] - 1s 846us/sample - loss: 0.1802 - combined_decoder_loss: 0.1803\n",
      "Epoch 698/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1813 - combined_decoder_loss: 0.1812\n",
      "Epoch 699/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1792 - combined_decoder_loss: 0.1792\n",
      "Epoch 700/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1826 - combined_decoder_loss: 0.1832\n",
      "Epoch 701/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1836 - combined_decoder_loss: 0.1837\n",
      "Epoch 702/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1823 - combined_decoder_loss: 0.1819\n",
      "Epoch 703/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1822 - combined_decoder_loss: 0.1821\n",
      "Epoch 704/3000\n",
      "1190/1190 [==============================] - 1s 836us/sample - loss: 0.1794 - combined_decoder_loss: 0.1792\n",
      "Epoch 705/3000\n",
      "1190/1190 [==============================] - 1s 834us/sample - loss: 0.1853 - combined_decoder_loss: 0.1848\n",
      "Epoch 706/3000\n",
      "1190/1190 [==============================] - 1s 846us/sample - loss: 0.1877 - combined_decoder_loss: 0.1877\n",
      "Epoch 707/3000\n",
      "1190/1190 [==============================] - 1s 831us/sample - loss: 0.1806 - combined_decoder_loss: 0.1808\n",
      "Epoch 708/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1797 - combined_decoder_loss: 0.1797\n",
      "Epoch 709/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1793 - combined_decoder_loss: 0.1792\n",
      "Epoch 710/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1824 - combined_decoder_loss: 0.1824\n",
      "Epoch 711/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1867 - combined_decoder_loss: 0.1867\n",
      "Epoch 712/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1801 - combined_decoder_loss: 0.1801\n",
      "Epoch 713/3000\n",
      "1190/1190 [==============================] - 1s 835us/sample - loss: 0.1845 - combined_decoder_loss: 0.1846\n",
      "Epoch 714/3000\n",
      "1190/1190 [==============================] - 1s 834us/sample - loss: 0.1798 - combined_decoder_loss: 0.1797\n",
      "Epoch 715/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1792 - combined_decoder_loss: 0.1793\n",
      "Epoch 716/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1803 - combined_decoder_loss: 0.1800\n",
      "Epoch 717/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1820 - combined_decoder_loss: 0.1818\n",
      "Epoch 718/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1840 - combined_decoder_loss: 0.1839\n",
      "Epoch 719/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1829 - combined_decoder_loss: 0.1826\n",
      "Epoch 720/3000\n",
      "1190/1190 [==============================] - 1s 842us/sample - loss: 0.1831 - combined_decoder_loss: 0.1833\n",
      "Epoch 721/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1821 - combined_decoder_loss: 0.1819\n",
      "Epoch 722/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1821 - combined_decoder_loss: 0.1831\n",
      "Epoch 723/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1813 - combined_decoder_loss: 0.1813\n",
      "Epoch 724/3000\n",
      "1190/1190 [==============================] - 1s 831us/sample - loss: 0.1818 - combined_decoder_loss: 0.1822\n",
      "Epoch 725/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1820 - combined_decoder_loss: 0.1823\n",
      "Epoch 726/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1808 - combined_decoder_loss: 0.1805\n",
      "Epoch 727/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1804 - combined_decoder_loss: 0.1808\n",
      "Epoch 728/3000\n",
      "1190/1190 [==============================] - 1s 841us/sample - loss: 0.1811 - combined_decoder_loss: 0.1813\n",
      "Epoch 729/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1802 - combined_decoder_loss: 0.1802\n",
      "Epoch 730/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1812 - combined_decoder_loss: 0.1809\n",
      "Epoch 731/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1808 - combined_decoder_loss: 0.1806\n",
      "Epoch 732/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1834 - combined_decoder_loss: 0.1831\n",
      "Epoch 733/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1817 - combined_decoder_loss: 0.1812\n",
      "Epoch 734/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1803 - combined_decoder_loss: 0.1808\n",
      "Epoch 735/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.1821 - combined_decoder_loss: 0.1823\n",
      "Epoch 736/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1820 - combined_decoder_loss: 0.1822\n",
      "Epoch 737/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1833 - combined_decoder_loss: 0.1832\n",
      "Epoch 738/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1791 - combined_decoder_loss: 0.1793\n",
      "Epoch 739/3000\n",
      "1190/1190 [==============================] - 1s 831us/sample - loss: 0.1828 - combined_decoder_loss: 0.1825\n",
      "Epoch 740/3000\n",
      "1190/1190 [==============================] - 1s 846us/sample - loss: 0.1798 - combined_decoder_loss: 0.1797\n",
      "Epoch 741/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1829 - combined_decoder_loss: 0.1827\n",
      "Epoch 742/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1803 - combined_decoder_loss: 0.1801\n",
      "Epoch 743/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1807 - combined_decoder_loss: 0.1806\n",
      "Epoch 744/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1826 - combined_decoder_loss: 0.1823\n",
      "Epoch 745/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1790 - combined_decoder_loss: 0.1790\n",
      "Epoch 746/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1804 - combined_decoder_loss: 0.1804\n",
      "Epoch 747/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1802 - combined_decoder_loss: 0.1804\n",
      "Epoch 748/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1810 - combined_decoder_loss: 0.1813\n",
      "Epoch 749/3000\n",
      "1190/1190 [==============================] - 1s 836us/sample - loss: 0.1814 - combined_decoder_loss: 0.1813\n",
      "Epoch 750/3000\n",
      "1190/1190 [==============================] - 1s 848us/sample - loss: 0.1803 - combined_decoder_loss: 0.1804\n",
      "Epoch 751/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1782 - combined_decoder_loss: 0.1780\n",
      "Epoch 752/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1832 - combined_decoder_loss: 0.1826\n",
      "Epoch 753/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1786 - combined_decoder_loss: 0.1786\n",
      "Epoch 754/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1806 - combined_decoder_loss: 0.1804\n",
      "Epoch 755/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1808 - combined_decoder_loss: 0.1808\n",
      "Epoch 756/3000\n",
      "1190/1190 [==============================] - 1s 831us/sample - loss: 0.1809 - combined_decoder_loss: 0.1810\n",
      "Epoch 757/3000\n",
      "1190/1190 [==============================] - 1s 843us/sample - loss: 0.1797 - combined_decoder_loss: 0.1800\n",
      "Epoch 758/3000\n",
      "1190/1190 [==============================] - 1s 834us/sample - loss: 0.1819 - combined_decoder_loss: 0.1817\n",
      "Epoch 759/3000\n",
      "1190/1190 [==============================] - 1s 846us/sample - loss: 0.1794 - combined_decoder_loss: 0.1794\n",
      "Epoch 760/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1845 - combined_decoder_loss: 0.1850\n",
      "Epoch 761/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1785 - combined_decoder_loss: 0.1783\n",
      "Epoch 762/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1825 - combined_decoder_loss: 0.1827\n",
      "Epoch 763/3000\n",
      "1190/1190 [==============================] - 1s 831us/sample - loss: 0.1813 - combined_decoder_loss: 0.1812\n",
      "Epoch 764/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1793 - combined_decoder_loss: 0.1793\n",
      "Epoch 765/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1801 - combined_decoder_loss: 0.1799\n",
      "Epoch 766/3000\n",
      "1190/1190 [==============================] - 1s 831us/sample - loss: 0.1817 - combined_decoder_loss: 0.1823\n",
      "Epoch 767/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1803 - combined_decoder_loss: 0.1802\n",
      "Epoch 768/3000\n",
      "1190/1190 [==============================] - 1s 842us/sample - loss: 0.1789 - combined_decoder_loss: 0.1792\n",
      "Epoch 769/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1820 - combined_decoder_loss: 0.1822\n",
      "Epoch 770/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1804 - combined_decoder_loss: 0.1805\n",
      "Epoch 771/3000\n",
      "1190/1190 [==============================] - 1s 846us/sample - loss: 0.1817 - combined_decoder_loss: 0.1821\n",
      "Epoch 772/3000\n",
      "1190/1190 [==============================] - 1s 854us/sample - loss: 0.1810 - combined_decoder_loss: 0.1811\n",
      "Epoch 773/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1850 - combined_decoder_loss: 0.1852\n",
      "Epoch 774/3000\n",
      "1190/1190 [==============================] - 1s 833us/sample - loss: 0.1795 - combined_decoder_loss: 0.1796\n",
      "Epoch 775/3000\n",
      "1190/1190 [==============================] - 1s 844us/sample - loss: 0.1795 - combined_decoder_loss: 0.1794\n",
      "Epoch 776/3000\n",
      "1190/1190 [==============================] - 1s 831us/sample - loss: 0.1805 - combined_decoder_loss: 0.1805\n",
      "Epoch 777/3000\n",
      "1190/1190 [==============================] - 1s 833us/sample - loss: 0.1810 - combined_decoder_loss: 0.1809\n",
      "Epoch 778/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1836 - combined_decoder_loss: 0.1831\n",
      "Epoch 779/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1785 - combined_decoder_loss: 0.1786\n",
      "Epoch 780/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1968 - combined_decoder_loss: 0.1962\n",
      "Epoch 781/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1814 - combined_decoder_loss: 0.1816\n",
      "Epoch 782/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1830 - combined_decoder_loss: 0.1827\n",
      "Epoch 783/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1882 - combined_decoder_loss: 0.1883\n",
      "Epoch 784/3000\n",
      "1190/1190 [==============================] - 1s 849us/sample - loss: 0.1855 - combined_decoder_loss: 0.1857\n",
      "Epoch 785/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1819 - combined_decoder_loss: 0.1820\n",
      "Epoch 786/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1846 - combined_decoder_loss: 0.1847\n",
      "Epoch 787/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1814 - combined_decoder_loss: 0.1810\n",
      "Epoch 788/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1795 - combined_decoder_loss: 0.1793\n",
      "Epoch 789/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1816 - combined_decoder_loss: 0.1812\n",
      "Epoch 790/3000\n",
      "1190/1190 [==============================] - 1s 846us/sample - loss: 0.1809 - combined_decoder_loss: 0.1813\n",
      "Epoch 791/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1797 - combined_decoder_loss: 0.1798\n",
      "Epoch 792/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1798 - combined_decoder_loss: 0.1796\n",
      "Epoch 793/3000\n",
      "1190/1190 [==============================] - 1s 836us/sample - loss: 0.1797 - combined_decoder_loss: 0.1794\n",
      "Epoch 794/3000\n",
      "1190/1190 [==============================] - 1s 826us/sample - loss: 0.1828 - combined_decoder_loss: 0.1833\n",
      "Epoch 795/3000\n",
      "1190/1190 [==============================] - 1s 822us/sample - loss: 0.1830 - combined_decoder_loss: 0.1831\n",
      "Epoch 796/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1805 - combined_decoder_loss: 0.1804\n",
      "Epoch 797/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1802 - combined_decoder_loss: 0.1801\n",
      "Epoch 798/3000\n",
      "1190/1190 [==============================] - 1s 831us/sample - loss: 0.1819 - combined_decoder_loss: 0.1820\n",
      "Epoch 799/3000\n",
      "1190/1190 [==============================] - 1s 831us/sample - loss: 0.1796 - combined_decoder_loss: 0.1793\n",
      "Epoch 800/3000\n",
      "1190/1190 [==============================] - 1s 824us/sample - loss: 0.1803 - combined_decoder_loss: 0.1802\n",
      "Epoch 801/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1794 - combined_decoder_loss: 0.1795\n",
      "Epoch 802/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1804 - combined_decoder_loss: 0.1802\n",
      "Epoch 803/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1806 - combined_decoder_loss: 0.1806\n",
      "Epoch 804/3000\n",
      "1190/1190 [==============================] - 1s 831us/sample - loss: 0.1807 - combined_decoder_loss: 0.1804\n",
      "Epoch 805/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1800 - combined_decoder_loss: 0.1799\n",
      "Epoch 806/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1822 - combined_decoder_loss: 0.1818\n",
      "Epoch 807/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1856 - combined_decoder_loss: 0.1854\n",
      "Epoch 808/3000\n",
      "1190/1190 [==============================] - 1s 831us/sample - loss: 0.1845 - combined_decoder_loss: 0.1838\n",
      "Epoch 809/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1863 - combined_decoder_loss: 0.1866\n",
      "Epoch 810/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1827 - combined_decoder_loss: 0.1825\n",
      "Epoch 811/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1846 - combined_decoder_loss: 0.1845\n",
      "Epoch 812/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1877 - combined_decoder_loss: 0.1880\n",
      "Epoch 813/3000\n",
      "1190/1190 [==============================] - 1s 831us/sample - loss: 0.1820 - combined_decoder_loss: 0.1816\n",
      "Epoch 814/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1799 - combined_decoder_loss: 0.1804\n",
      "Epoch 815/3000\n",
      "1190/1190 [==============================] - 1s 831us/sample - loss: 0.1804 - combined_decoder_loss: 0.1802\n",
      "Epoch 816/3000\n",
      "1190/1190 [==============================] - 1s 841us/sample - loss: 0.1814 - combined_decoder_loss: 0.1812\n",
      "Epoch 817/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1834 - combined_decoder_loss: 0.1836\n",
      "Epoch 818/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1808 - combined_decoder_loss: 0.1810\n",
      "Epoch 819/3000\n",
      "1190/1190 [==============================] - 1s 831us/sample - loss: 0.1775 - combined_decoder_loss: 0.1774\n",
      "Epoch 820/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1848 - combined_decoder_loss: 0.1846\n",
      "Epoch 821/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1803 - combined_decoder_loss: 0.1804\n",
      "Epoch 822/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1804 - combined_decoder_loss: 0.1813\n",
      "Epoch 823/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1853 - combined_decoder_loss: 0.1855\n",
      "Epoch 824/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1812 - combined_decoder_loss: 0.1806\n",
      "Epoch 825/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1862 - combined_decoder_loss: 0.1862\n",
      "Epoch 826/3000\n",
      "1190/1190 [==============================] - 1s 834us/sample - loss: 0.1862 - combined_decoder_loss: 0.1859\n",
      "Epoch 827/3000\n",
      "1190/1190 [==============================] - 1s 835us/sample - loss: 0.1866 - combined_decoder_loss: 0.1872\n",
      "Epoch 828/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1820 - combined_decoder_loss: 0.1818\n",
      "Epoch 829/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1813 - combined_decoder_loss: 0.1809\n",
      "Epoch 830/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1919 - combined_decoder_loss: 0.1918\n",
      "Epoch 831/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1845 - combined_decoder_loss: 0.1845\n",
      "Epoch 832/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1849 - combined_decoder_loss: 0.1846\n",
      "Epoch 833/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1857 - combined_decoder_loss: 0.1856\n",
      "Epoch 834/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1829 - combined_decoder_loss: 0.1828\n",
      "Epoch 835/3000\n",
      "1190/1190 [==============================] - 1s 831us/sample - loss: 0.1812 - combined_decoder_loss: 0.1809\n",
      "Epoch 836/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1791 - combined_decoder_loss: 0.1791\n",
      "Epoch 837/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1805 - combined_decoder_loss: 0.1809\n",
      "Epoch 838/3000\n",
      "1190/1190 [==============================] - 1s 831us/sample - loss: 0.1778 - combined_decoder_loss: 0.1777\n",
      "Epoch 839/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1824 - combined_decoder_loss: 0.1829\n",
      "Epoch 840/3000\n",
      "1190/1190 [==============================] - 1s 848us/sample - loss: 0.1816 - combined_decoder_loss: 0.1815\n",
      "Epoch 841/3000\n",
      "1190/1190 [==============================] - 1s 846us/sample - loss: 0.1788 - combined_decoder_loss: 0.1789\n",
      "Epoch 842/3000\n",
      "1190/1190 [==============================] - 1s 821us/sample - loss: 0.1818 - combined_decoder_loss: 0.1823\n",
      "Epoch 843/3000\n",
      "1190/1190 [==============================] - 1s 831us/sample - loss: 0.1854 - combined_decoder_loss: 0.1857\n",
      "Epoch 844/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1856 - combined_decoder_loss: 0.1905\n",
      "Epoch 845/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1828 - combined_decoder_loss: 0.1828\n",
      "Epoch 846/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1808 - combined_decoder_loss: 0.1808\n",
      "Epoch 847/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1842 - combined_decoder_loss: 0.1845\n",
      "Epoch 848/3000\n",
      "1190/1190 [==============================] - 1s 841us/sample - loss: 0.1895 - combined_decoder_loss: 0.1894\n",
      "Epoch 849/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1796 - combined_decoder_loss: 0.1792\n",
      "Epoch 850/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1792 - combined_decoder_loss: 0.1792\n",
      "Epoch 851/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1832 - combined_decoder_loss: 0.1830\n",
      "Epoch 852/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1900 - combined_decoder_loss: 0.1898\n",
      "Epoch 853/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1847 - combined_decoder_loss: 0.1844\n",
      "Epoch 854/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1907 - combined_decoder_loss: 0.1909\n",
      "Epoch 855/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1847 - combined_decoder_loss: 0.1847\n",
      "Epoch 856/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1831 - combined_decoder_loss: 0.1827\n",
      "Epoch 857/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1801 - combined_decoder_loss: 0.1800\n",
      "Epoch 858/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1797 - combined_decoder_loss: 0.1804\n",
      "Epoch 859/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1768 - combined_decoder_loss: 0.1772\n",
      "Epoch 860/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1810 - combined_decoder_loss: 0.1806\n",
      "Epoch 861/3000\n",
      "1190/1190 [==============================] - 1s 831us/sample - loss: 0.1800 - combined_decoder_loss: 0.1806\n",
      "Epoch 862/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1882 - combined_decoder_loss: 0.1881\n",
      "Epoch 863/3000\n",
      "1190/1190 [==============================] - 1s 841us/sample - loss: 0.1796 - combined_decoder_loss: 0.1789\n",
      "Epoch 864/3000\n",
      "1190/1190 [==============================] - 1s 836us/sample - loss: 0.1801 - combined_decoder_loss: 0.1801\n",
      "Epoch 865/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1804 - combined_decoder_loss: 0.1803\n",
      "Epoch 866/3000\n",
      "1190/1190 [==============================] - 1s 841us/sample - loss: 0.1795 - combined_decoder_loss: 0.1795\n",
      "Epoch 867/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1788 - combined_decoder_loss: 0.1792\n",
      "Epoch 868/3000\n",
      "1190/1190 [==============================] - 1s 848us/sample - loss: 0.1795 - combined_decoder_loss: 0.1798\n",
      "Epoch 869/3000\n",
      "1190/1190 [==============================] - 1s 848us/sample - loss: 0.1842 - combined_decoder_loss: 0.1841\n",
      "Epoch 870/3000\n",
      "1190/1190 [==============================] - 1s 846us/sample - loss: 0.1799 - combined_decoder_loss: 0.1799\n",
      "Epoch 871/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1827 - combined_decoder_loss: 0.1826\n",
      "Epoch 872/3000\n",
      "1190/1190 [==============================] - 1s 856us/sample - loss: 0.1811 - combined_decoder_loss: 0.1806\n",
      "Epoch 873/3000\n",
      "1190/1190 [==============================] - 1s 849us/sample - loss: 0.1873 - combined_decoder_loss: 0.1871\n",
      "Epoch 874/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1798 - combined_decoder_loss: 0.1800\n",
      "Epoch 875/3000\n",
      "1190/1190 [==============================] - 1s 841us/sample - loss: 0.1789 - combined_decoder_loss: 0.1786\n",
      "Epoch 876/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1803 - combined_decoder_loss: 0.1801\n",
      "Epoch 877/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1851 - combined_decoder_loss: 0.1852\n",
      "Epoch 878/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1870 - combined_decoder_loss: 0.1871\n",
      "Epoch 879/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1849 - combined_decoder_loss: 0.1849\n",
      "Epoch 880/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1835 - combined_decoder_loss: 0.1831\n",
      "Epoch 881/3000\n",
      "1190/1190 [==============================] - 1s 848us/sample - loss: 0.1796 - combined_decoder_loss: 0.1792\n",
      "Epoch 882/3000\n",
      "1190/1190 [==============================] - 1s 848us/sample - loss: 0.1794 - combined_decoder_loss: 0.1798\n",
      "Epoch 883/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1791 - combined_decoder_loss: 0.1789\n",
      "Epoch 884/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1813 - combined_decoder_loss: 0.1810\n",
      "Epoch 885/3000\n",
      "1190/1190 [==============================] - 1s 831us/sample - loss: 0.1790 - combined_decoder_loss: 0.1792\n",
      "Epoch 886/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1783 - combined_decoder_loss: 0.1786\n",
      "Epoch 887/3000\n",
      "1190/1190 [==============================] - 1s 831us/sample - loss: 0.1785 - combined_decoder_loss: 0.1783\n",
      "Epoch 888/3000\n",
      "1190/1190 [==============================] - 1s 829us/sample - loss: 0.1788 - combined_decoder_loss: 0.1789\n",
      "Epoch 889/3000\n",
      "1190/1190 [==============================] - 1s 848us/sample - loss: 0.1799 - combined_decoder_loss: 0.1800\n",
      "Epoch 890/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1820 - combined_decoder_loss: 0.1825\n",
      "Epoch 891/3000\n",
      "1190/1190 [==============================] - 1s 833us/sample - loss: 0.1868 - combined_decoder_loss: 0.1867\n",
      "Epoch 892/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1867 - combined_decoder_loss: 0.1868\n",
      "Epoch 893/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1824 - combined_decoder_loss: 0.1821\n",
      "Epoch 894/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1816 - combined_decoder_loss: 0.1814\n",
      "Epoch 895/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1841 - combined_decoder_loss: 0.1840\n",
      "Epoch 896/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1832 - combined_decoder_loss: 0.1831\n",
      "Epoch 897/3000\n",
      "1190/1190 [==============================] - 1s 841us/sample - loss: 0.1817 - combined_decoder_loss: 0.1815\n",
      "Epoch 898/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1819 - combined_decoder_loss: 0.1818\n",
      "Epoch 899/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1820 - combined_decoder_loss: 0.1823\n",
      "Epoch 900/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1799 - combined_decoder_loss: 0.1797\n",
      "Epoch 901/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1840 - combined_decoder_loss: 0.1835\n",
      "Epoch 902/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1805 - combined_decoder_loss: 0.1800\n",
      "Epoch 903/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1792 - combined_decoder_loss: 0.1790\n",
      "Epoch 904/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1801 - combined_decoder_loss: 0.1798\n",
      "Epoch 905/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1780 - combined_decoder_loss: 0.1784\n",
      "Epoch 906/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1780 - combined_decoder_loss: 0.1780\n",
      "Epoch 907/3000\n",
      "1190/1190 [==============================] - 1s 833us/sample - loss: 0.1781 - combined_decoder_loss: 0.1785\n",
      "Epoch 908/3000\n",
      "1190/1190 [==============================] - 1s 842us/sample - loss: 0.1801 - combined_decoder_loss: 0.1801\n",
      "Epoch 909/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1786 - combined_decoder_loss: 0.1787\n",
      "Epoch 910/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1810 - combined_decoder_loss: 0.1808\n",
      "Epoch 911/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1806 - combined_decoder_loss: 0.1807\n",
      "Epoch 912/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1797 - combined_decoder_loss: 0.1794\n",
      "Epoch 913/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1780 - combined_decoder_loss: 0.1780\n",
      "Epoch 914/3000\n",
      "1190/1190 [==============================] - 1s 846us/sample - loss: 0.1811 - combined_decoder_loss: 0.1806\n",
      "Epoch 915/3000\n",
      "1190/1190 [==============================] - 1s 846us/sample - loss: 0.1803 - combined_decoder_loss: 0.1809\n",
      "Epoch 916/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1778 - combined_decoder_loss: 0.1781\n",
      "Epoch 917/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1794 - combined_decoder_loss: 0.1794\n",
      "Epoch 918/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1807 - combined_decoder_loss: 0.1804\n",
      "Epoch 919/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1776 - combined_decoder_loss: 0.1776\n",
      "Epoch 920/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1768 - combined_decoder_loss: 0.1770\n",
      "Epoch 921/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1791 - combined_decoder_loss: 0.1792\n",
      "Epoch 922/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1794 - combined_decoder_loss: 0.1796\n",
      "Epoch 923/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1190/1190 [==============================] - 1s 848us/sample - loss: 0.1793 - combined_decoder_loss: 0.1792\n",
      "Epoch 924/3000\n",
      "1190/1190 [==============================] - 1s 848us/sample - loss: 0.1818 - combined_decoder_loss: 0.1817\n",
      "Epoch 925/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1825 - combined_decoder_loss: 0.1823\n",
      "Epoch 926/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1794 - combined_decoder_loss: 0.1793\n",
      "Epoch 927/3000\n",
      "1190/1190 [==============================] - 1s 846us/sample - loss: 0.1817 - combined_decoder_loss: 0.1816\n",
      "Epoch 928/3000\n",
      "1190/1190 [==============================] - 1s 851us/sample - loss: 0.1786 - combined_decoder_loss: 0.1786\n",
      "Epoch 929/3000\n",
      "1190/1190 [==============================] - 1s 841us/sample - loss: 0.1801 - combined_decoder_loss: 0.1803\n",
      "Epoch 930/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1818 - combined_decoder_loss: 0.1815\n",
      "Epoch 931/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1821 - combined_decoder_loss: 0.1823\n",
      "Epoch 932/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1816 - combined_decoder_loss: 0.1817\n",
      "Epoch 933/3000\n",
      "1190/1190 [==============================] - 1s 846us/sample - loss: 0.1801 - combined_decoder_loss: 0.1807\n",
      "Epoch 934/3000\n",
      "1190/1190 [==============================] - 1s 831us/sample - loss: 0.1839 - combined_decoder_loss: 0.1840\n",
      "Epoch 935/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1854 - combined_decoder_loss: 0.1849\n",
      "Epoch 936/3000\n",
      "1190/1190 [==============================] - 1s 848us/sample - loss: 0.1927 - combined_decoder_loss: 0.1923\n",
      "Epoch 937/3000\n",
      "1190/1190 [==============================] - 1s 843us/sample - loss: 0.1974 - combined_decoder_loss: 0.1971\n",
      "Epoch 938/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1947 - combined_decoder_loss: 0.1947\n",
      "Epoch 939/3000\n",
      "1190/1190 [==============================] - 1s 846us/sample - loss: 0.1848 - combined_decoder_loss: 0.1846\n",
      "Epoch 940/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1811 - combined_decoder_loss: 0.1810\n",
      "Epoch 941/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1855 - combined_decoder_loss: 0.1851\n",
      "Epoch 942/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1839 - combined_decoder_loss: 0.1846\n",
      "Epoch 943/3000\n",
      "1190/1190 [==============================] - 1s 816us/sample - loss: 0.1823 - combined_decoder_loss: 0.1819\n",
      "Epoch 944/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1790 - combined_decoder_loss: 0.1784\n",
      "Epoch 945/3000\n",
      "1190/1190 [==============================] - 1s 831us/sample - loss: 0.1829 - combined_decoder_loss: 0.1830\n",
      "Epoch 946/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1772 - combined_decoder_loss: 0.1770\n",
      "Epoch 947/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1787 - combined_decoder_loss: 0.1783\n",
      "Epoch 948/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1786 - combined_decoder_loss: 0.1782\n",
      "Epoch 949/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1789 - combined_decoder_loss: 0.1789\n",
      "Epoch 950/3000\n",
      "1190/1190 [==============================] - 1s 833us/sample - loss: 0.1818 - combined_decoder_loss: 0.1817\n",
      "Epoch 951/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1854 - combined_decoder_loss: 0.1859\n",
      "Epoch 952/3000\n",
      "1190/1190 [==============================] - 1s 848us/sample - loss: 0.1819 - combined_decoder_loss: 0.1819\n",
      "Epoch 953/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1796 - combined_decoder_loss: 0.1794\n",
      "Epoch 954/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1838 - combined_decoder_loss: 0.1838\n",
      "Epoch 955/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1835 - combined_decoder_loss: 0.1833\n",
      "Epoch 956/3000\n",
      "1190/1190 [==============================] - 1s 846us/sample - loss: 0.1810 - combined_decoder_loss: 0.1808\n",
      "Epoch 957/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1826 - combined_decoder_loss: 0.1824\n",
      "Epoch 958/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1837 - combined_decoder_loss: 0.1837\n",
      "Epoch 959/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1779 - combined_decoder_loss: 0.1777\n",
      "Epoch 960/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1814 - combined_decoder_loss: 0.1820\n",
      "Epoch 961/3000\n",
      "1190/1190 [==============================] - 1s 833us/sample - loss: 0.1798 - combined_decoder_loss: 0.1798\n",
      "Epoch 962/3000\n",
      "1190/1190 [==============================] - 1s 833us/sample - loss: 0.1796 - combined_decoder_loss: 0.1793\n",
      "Epoch 963/3000\n",
      "1190/1190 [==============================] - 1s 848us/sample - loss: 0.1784 - combined_decoder_loss: 0.1787\n",
      "Epoch 964/3000\n",
      "1190/1190 [==============================] - 1s 828us/sample - loss: 0.1793 - combined_decoder_loss: 0.1794\n",
      "Epoch 965/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1790 - combined_decoder_loss: 0.1793\n",
      "Epoch 966/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1790 - combined_decoder_loss: 0.1786\n",
      "Epoch 967/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1796 - combined_decoder_loss: 0.1792\n",
      "Epoch 968/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1787 - combined_decoder_loss: 0.1784\n",
      "Epoch 969/3000\n",
      "1190/1190 [==============================] - 1s 831us/sample - loss: 0.1795 - combined_decoder_loss: 0.1795\n",
      "Epoch 970/3000\n",
      "1190/1190 [==============================] - 1s 833us/sample - loss: 0.1775 - combined_decoder_loss: 0.1776\n",
      "Epoch 971/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1829 - combined_decoder_loss: 0.1833\n",
      "Epoch 972/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1800 - combined_decoder_loss: 0.1800\n",
      "Epoch 973/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1782 - combined_decoder_loss: 0.1783\n",
      "Epoch 974/3000\n",
      "1190/1190 [==============================] - 1s 831us/sample - loss: 0.1849 - combined_decoder_loss: 0.1851\n",
      "Epoch 975/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1795 - combined_decoder_loss: 0.1795\n",
      "Epoch 976/3000\n",
      "1190/1190 [==============================] - 1s 848us/sample - loss: 0.1820 - combined_decoder_loss: 0.1825\n",
      "Epoch 977/3000\n",
      "1190/1190 [==============================] - 1s 831us/sample - loss: 0.1832 - combined_decoder_loss: 0.1857\n",
      "Epoch 978/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1821 - combined_decoder_loss: 0.1817\n",
      "Epoch 979/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1858 - combined_decoder_loss: 0.1859\n",
      "Epoch 980/3000\n",
      "1190/1190 [==============================] - 1s 848us/sample - loss: 0.1816 - combined_decoder_loss: 0.1812\n",
      "Epoch 981/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1785 - combined_decoder_loss: 0.1781\n",
      "Epoch 982/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.1833 - combined_decoder_loss: 0.1832\n",
      "Epoch 983/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1838 - combined_decoder_loss: 0.1832\n",
      "Epoch 984/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1799 - combined_decoder_loss: 0.1800\n",
      "Epoch 985/3000\n",
      "1190/1190 [==============================] - 1s 831us/sample - loss: 0.1829 - combined_decoder_loss: 0.1829\n",
      "Epoch 986/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1881 - combined_decoder_loss: 0.1877\n",
      "Epoch 987/3000\n",
      "1190/1190 [==============================] - 1s 831us/sample - loss: 0.1908 - combined_decoder_loss: 0.1904\n",
      "Epoch 988/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1839 - combined_decoder_loss: 0.1838\n",
      "Epoch 989/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1190/1190 [==============================] - 1s 831us/sample - loss: 0.1837 - combined_decoder_loss: 0.1839\n",
      "Epoch 990/3000\n",
      "1190/1190 [==============================] - 1s 835us/sample - loss: 0.1864 - combined_decoder_loss: 0.1871\n",
      "Epoch 991/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1953 - combined_decoder_loss: 0.1948\n",
      "Epoch 992/3000\n",
      "1190/1190 [==============================] - 1s 833us/sample - loss: 0.1948 - combined_decoder_loss: 0.1947\n",
      "Epoch 993/3000\n",
      "1190/1190 [==============================] - 1s 834us/sample - loss: 0.1868 - combined_decoder_loss: 0.1871\n",
      "Epoch 994/3000\n",
      "1190/1190 [==============================] - 1s 850us/sample - loss: 0.1834 - combined_decoder_loss: 0.1832\n",
      "Epoch 995/3000\n",
      "1190/1190 [==============================] - 1s 848us/sample - loss: 0.1843 - combined_decoder_loss: 0.1841\n",
      "Epoch 996/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1848 - combined_decoder_loss: 0.1853\n",
      "Epoch 997/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1887 - combined_decoder_loss: 0.1889\n",
      "Epoch 998/3000\n",
      "1190/1190 [==============================] - 1s 842us/sample - loss: 0.1852 - combined_decoder_loss: 0.1850\n",
      "Epoch 999/3000\n",
      "1190/1190 [==============================] - 1s 835us/sample - loss: 0.1816 - combined_decoder_loss: 0.1812\n",
      "Epoch 1000/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1807 - combined_decoder_loss: 0.1804\n",
      "Epoch 1001/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1791 - combined_decoder_loss: 0.1790\n",
      "Epoch 1002/3000\n",
      "1190/1190 [==============================] - 1s 823us/sample - loss: 0.1826 - combined_decoder_loss: 0.1825\n",
      "Epoch 1003/3000\n",
      "1190/1190 [==============================] - 1s 824us/sample - loss: 0.1830 - combined_decoder_loss: 0.1837\n",
      "Epoch 1004/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1835 - combined_decoder_loss: 0.1839\n",
      "Epoch 1005/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1915 - combined_decoder_loss: 0.1920\n",
      "Epoch 1006/3000\n",
      "1190/1190 [==============================] - 1s 835us/sample - loss: 0.1844 - combined_decoder_loss: 0.1840\n",
      "Epoch 1007/3000\n",
      "1190/1190 [==============================] - 1s 818us/sample - loss: 0.1825 - combined_decoder_loss: 0.1826\n",
      "Epoch 1008/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1841 - combined_decoder_loss: 0.1842\n",
      "Epoch 1009/3000\n",
      "1190/1190 [==============================] - 1s 831us/sample - loss: 0.1876 - combined_decoder_loss: 0.1875\n",
      "Epoch 1010/3000\n",
      "1190/1190 [==============================] - 1s 823us/sample - loss: 0.1816 - combined_decoder_loss: 0.1818\n",
      "Epoch 1011/3000\n",
      "1190/1190 [==============================] - 1s 825us/sample - loss: 0.1831 - combined_decoder_loss: 0.1831\n",
      "Epoch 1012/3000\n",
      "1190/1190 [==============================] - 1s 824us/sample - loss: 0.1805 - combined_decoder_loss: 0.1804\n",
      "Epoch 1013/3000\n",
      "1190/1190 [==============================] - 1s 836us/sample - loss: 0.1811 - combined_decoder_loss: 0.1811\n",
      "Epoch 1014/3000\n",
      "1190/1190 [==============================] - 1s 824us/sample - loss: 0.1844 - combined_decoder_loss: 0.1848\n",
      "Epoch 1015/3000\n",
      "1190/1190 [==============================] - 1s 825us/sample - loss: 0.1792 - combined_decoder_loss: 0.1791\n",
      "Epoch 1016/3000\n",
      "1190/1190 [==============================] - 1s 824us/sample - loss: 0.1799 - combined_decoder_loss: 0.1801\n",
      "Epoch 1017/3000\n",
      "1190/1190 [==============================] - 1s 831us/sample - loss: 0.1805 - combined_decoder_loss: 0.1813\n",
      "Epoch 1018/3000\n",
      "1190/1190 [==============================] - 1s 829us/sample - loss: 0.1795 - combined_decoder_loss: 0.1793\n",
      "Epoch 1019/3000\n",
      "1190/1190 [==============================] - 1s 823us/sample - loss: 0.1790 - combined_decoder_loss: 0.1787\n",
      "Epoch 1020/3000\n",
      "1190/1190 [==============================] - 1s 825us/sample - loss: 0.1810 - combined_decoder_loss: 0.1812\n",
      "Epoch 1021/3000\n",
      "1190/1190 [==============================] - 1s 825us/sample - loss: 0.1805 - combined_decoder_loss: 0.1811\n",
      "Epoch 1022/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1807 - combined_decoder_loss: 0.1811\n",
      "Epoch 1023/3000\n",
      "1190/1190 [==============================] - 1s 831us/sample - loss: 0.1831 - combined_decoder_loss: 0.1829\n",
      "Epoch 1024/3000\n",
      "1190/1190 [==============================] - 1s 831us/sample - loss: 0.1939 - combined_decoder_loss: 0.1935\n",
      "Epoch 1025/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1889 - combined_decoder_loss: 0.1886\n",
      "Epoch 1026/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1925 - combined_decoder_loss: 0.1921\n",
      "Epoch 1027/3000\n",
      "1190/1190 [==============================] - 1s 823us/sample - loss: 0.1830 - combined_decoder_loss: 0.1826\n",
      "Epoch 1028/3000\n",
      "1190/1190 [==============================] - 1s 836us/sample - loss: 0.1848 - combined_decoder_loss: 0.1846\n",
      "Epoch 1029/3000\n",
      "1190/1190 [==============================] - 1s 824us/sample - loss: 0.1869 - combined_decoder_loss: 0.1868\n",
      "Epoch 1030/3000\n",
      "1190/1190 [==============================] - 1s 831us/sample - loss: 0.1950 - combined_decoder_loss: 0.1962\n",
      "Epoch 1031/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1947 - combined_decoder_loss: 0.1940\n",
      "Epoch 1032/3000\n",
      "1190/1190 [==============================] - 1s 824us/sample - loss: 0.1857 - combined_decoder_loss: 0.1860\n",
      "Epoch 1033/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1808 - combined_decoder_loss: 0.1810\n",
      "Epoch 1034/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1794 - combined_decoder_loss: 0.1803\n",
      "Epoch 1035/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1836 - combined_decoder_loss: 0.1832\n",
      "Epoch 1036/3000\n",
      "1190/1190 [==============================] - 1s 824us/sample - loss: 0.1809 - combined_decoder_loss: 0.1815\n",
      "Epoch 1037/3000\n",
      "1190/1190 [==============================] - 1s 825us/sample - loss: 0.1802 - combined_decoder_loss: 0.1798\n",
      "Epoch 1038/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1831 - combined_decoder_loss: 0.1832\n",
      "Epoch 1039/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1810 - combined_decoder_loss: 0.1812\n",
      "Epoch 1040/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1931 - combined_decoder_loss: 0.1934\n",
      "Epoch 1041/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1869 - combined_decoder_loss: 0.1869\n",
      "Epoch 1042/3000\n",
      "1190/1190 [==============================] - 1s 823us/sample - loss: 0.1827 - combined_decoder_loss: 0.1826\n",
      "Epoch 1043/3000\n",
      "1190/1190 [==============================] - 1s 825us/sample - loss: 0.1831 - combined_decoder_loss: 0.1832\n",
      "Epoch 1044/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1823 - combined_decoder_loss: 0.1827\n",
      "Epoch 1045/3000\n",
      "1190/1190 [==============================] - 1s 822us/sample - loss: 0.1796 - combined_decoder_loss: 0.1796\n",
      "Epoch 1046/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1800 - combined_decoder_loss: 0.1797\n",
      "Epoch 1047/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1798 - combined_decoder_loss: 0.1794\n",
      "Epoch 1048/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1803 - combined_decoder_loss: 0.1810\n",
      "Epoch 1049/3000\n",
      "1190/1190 [==============================] - 1s 815us/sample - loss: 0.1783 - combined_decoder_loss: 0.1787\n",
      "Epoch 1050/3000\n",
      "1190/1190 [==============================] - 1s 833us/sample - loss: 0.1794 - combined_decoder_loss: 0.1795\n",
      "Epoch 1051/3000\n",
      "1190/1190 [==============================] - 1s 828us/sample - loss: 0.1832 - combined_decoder_loss: 0.1829\n",
      "Epoch 1052/3000\n",
      "1190/1190 [==============================] - 1s 825us/sample - loss: 0.1800 - combined_decoder_loss: 0.1801\n",
      "Epoch 1053/3000\n",
      "1190/1190 [==============================] - 1s 834us/sample - loss: 0.1795 - combined_decoder_loss: 0.1799\n",
      "Epoch 1054/3000\n",
      "1190/1190 [==============================] - 1s 834us/sample - loss: 0.1812 - combined_decoder_loss: 0.1809\n",
      "Epoch 1055/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1810 - combined_decoder_loss: 0.1813\n",
      "Epoch 1056/3000\n",
      "1190/1190 [==============================] - 1s 831us/sample - loss: 0.1794 - combined_decoder_loss: 0.1789\n",
      "Epoch 1057/3000\n",
      "1190/1190 [==============================] - 1s 823us/sample - loss: 0.1890 - combined_decoder_loss: 0.1894\n",
      "Epoch 1058/3000\n",
      "1190/1190 [==============================] - 1s 833us/sample - loss: 0.1812 - combined_decoder_loss: 0.1810\n",
      "Epoch 1059/3000\n",
      "1190/1190 [==============================] - 1s 820us/sample - loss: 0.1821 - combined_decoder_loss: 0.1815\n",
      "Epoch 1060/3000\n",
      "1190/1190 [==============================] - 1s 825us/sample - loss: 0.1836 - combined_decoder_loss: 0.1837\n",
      "Epoch 1061/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1832 - combined_decoder_loss: 0.1834\n",
      "Epoch 1062/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1830 - combined_decoder_loss: 0.1829\n",
      "Epoch 1063/3000\n",
      "1190/1190 [==============================] - 1s 833us/sample - loss: 0.1849 - combined_decoder_loss: 0.1847\n",
      "Epoch 1064/3000\n",
      "1190/1190 [==============================] - 1s 831us/sample - loss: 0.1830 - combined_decoder_loss: 0.1833\n",
      "Epoch 1065/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1816 - combined_decoder_loss: 0.1816\n",
      "Epoch 1066/3000\n",
      "1190/1190 [==============================] - 1s 823us/sample - loss: 0.1821 - combined_decoder_loss: 0.1823\n",
      "Epoch 1067/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1801 - combined_decoder_loss: 0.1799\n",
      "Epoch 1068/3000\n",
      "1190/1190 [==============================] - 1s 828us/sample - loss: 0.1809 - combined_decoder_loss: 0.1815\n",
      "Epoch 1069/3000\n",
      "1190/1190 [==============================] - 1s 833us/sample - loss: 0.1816 - combined_decoder_loss: 0.1811\n",
      "Epoch 1070/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1843 - combined_decoder_loss: 0.1839\n",
      "Epoch 1071/3000\n",
      "1190/1190 [==============================] - 1s 827us/sample - loss: 0.1815 - combined_decoder_loss: 0.1817\n",
      "Epoch 1072/3000\n",
      "1190/1190 [==============================] - 1s 829us/sample - loss: 0.1851 - combined_decoder_loss: 0.1850\n",
      "Epoch 1073/3000\n",
      "1190/1190 [==============================] - 1s 828us/sample - loss: 0.1857 - combined_decoder_loss: 0.1856\n",
      "Epoch 1074/3000\n",
      "1190/1190 [==============================] - 1s 831us/sample - loss: 0.1873 - combined_decoder_loss: 0.1872\n",
      "Epoch 1075/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.2001 - combined_decoder_loss: 0.1995\n",
      "Epoch 1076/3000\n",
      "1190/1190 [==============================] - 1s 829us/sample - loss: 0.1970 - combined_decoder_loss: 0.1969\n",
      "Epoch 1077/3000\n",
      "1190/1190 [==============================] - 1s 827us/sample - loss: 0.1870 - combined_decoder_loss: 0.1869\n",
      "Epoch 1078/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1822 - combined_decoder_loss: 0.1823\n",
      "Epoch 1079/3000\n",
      "1190/1190 [==============================] - 1s 833us/sample - loss: 0.1824 - combined_decoder_loss: 0.1820\n",
      "Epoch 1080/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1835 - combined_decoder_loss: 0.1836\n",
      "Epoch 1081/3000\n",
      "1190/1190 [==============================] - 1s 826us/sample - loss: 0.1826 - combined_decoder_loss: 0.1844\n",
      "Epoch 1082/3000\n",
      "1190/1190 [==============================] - 1s 826us/sample - loss: 0.1842 - combined_decoder_loss: 0.1839\n",
      "Epoch 1083/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1816 - combined_decoder_loss: 0.1817\n",
      "Epoch 1084/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1822 - combined_decoder_loss: 0.1823\n",
      "Epoch 1085/3000\n",
      "1190/1190 [==============================] - 1s 827us/sample - loss: 0.1819 - combined_decoder_loss: 0.1819\n",
      "Epoch 1086/3000\n",
      "1190/1190 [==============================] - 1s 829us/sample - loss: 0.1817 - combined_decoder_loss: 0.1818\n",
      "Epoch 1087/3000\n",
      "1190/1190 [==============================] - 1s 834us/sample - loss: 0.1828 - combined_decoder_loss: 0.1825\n",
      "Epoch 1088/3000\n",
      "1190/1190 [==============================] - 1s 827us/sample - loss: 0.1845 - combined_decoder_loss: 0.1840\n",
      "Epoch 1089/3000\n",
      "1190/1190 [==============================] - 1s 828us/sample - loss: 0.1829 - combined_decoder_loss: 0.1829\n",
      "Epoch 1090/3000\n",
      "1190/1190 [==============================] - 1s 836us/sample - loss: 0.1820 - combined_decoder_loss: 0.1823\n",
      "Epoch 1091/3000\n",
      "1190/1190 [==============================] - 1s 825us/sample - loss: 0.1831 - combined_decoder_loss: 0.1842\n",
      "Epoch 1092/3000\n",
      "1190/1190 [==============================] - 1s 824us/sample - loss: 0.1816 - combined_decoder_loss: 0.1809\n",
      "Epoch 1093/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1971 - combined_decoder_loss: 0.1968\n",
      "Epoch 1094/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1848 - combined_decoder_loss: 0.1850\n",
      "Epoch 1095/3000\n",
      "1190/1190 [==============================] - 1s 831us/sample - loss: 0.2047 - combined_decoder_loss: 0.2040\n",
      "Epoch 1096/3000\n",
      "1190/1190 [==============================] - 1s 825us/sample - loss: 0.1860 - combined_decoder_loss: 0.1861\n",
      "Epoch 1097/3000\n",
      "1190/1190 [==============================] - 1s 824us/sample - loss: 0.1839 - combined_decoder_loss: 0.1840\n",
      "Epoch 1098/3000\n",
      "1190/1190 [==============================] - 1s 824us/sample - loss: 0.1804 - combined_decoder_loss: 0.1806\n",
      "Epoch 1099/3000\n",
      "1190/1190 [==============================] - 1s 825us/sample - loss: 0.1839 - combined_decoder_loss: 0.1838\n",
      "Epoch 1100/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1825 - combined_decoder_loss: 0.1828\n",
      "Epoch 1101/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1897 - combined_decoder_loss: 0.1899\n",
      "Epoch 1102/3000\n",
      "1190/1190 [==============================] - 1s 824us/sample - loss: 0.1889 - combined_decoder_loss: 0.1899\n",
      "Epoch 1103/3000\n",
      "1190/1190 [==============================] - 1s 836us/sample - loss: 0.1934 - combined_decoder_loss: 0.1939\n",
      "Epoch 1104/3000\n",
      "1190/1190 [==============================] - 1s 834us/sample - loss: 0.2076 - combined_decoder_loss: 0.2072\n",
      "Epoch 1105/3000\n",
      "1190/1190 [==============================] - 1s 823us/sample - loss: 0.2045 - combined_decoder_loss: 0.2039\n",
      "Epoch 1106/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.2026 - combined_decoder_loss: 0.2023\n",
      "Epoch 1107/3000\n",
      "1190/1190 [==============================] - 1s 822us/sample - loss: 0.2049 - combined_decoder_loss: 0.2044\n",
      "Epoch 1108/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.2044 - combined_decoder_loss: 0.2040\n",
      "Epoch 1109/3000\n",
      "1190/1190 [==============================] - 1s 823us/sample - loss: 0.2011 - combined_decoder_loss: 0.2007\n",
      "Epoch 1110/3000\n",
      "1190/1190 [==============================] - 1s 825us/sample - loss: 0.1998 - combined_decoder_loss: 0.1999\n",
      "Epoch 1111/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1987 - combined_decoder_loss: 0.1985\n",
      "Epoch 1112/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1989 - combined_decoder_loss: 0.1989\n",
      "Epoch 1113/3000\n",
      "1190/1190 [==============================] - 1s 826us/sample - loss: 0.1981 - combined_decoder_loss: 0.1975\n",
      "Epoch 1114/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1963 - combined_decoder_loss: 0.1964\n",
      "Epoch 1115/3000\n",
      "1190/1190 [==============================] - 1s 825us/sample - loss: 0.1981 - combined_decoder_loss: 0.1978\n",
      "Epoch 1116/3000\n",
      "1190/1190 [==============================] - 1s 831us/sample - loss: 0.1976 - combined_decoder_loss: 0.1977\n",
      "Epoch 1117/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1955 - combined_decoder_loss: 0.1955\n",
      "Epoch 1118/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1961 - combined_decoder_loss: 0.1962\n",
      "Epoch 1119/3000\n",
      "1190/1190 [==============================] - 1s 831us/sample - loss: 0.1948 - combined_decoder_loss: 0.1947\n",
      "Epoch 1120/3000\n",
      "1190/1190 [==============================] - 1s 815us/sample - loss: 0.1940 - combined_decoder_loss: 0.1937\n",
      "Epoch 1121/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1190/1190 [==============================] - 1s 825us/sample - loss: 0.1949 - combined_decoder_loss: 0.1944\n",
      "Epoch 1122/3000\n",
      "1190/1190 [==============================] - 1s 831us/sample - loss: 0.1938 - combined_decoder_loss: 0.1935\n",
      "Epoch 1123/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1945 - combined_decoder_loss: 0.1942\n",
      "Epoch 1124/3000\n",
      "1190/1190 [==============================] - 1s 831us/sample - loss: 0.1925 - combined_decoder_loss: 0.1923\n",
      "Epoch 1125/3000\n",
      "1190/1190 [==============================] - 1s 831us/sample - loss: 0.1953 - combined_decoder_loss: 0.1951\n",
      "Epoch 1126/3000\n",
      "1190/1190 [==============================] - 1s 823us/sample - loss: 0.1940 - combined_decoder_loss: 0.1939\n",
      "Epoch 1127/3000\n",
      "1190/1190 [==============================] - 1s 831us/sample - loss: 0.1960 - combined_decoder_loss: 0.1958\n",
      "Epoch 1128/3000\n",
      "1190/1190 [==============================] - 1s 827us/sample - loss: 0.1923 - combined_decoder_loss: 0.1919\n",
      "Epoch 1129/3000\n",
      "1190/1190 [==============================] - 1s 825us/sample - loss: 0.1926 - combined_decoder_loss: 0.1926\n",
      "Epoch 1130/3000\n",
      "1190/1190 [==============================] - 1s 831us/sample - loss: 0.1915 - combined_decoder_loss: 0.1917\n",
      "Epoch 1131/3000\n",
      "1190/1190 [==============================] - 1s 829us/sample - loss: 0.1899 - combined_decoder_loss: 0.1901\n",
      "Epoch 1132/3000\n",
      "1190/1190 [==============================] - 1s 822us/sample - loss: 0.1930 - combined_decoder_loss: 0.1934\n",
      "Epoch 1133/3000\n",
      "1190/1190 [==============================] - 1s 833us/sample - loss: 0.1923 - combined_decoder_loss: 0.1928\n",
      "Epoch 1134/3000\n",
      "1190/1190 [==============================] - 1s 826us/sample - loss: 0.1924 - combined_decoder_loss: 0.1919\n",
      "Epoch 1135/3000\n",
      "1190/1190 [==============================] - 1s 831us/sample - loss: 0.1920 - combined_decoder_loss: 0.1915\n",
      "Epoch 1136/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1926 - combined_decoder_loss: 0.1927\n",
      "Epoch 1137/3000\n",
      "1190/1190 [==============================] - 1s 823us/sample - loss: 0.1898 - combined_decoder_loss: 0.1905\n",
      "Epoch 1138/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1913 - combined_decoder_loss: 0.1916\n",
      "Epoch 1139/3000\n",
      "1190/1190 [==============================] - 1s 823us/sample - loss: 0.1928 - combined_decoder_loss: 0.1930\n",
      "Epoch 1140/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1895 - combined_decoder_loss: 0.1899\n",
      "Epoch 1141/3000\n",
      "1190/1190 [==============================] - 1s 823us/sample - loss: 0.1916 - combined_decoder_loss: 0.1911\n",
      "Epoch 1142/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1915 - combined_decoder_loss: 0.1917\n",
      "Epoch 1143/3000\n",
      "1190/1190 [==============================] - 1s 824us/sample - loss: 0.1899 - combined_decoder_loss: 0.1901\n",
      "Epoch 1144/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1905 - combined_decoder_loss: 0.1902\n",
      "Epoch 1145/3000\n",
      "1190/1190 [==============================] - 1s 824us/sample - loss: 0.1891 - combined_decoder_loss: 0.1885\n",
      "Epoch 1146/3000\n",
      "1190/1190 [==============================] - 1s 825us/sample - loss: 0.1888 - combined_decoder_loss: 0.1888\n",
      "Epoch 1147/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1898 - combined_decoder_loss: 0.1896\n",
      "Epoch 1148/3000\n",
      "1190/1190 [==============================] - 1s 836us/sample - loss: 0.1900 - combined_decoder_loss: 0.1897\n",
      "Epoch 1149/3000\n",
      "1190/1190 [==============================] - 1s 826us/sample - loss: 0.1907 - combined_decoder_loss: 0.1908\n",
      "Epoch 1150/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1902 - combined_decoder_loss: 0.1900\n",
      "Epoch 1151/3000\n",
      "1190/1190 [==============================] - 1s 825us/sample - loss: 0.1893 - combined_decoder_loss: 0.1890\n",
      "Epoch 1152/3000\n",
      "1190/1190 [==============================] - 1s 823us/sample - loss: 0.1865 - combined_decoder_loss: 0.1861\n",
      "Epoch 1153/3000\n",
      "1190/1190 [==============================] - 1s 823us/sample - loss: 0.1891 - combined_decoder_loss: 0.1893\n",
      "Epoch 1154/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1901 - combined_decoder_loss: 0.1898\n",
      "Epoch 1155/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1869 - combined_decoder_loss: 0.1869\n",
      "Epoch 1156/3000\n",
      "1190/1190 [==============================] - 1s 831us/sample - loss: 0.1869 - combined_decoder_loss: 0.1865\n",
      "Epoch 1157/3000\n",
      "1190/1190 [==============================] - 1s 823us/sample - loss: 0.1879 - combined_decoder_loss: 0.1877\n",
      "Epoch 1158/3000\n",
      "1190/1190 [==============================] - 1s 826us/sample - loss: 0.1881 - combined_decoder_loss: 0.1880\n",
      "Epoch 1159/3000\n",
      "1190/1190 [==============================] - 1s 825us/sample - loss: 0.1887 - combined_decoder_loss: 0.1885\n",
      "Epoch 1160/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1877 - combined_decoder_loss: 0.1878\n",
      "Epoch 1161/3000\n",
      "1190/1190 [==============================] - 1s 831us/sample - loss: 0.1856 - combined_decoder_loss: 0.1856\n",
      "Epoch 1162/3000\n",
      "1190/1190 [==============================] - 1s 829us/sample - loss: 0.1880 - combined_decoder_loss: 0.1895\n",
      "Epoch 1163/3000\n",
      "1190/1190 [==============================] - 1s 831us/sample - loss: 0.1846 - combined_decoder_loss: 0.1850\n",
      "Epoch 1164/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1876 - combined_decoder_loss: 0.1877\n",
      "Epoch 1165/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1870 - combined_decoder_loss: 0.1869\n",
      "Epoch 1166/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1880 - combined_decoder_loss: 0.1879\n",
      "Epoch 1167/3000\n",
      "1190/1190 [==============================] - 1s 831us/sample - loss: 0.1892 - combined_decoder_loss: 0.1898\n",
      "Epoch 1168/3000\n",
      "1190/1190 [==============================] - 1s 823us/sample - loss: 0.1877 - combined_decoder_loss: 0.1878\n",
      "Epoch 1169/3000\n",
      "1190/1190 [==============================] - 1s 829us/sample - loss: 0.1878 - combined_decoder_loss: 0.1873\n",
      "Epoch 1170/3000\n",
      "1190/1190 [==============================] - 1s 824us/sample - loss: 0.1853 - combined_decoder_loss: 0.1854\n",
      "Epoch 1171/3000\n",
      "1190/1190 [==============================] - 1s 827us/sample - loss: 0.1864 - combined_decoder_loss: 0.1861\n",
      "Epoch 1172/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1887 - combined_decoder_loss: 0.1888\n",
      "Epoch 1173/3000\n",
      "1190/1190 [==============================] - 1s 822us/sample - loss: 0.1840 - combined_decoder_loss: 0.1838\n",
      "Epoch 1174/3000\n",
      "1190/1190 [==============================] - 1s 826us/sample - loss: 0.1877 - combined_decoder_loss: 0.1878\n",
      "Epoch 1175/3000\n",
      "1190/1190 [==============================] - 1s 827us/sample - loss: 0.1880 - combined_decoder_loss: 0.1879\n",
      "Epoch 1176/3000\n",
      "1190/1190 [==============================] - 1s 829us/sample - loss: 0.1855 - combined_decoder_loss: 0.1852\n",
      "Epoch 1177/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1865 - combined_decoder_loss: 0.1858\n",
      "Epoch 1178/3000\n",
      "1190/1190 [==============================] - 1s 821us/sample - loss: 0.1858 - combined_decoder_loss: 0.1859\n",
      "Epoch 1179/3000\n",
      "1190/1190 [==============================] - 1s 831us/sample - loss: 0.1844 - combined_decoder_loss: 0.1841\n",
      "Epoch 1180/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1854 - combined_decoder_loss: 0.1851\n",
      "Epoch 1181/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1883 - combined_decoder_loss: 0.1883\n",
      "Epoch 1182/3000\n",
      "1190/1190 [==============================] - 1s 831us/sample - loss: 0.1893 - combined_decoder_loss: 0.1891\n",
      "Epoch 1183/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1892 - combined_decoder_loss: 0.1892\n",
      "Epoch 1184/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1847 - combined_decoder_loss: 0.1851\n",
      "Epoch 1185/3000\n",
      "1190/1190 [==============================] - 1s 833us/sample - loss: 0.1863 - combined_decoder_loss: 0.1864\n",
      "Epoch 1186/3000\n",
      "1190/1190 [==============================] - 1s 827us/sample - loss: 0.1858 - combined_decoder_loss: 0.1854\n",
      "Epoch 1187/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1190/1190 [==============================] - 1s 831us/sample - loss: 0.1844 - combined_decoder_loss: 0.1845\n",
      "Epoch 1188/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1838 - combined_decoder_loss: 0.1839\n",
      "Epoch 1189/3000\n",
      "1190/1190 [==============================] - 1s 834us/sample - loss: 0.1844 - combined_decoder_loss: 0.1848\n",
      "Epoch 1190/3000\n",
      "1190/1190 [==============================] - 1s 814us/sample - loss: 0.1871 - combined_decoder_loss: 0.1873\n",
      "Epoch 1191/3000\n",
      "1190/1190 [==============================] - 1s 798us/sample - loss: 0.1858 - combined_decoder_loss: 0.1861\n",
      "Epoch 1192/3000\n",
      "1190/1190 [==============================] - 1s 813us/sample - loss: 0.1851 - combined_decoder_loss: 0.1857\n",
      "Epoch 1193/3000\n",
      "1190/1190 [==============================] - 1s 831us/sample - loss: 0.1849 - combined_decoder_loss: 0.1850\n",
      "Epoch 1194/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1851 - combined_decoder_loss: 0.1850\n",
      "Epoch 1195/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1847 - combined_decoder_loss: 0.1844\n",
      "Epoch 1196/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1835 - combined_decoder_loss: 0.1830\n",
      "Epoch 1197/3000\n",
      "1190/1190 [==============================] - 1s 829us/sample - loss: 0.1854 - combined_decoder_loss: 0.1855\n",
      "Epoch 1198/3000\n",
      "1190/1190 [==============================] - 1s 823us/sample - loss: 0.1839 - combined_decoder_loss: 0.1834\n",
      "Epoch 1199/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1836 - combined_decoder_loss: 0.1840\n",
      "Epoch 1200/3000\n",
      "1190/1190 [==============================] - 1s 831us/sample - loss: 0.1853 - combined_decoder_loss: 0.1851\n",
      "Epoch 1201/3000\n",
      "1190/1190 [==============================] - 1s 831us/sample - loss: 0.1837 - combined_decoder_loss: 0.1838\n",
      "Epoch 1202/3000\n",
      "1190/1190 [==============================] - 1s 824us/sample - loss: 0.1829 - combined_decoder_loss: 0.1828\n",
      "Epoch 1203/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1836 - combined_decoder_loss: 0.1834\n",
      "Epoch 1204/3000\n",
      "1190/1190 [==============================] - 1s 824us/sample - loss: 0.1839 - combined_decoder_loss: 0.1841\n",
      "Epoch 1205/3000\n",
      "1190/1190 [==============================] - 1s 831us/sample - loss: 0.1871 - combined_decoder_loss: 0.1870\n",
      "Epoch 1206/3000\n",
      "1190/1190 [==============================] - 1s 831us/sample - loss: 0.1865 - combined_decoder_loss: 0.1872\n",
      "Epoch 1207/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1859 - combined_decoder_loss: 0.1864\n",
      "Epoch 1208/3000\n",
      "1190/1190 [==============================] - 1s 822us/sample - loss: 0.1854 - combined_decoder_loss: 0.1850\n",
      "Epoch 1209/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1843 - combined_decoder_loss: 0.1846\n",
      "Epoch 1210/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1838 - combined_decoder_loss: 0.1846\n",
      "Epoch 1211/3000\n",
      "1190/1190 [==============================] - 1s 823us/sample - loss: 0.1836 - combined_decoder_loss: 0.1832\n",
      "Epoch 1212/3000\n",
      "1190/1190 [==============================] - 1s 827us/sample - loss: 0.1833 - combined_decoder_loss: 0.1832\n",
      "Epoch 1213/3000\n",
      "1190/1190 [==============================] - 1s 826us/sample - loss: 0.1841 - combined_decoder_loss: 0.1847\n",
      "Epoch 1214/3000\n",
      "1190/1190 [==============================] - 1s 831us/sample - loss: 0.1825 - combined_decoder_loss: 0.1825\n",
      "Epoch 1215/3000\n",
      "1190/1190 [==============================] - 1s 834us/sample - loss: 0.1826 - combined_decoder_loss: 0.1823\n",
      "Epoch 1216/3000\n",
      "1190/1190 [==============================] - 1s 826us/sample - loss: 0.1809 - combined_decoder_loss: 0.1808\n",
      "Epoch 1217/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1805 - combined_decoder_loss: 0.1818\n",
      "Epoch 1218/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1800 - combined_decoder_loss: 0.1799\n",
      "Epoch 1219/3000\n",
      "1190/1190 [==============================] - 1s 831us/sample - loss: 0.1828 - combined_decoder_loss: 0.1825\n",
      "Epoch 1220/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1811 - combined_decoder_loss: 0.1810\n",
      "Epoch 1221/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1804 - combined_decoder_loss: 0.1801\n",
      "Epoch 1222/3000\n",
      "1190/1190 [==============================] - 1s 829us/sample - loss: 0.1803 - combined_decoder_loss: 0.1805\n",
      "Epoch 1223/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1828 - combined_decoder_loss: 0.1830\n",
      "Epoch 1224/3000\n",
      "1190/1190 [==============================] - 1s 831us/sample - loss: 0.1805 - combined_decoder_loss: 0.1804\n",
      "Epoch 1225/3000\n",
      "1190/1190 [==============================] - 1s 824us/sample - loss: 0.1880 - combined_decoder_loss: 0.1877\n",
      "Epoch 1226/3000\n",
      "1190/1190 [==============================] - 1s 823us/sample - loss: 0.1857 - combined_decoder_loss: 0.1861\n",
      "Epoch 1227/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1791 - combined_decoder_loss: 0.1793\n",
      "Epoch 1228/3000\n",
      "1190/1190 [==============================] - 1s 823us/sample - loss: 0.1826 - combined_decoder_loss: 0.1826\n",
      "Epoch 1229/3000\n",
      "1190/1190 [==============================] - 1s 835us/sample - loss: 0.1835 - combined_decoder_loss: 0.1830\n",
      "Epoch 1230/3000\n",
      "1190/1190 [==============================] - 1s 826us/sample - loss: 0.1810 - combined_decoder_loss: 0.1809\n",
      "Epoch 1231/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1796 - combined_decoder_loss: 0.1795\n",
      "Epoch 1232/3000\n",
      "1190/1190 [==============================] - 1s 824us/sample - loss: 0.1814 - combined_decoder_loss: 0.1814\n",
      "Epoch 1233/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1812 - combined_decoder_loss: 0.1809\n",
      "Epoch 1234/3000\n",
      "1190/1190 [==============================] - 1s 826us/sample - loss: 0.1808 - combined_decoder_loss: 0.1807\n",
      "Epoch 1235/3000\n",
      "1190/1190 [==============================] - 1s 825us/sample - loss: 0.1809 - combined_decoder_loss: 0.1809\n",
      "Epoch 1236/3000\n",
      "1190/1190 [==============================] - 1s 825us/sample - loss: 0.1809 - combined_decoder_loss: 0.1809\n",
      "Epoch 1237/3000\n",
      "1190/1190 [==============================] - 1s 824us/sample - loss: 0.1813 - combined_decoder_loss: 0.1814\n",
      "Epoch 1238/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1847 - combined_decoder_loss: 0.1849\n",
      "Epoch 1239/3000\n",
      "1190/1190 [==============================] - 1s 823us/sample - loss: 0.1888 - combined_decoder_loss: 0.1885\n",
      "Epoch 1240/3000\n",
      "1190/1190 [==============================] - 1s 825us/sample - loss: 0.1839 - combined_decoder_loss: 0.1835\n",
      "Epoch 1241/3000\n",
      "1190/1190 [==============================] - 1s 824us/sample - loss: 0.1806 - combined_decoder_loss: 0.1807\n",
      "Epoch 1242/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1804 - combined_decoder_loss: 0.1806\n",
      "Epoch 1243/3000\n",
      "1190/1190 [==============================] - 1s 824us/sample - loss: 0.1818 - combined_decoder_loss: 0.1818\n",
      "Epoch 1244/3000\n",
      "1190/1190 [==============================] - 1s 833us/sample - loss: 0.1803 - combined_decoder_loss: 0.1810\n",
      "Epoch 1245/3000\n",
      "1190/1190 [==============================] - 1s 828us/sample - loss: 0.1813 - combined_decoder_loss: 0.1819\n",
      "Epoch 1246/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1809 - combined_decoder_loss: 0.1809\n",
      "Epoch 1247/3000\n",
      "1190/1190 [==============================] - 1s 823us/sample - loss: 0.1803 - combined_decoder_loss: 0.1804\n",
      "Epoch 1248/3000\n",
      "1190/1190 [==============================] - 1s 825us/sample - loss: 0.1819 - combined_decoder_loss: 0.1816\n",
      "Epoch 1249/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1790 - combined_decoder_loss: 0.1785\n",
      "Epoch 1250/3000\n",
      "1190/1190 [==============================] - 1s 831us/sample - loss: 0.1805 - combined_decoder_loss: 0.1804\n",
      "Epoch 1251/3000\n",
      "1190/1190 [==============================] - 1s 831us/sample - loss: 0.1812 - combined_decoder_loss: 0.1805\n",
      "Epoch 1252/3000\n",
      "1190/1190 [==============================] - 1s 831us/sample - loss: 0.1791 - combined_decoder_loss: 0.1789\n",
      "Epoch 1253/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1787 - combined_decoder_loss: 0.1788\n",
      "Epoch 1254/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1764 - combined_decoder_loss: 0.1765\n",
      "Epoch 1255/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1809 - combined_decoder_loss: 0.1821\n",
      "Epoch 1256/3000\n",
      "1190/1190 [==============================] - 1s 815us/sample - loss: 0.1782 - combined_decoder_loss: 0.1782\n",
      "Epoch 1257/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1786 - combined_decoder_loss: 0.1787\n",
      "Epoch 1258/3000\n",
      "1190/1190 [==============================] - 1s 841us/sample - loss: 0.1838 - combined_decoder_loss: 0.1840\n",
      "Epoch 1259/3000\n",
      "1190/1190 [==============================] - 1s 828us/sample - loss: 0.1789 - combined_decoder_loss: 0.1788\n",
      "Epoch 1260/3000\n",
      "1190/1190 [==============================] - 1s 831us/sample - loss: 0.1795 - combined_decoder_loss: 0.1795\n",
      "Epoch 1261/3000\n",
      "1190/1190 [==============================] - 1s 829us/sample - loss: 0.1780 - combined_decoder_loss: 0.1784\n",
      "Epoch 1262/3000\n",
      "1190/1190 [==============================] - 1s 826us/sample - loss: 0.1764 - combined_decoder_loss: 0.1762\n",
      "Epoch 1263/3000\n",
      "1190/1190 [==============================] - 1s 829us/sample - loss: 0.1778 - combined_decoder_loss: 0.1775\n",
      "Epoch 1264/3000\n",
      "1190/1190 [==============================] - 1s 815us/sample - loss: 0.1795 - combined_decoder_loss: 0.1797\n",
      "Epoch 1265/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1783 - combined_decoder_loss: 0.1780\n",
      "Epoch 1266/3000\n",
      "1190/1190 [==============================] - 1s 854us/sample - loss: 0.1784 - combined_decoder_loss: 0.1785\n",
      "Epoch 1267/3000\n",
      "1190/1190 [==============================] - 1s 860us/sample - loss: 0.1886 - combined_decoder_loss: 0.1881\n",
      "Epoch 1268/3000\n",
      "1190/1190 [==============================] - 1s 857us/sample - loss: 0.1840 - combined_decoder_loss: 0.1834\n",
      "Epoch 1269/3000\n",
      "1190/1190 [==============================] - 1s 841us/sample - loss: 0.1835 - combined_decoder_loss: 0.1833\n",
      "Epoch 1270/3000\n",
      "1190/1190 [==============================] - 1s 850us/sample - loss: 0.1773 - combined_decoder_loss: 0.1771\n",
      "Epoch 1271/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1781 - combined_decoder_loss: 0.1784\n",
      "Epoch 1272/3000\n",
      "1190/1190 [==============================] - 1s 865us/sample - loss: 0.1786 - combined_decoder_loss: 0.1788\n",
      "Epoch 1273/3000\n",
      "1190/1190 [==============================] - 1s 856us/sample - loss: 0.1802 - combined_decoder_loss: 0.1797\n",
      "Epoch 1274/3000\n",
      "1190/1190 [==============================] - 1s 854us/sample - loss: 0.1785 - combined_decoder_loss: 0.1787\n",
      "Epoch 1275/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1848 - combined_decoder_loss: 0.1850\n",
      "Epoch 1276/3000\n",
      "1190/1190 [==============================] - 1s 855us/sample - loss: 0.1773 - combined_decoder_loss: 0.1770\n",
      "Epoch 1277/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1789 - combined_decoder_loss: 0.1788\n",
      "Epoch 1278/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1783 - combined_decoder_loss: 0.1784\n",
      "Epoch 1279/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1786 - combined_decoder_loss: 0.1784\n",
      "Epoch 1280/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1779 - combined_decoder_loss: 0.1780\n",
      "Epoch 1281/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1770 - combined_decoder_loss: 0.1773\n",
      "Epoch 1282/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1790 - combined_decoder_loss: 0.1786\n",
      "Epoch 1283/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1767 - combined_decoder_loss: 0.1767\n",
      "Epoch 1284/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1804 - combined_decoder_loss: 0.1802\n",
      "Epoch 1285/3000\n",
      "1190/1190 [==============================] - 1s 848us/sample - loss: 0.1780 - combined_decoder_loss: 0.1792\n",
      "Epoch 1286/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1759 - combined_decoder_loss: 0.1770\n",
      "Epoch 1287/3000\n",
      "1190/1190 [==============================] - 1s 849us/sample - loss: 0.1779 - combined_decoder_loss: 0.1782\n",
      "Epoch 1288/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1768 - combined_decoder_loss: 0.1779\n",
      "Epoch 1289/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1753 - combined_decoder_loss: 0.1756\n",
      "Epoch 1290/3000\n",
      "1190/1190 [==============================] - 1s 841us/sample - loss: 0.1797 - combined_decoder_loss: 0.1798\n",
      "Epoch 1291/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1757 - combined_decoder_loss: 0.1757\n",
      "Epoch 1292/3000\n",
      "1190/1190 [==============================] - 1s 841us/sample - loss: 0.1772 - combined_decoder_loss: 0.1772\n",
      "Epoch 1293/3000\n",
      "1190/1190 [==============================] - 1s 856us/sample - loss: 0.1765 - combined_decoder_loss: 0.1765\n",
      "Epoch 1294/3000\n",
      "1190/1190 [==============================] - 1s 836us/sample - loss: 0.1769 - combined_decoder_loss: 0.1772\n",
      "Epoch 1295/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1781 - combined_decoder_loss: 0.1783\n",
      "Epoch 1296/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1774 - combined_decoder_loss: 0.1778\n",
      "Epoch 1297/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1769 - combined_decoder_loss: 0.1771\n",
      "Epoch 1298/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1766 - combined_decoder_loss: 0.1763\n",
      "Epoch 1299/3000\n",
      "1190/1190 [==============================] - 1s 846us/sample - loss: 0.1781 - combined_decoder_loss: 0.1778\n",
      "Epoch 1300/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1764 - combined_decoder_loss: 0.1763\n",
      "Epoch 1301/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1801 - combined_decoder_loss: 0.1805\n",
      "Epoch 1302/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1767 - combined_decoder_loss: 0.1764\n",
      "Epoch 1303/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1782 - combined_decoder_loss: 0.1778\n",
      "Epoch 1304/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.1771 - combined_decoder_loss: 0.1772\n",
      "Epoch 1305/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1750 - combined_decoder_loss: 0.1753\n",
      "Epoch 1306/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1775 - combined_decoder_loss: 0.1774\n",
      "Epoch 1307/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.1767 - combined_decoder_loss: 0.1767\n",
      "Epoch 1308/3000\n",
      "1190/1190 [==============================] - 1s 846us/sample - loss: 0.1754 - combined_decoder_loss: 0.1754\n",
      "Epoch 1309/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1772 - combined_decoder_loss: 0.1770\n",
      "Epoch 1310/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1751 - combined_decoder_loss: 0.1745\n",
      "Epoch 1311/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1771 - combined_decoder_loss: 0.1771\n",
      "Epoch 1312/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1783 - combined_decoder_loss: 0.1781\n",
      "Epoch 1313/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1754 - combined_decoder_loss: 0.1754\n",
      "Epoch 1314/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1772 - combined_decoder_loss: 0.1769\n",
      "Epoch 1315/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1765 - combined_decoder_loss: 0.1764\n",
      "Epoch 1316/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1757 - combined_decoder_loss: 0.1755\n",
      "Epoch 1317/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1757 - combined_decoder_loss: 0.1753\n",
      "Epoch 1318/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1785 - combined_decoder_loss: 0.1787\n",
      "Epoch 1319/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1750 - combined_decoder_loss: 0.1746\n",
      "Epoch 1320/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1777 - combined_decoder_loss: 0.1778\n",
      "Epoch 1321/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1757 - combined_decoder_loss: 0.1760\n",
      "Epoch 1322/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1735 - combined_decoder_loss: 0.1735\n",
      "Epoch 1323/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.1760 - combined_decoder_loss: 0.1760\n",
      "Epoch 1324/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.1751 - combined_decoder_loss: 0.1751\n",
      "Epoch 1325/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1744 - combined_decoder_loss: 0.1743\n",
      "Epoch 1326/3000\n",
      "1190/1190 [==============================] - 1s 841us/sample - loss: 0.1787 - combined_decoder_loss: 0.1786\n",
      "Epoch 1327/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1772 - combined_decoder_loss: 0.1766\n",
      "Epoch 1328/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1754 - combined_decoder_loss: 0.1754\n",
      "Epoch 1329/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1772 - combined_decoder_loss: 0.1770\n",
      "Epoch 1330/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1753 - combined_decoder_loss: 0.1749\n",
      "Epoch 1331/3000\n",
      "1190/1190 [==============================] - 1s 862us/sample - loss: 0.1780 - combined_decoder_loss: 0.1783\n",
      "Epoch 1332/3000\n",
      "1190/1190 [==============================] - 1s 899us/sample - loss: 0.1750 - combined_decoder_loss: 0.1748\n",
      "Epoch 1333/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1778 - combined_decoder_loss: 0.1776\n",
      "Epoch 1334/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1759 - combined_decoder_loss: 0.1757\n",
      "Epoch 1335/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1805 - combined_decoder_loss: 0.1802\n",
      "Epoch 1336/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1742 - combined_decoder_loss: 0.1739\n",
      "Epoch 1337/3000\n",
      "1190/1190 [==============================] - 1s 841us/sample - loss: 0.1752 - combined_decoder_loss: 0.1749\n",
      "Epoch 1338/3000\n",
      "1190/1190 [==============================] - 1s 828us/sample - loss: 0.1738 - combined_decoder_loss: 0.1734\n",
      "Epoch 1339/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1755 - combined_decoder_loss: 0.1767\n",
      "Epoch 1340/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1775 - combined_decoder_loss: 0.1776\n",
      "Epoch 1341/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1758 - combined_decoder_loss: 0.1763\n",
      "Epoch 1342/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1936 - combined_decoder_loss: 0.1933\n",
      "Epoch 1343/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1780 - combined_decoder_loss: 0.1779\n",
      "Epoch 1344/3000\n",
      "1190/1190 [==============================] - 1s 846us/sample - loss: 0.1755 - combined_decoder_loss: 0.1752\n",
      "Epoch 1345/3000\n",
      "1190/1190 [==============================] - 1s 836us/sample - loss: 0.1757 - combined_decoder_loss: 0.1754\n",
      "Epoch 1346/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1749 - combined_decoder_loss: 0.1748\n",
      "Epoch 1347/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1739 - combined_decoder_loss: 0.1742\n",
      "Epoch 1348/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1812 - combined_decoder_loss: 0.1813\n",
      "Epoch 1349/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1742 - combined_decoder_loss: 0.1740\n",
      "Epoch 1350/3000\n",
      "1190/1190 [==============================] - 1s 848us/sample - loss: 0.1737 - combined_decoder_loss: 0.1739\n",
      "Epoch 1351/3000\n",
      "1190/1190 [==============================] - 1s 820us/sample - loss: 0.1728 - combined_decoder_loss: 0.1730\n",
      "Epoch 1352/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.1745 - combined_decoder_loss: 0.1744\n",
      "Epoch 1353/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1752 - combined_decoder_loss: 0.1748\n",
      "Epoch 1354/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1749 - combined_decoder_loss: 0.1751\n",
      "Epoch 1355/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1742 - combined_decoder_loss: 0.1742\n",
      "Epoch 1356/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1770 - combined_decoder_loss: 0.1769\n",
      "Epoch 1357/3000\n",
      "1190/1190 [==============================] - 1s 843us/sample - loss: 0.1759 - combined_decoder_loss: 0.1761\n",
      "Epoch 1358/3000\n",
      "1190/1190 [==============================] - 1s 849us/sample - loss: 0.1746 - combined_decoder_loss: 0.1746\n",
      "Epoch 1359/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1760 - combined_decoder_loss: 0.1765\n",
      "Epoch 1360/3000\n",
      "1190/1190 [==============================] - 1s 846us/sample - loss: 0.1758 - combined_decoder_loss: 0.1759\n",
      "Epoch 1361/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1718 - combined_decoder_loss: 0.1718\n",
      "Epoch 1362/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1735 - combined_decoder_loss: 0.1733\n",
      "Epoch 1363/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1786 - combined_decoder_loss: 0.1785\n",
      "Epoch 1364/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1754 - combined_decoder_loss: 0.1754\n",
      "Epoch 1365/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1749 - combined_decoder_loss: 0.1750\n",
      "Epoch 1366/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1756 - combined_decoder_loss: 0.1753\n",
      "Epoch 1367/3000\n",
      "1190/1190 [==============================] - 1s 828us/sample - loss: 0.1791 - combined_decoder_loss: 0.1789\n",
      "Epoch 1368/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.1744 - combined_decoder_loss: 0.1742\n",
      "Epoch 1369/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1714 - combined_decoder_loss: 0.1710\n",
      "Epoch 1370/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1833 - combined_decoder_loss: 0.1830\n",
      "Epoch 1371/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1728 - combined_decoder_loss: 0.1728\n",
      "Epoch 1372/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.1740 - combined_decoder_loss: 0.1737\n",
      "Epoch 1373/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1735 - combined_decoder_loss: 0.1732\n",
      "Epoch 1374/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1743 - combined_decoder_loss: 0.1741\n",
      "Epoch 1375/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1735 - combined_decoder_loss: 0.1734\n",
      "Epoch 1376/3000\n",
      "1190/1190 [==============================] - 1s 849us/sample - loss: 0.1738 - combined_decoder_loss: 0.1736\n",
      "Epoch 1377/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1744 - combined_decoder_loss: 0.1743\n",
      "Epoch 1378/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1743 - combined_decoder_loss: 0.1744\n",
      "Epoch 1379/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1723 - combined_decoder_loss: 0.1724\n",
      "Epoch 1380/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1723 - combined_decoder_loss: 0.1731\n",
      "Epoch 1381/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.1750 - combined_decoder_loss: 0.1747\n",
      "Epoch 1382/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1750 - combined_decoder_loss: 0.1749\n",
      "Epoch 1383/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1730 - combined_decoder_loss: 0.1737\n",
      "Epoch 1384/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1708 - combined_decoder_loss: 0.1712\n",
      "Epoch 1385/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1715 - combined_decoder_loss: 0.1713\n",
      "Epoch 1386/3000\n",
      "1190/1190 [==============================] - 1s 855us/sample - loss: 0.1771 - combined_decoder_loss: 0.1774\n",
      "Epoch 1387/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1736 - combined_decoder_loss: 0.1735\n",
      "Epoch 1388/3000\n",
      "1190/1190 [==============================] - 1s 841us/sample - loss: 0.1714 - combined_decoder_loss: 0.1716\n",
      "Epoch 1389/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1732 - combined_decoder_loss: 0.1732\n",
      "Epoch 1390/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1744 - combined_decoder_loss: 0.1754\n",
      "Epoch 1391/3000\n",
      "1190/1190 [==============================] - 1s 854us/sample - loss: 0.1732 - combined_decoder_loss: 0.1733\n",
      "Epoch 1392/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1732 - combined_decoder_loss: 0.1728\n",
      "Epoch 1393/3000\n",
      "1190/1190 [==============================] - 1s 846us/sample - loss: 0.1717 - combined_decoder_loss: 0.1718\n",
      "Epoch 1394/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1716 - combined_decoder_loss: 0.1715\n",
      "Epoch 1395/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1724 - combined_decoder_loss: 0.1722\n",
      "Epoch 1396/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.1725 - combined_decoder_loss: 0.1726\n",
      "Epoch 1397/3000\n",
      "1190/1190 [==============================] - 1s 856us/sample - loss: 0.1713 - combined_decoder_loss: 0.1718\n",
      "Epoch 1398/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.1741 - combined_decoder_loss: 0.1740\n",
      "Epoch 1399/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1755 - combined_decoder_loss: 0.1754\n",
      "Epoch 1400/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1739 - combined_decoder_loss: 0.1738\n",
      "Epoch 1401/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1722 - combined_decoder_loss: 0.1721\n",
      "Epoch 1402/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1723 - combined_decoder_loss: 0.1721\n",
      "Epoch 1403/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1724 - combined_decoder_loss: 0.1718\n",
      "Epoch 1404/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1728 - combined_decoder_loss: 0.1724\n",
      "Epoch 1405/3000\n",
      "1190/1190 [==============================] - 1s 854us/sample - loss: 0.1741 - combined_decoder_loss: 0.1741\n",
      "Epoch 1406/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1754 - combined_decoder_loss: 0.1753\n",
      "Epoch 1407/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1744 - combined_decoder_loss: 0.1742\n",
      "Epoch 1408/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1715 - combined_decoder_loss: 0.1718\n",
      "Epoch 1409/3000\n",
      "1190/1190 [==============================] - 1s 849us/sample - loss: 0.1719 - combined_decoder_loss: 0.1716\n",
      "Epoch 1410/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1736 - combined_decoder_loss: 0.1734\n",
      "Epoch 1411/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1710 - combined_decoder_loss: 0.1709\n",
      "Epoch 1412/3000\n",
      "1190/1190 [==============================] - 1s 855us/sample - loss: 0.1723 - combined_decoder_loss: 0.1722\n",
      "Epoch 1413/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.1723 - combined_decoder_loss: 0.1723\n",
      "Epoch 1414/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1725 - combined_decoder_loss: 0.1727\n",
      "Epoch 1415/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1732 - combined_decoder_loss: 0.1728\n",
      "Epoch 1416/3000\n",
      "1190/1190 [==============================] - 1s 841us/sample - loss: 0.1840 - combined_decoder_loss: 0.1841\n",
      "Epoch 1417/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1722 - combined_decoder_loss: 0.1716\n",
      "Epoch 1418/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1715 - combined_decoder_loss: 0.1718\n",
      "Epoch 1419/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1709 - combined_decoder_loss: 0.1709\n",
      "Epoch 1420/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1740 - combined_decoder_loss: 0.1738\n",
      "Epoch 1421/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1720 - combined_decoder_loss: 0.1717\n",
      "Epoch 1422/3000\n",
      "1190/1190 [==============================] - 1s 854us/sample - loss: 0.1718 - combined_decoder_loss: 0.1714\n",
      "Epoch 1423/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1718 - combined_decoder_loss: 0.1718\n",
      "Epoch 1424/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1712 - combined_decoder_loss: 0.1713\n",
      "Epoch 1425/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1691 - combined_decoder_loss: 0.1692\n",
      "Epoch 1426/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1737 - combined_decoder_loss: 0.1735\n",
      "Epoch 1427/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1729 - combined_decoder_loss: 0.1726\n",
      "Epoch 1428/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1731 - combined_decoder_loss: 0.1733\n",
      "Epoch 1429/3000\n",
      "1190/1190 [==============================] - 1s 849us/sample - loss: 0.1712 - combined_decoder_loss: 0.1714\n",
      "Epoch 1430/3000\n",
      "1190/1190 [==============================] - 1s 829us/sample - loss: 0.1815 - combined_decoder_loss: 0.1812\n",
      "Epoch 1431/3000\n",
      "1190/1190 [==============================] - 1s 820us/sample - loss: 0.1726 - combined_decoder_loss: 0.1728\n",
      "Epoch 1432/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1713 - combined_decoder_loss: 0.1712\n",
      "Epoch 1433/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1722 - combined_decoder_loss: 0.1717\n",
      "Epoch 1434/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1719 - combined_decoder_loss: 0.1720\n",
      "Epoch 1435/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.1739 - combined_decoder_loss: 0.1743\n",
      "Epoch 1436/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1739 - combined_decoder_loss: 0.1739\n",
      "Epoch 1437/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1759 - combined_decoder_loss: 0.1754\n",
      "Epoch 1438/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1708 - combined_decoder_loss: 0.1713\n",
      "Epoch 1439/3000\n",
      "1190/1190 [==============================] - 1s 841us/sample - loss: 0.1718 - combined_decoder_loss: 0.1719\n",
      "Epoch 1440/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1712 - combined_decoder_loss: 0.1713\n",
      "Epoch 1441/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1863 - combined_decoder_loss: 0.1859\n",
      "Epoch 1442/3000\n",
      "1190/1190 [==============================] - 1s 854us/sample - loss: 0.1726 - combined_decoder_loss: 0.1725\n",
      "Epoch 1443/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1752 - combined_decoder_loss: 0.1747\n",
      "Epoch 1444/3000\n",
      "1190/1190 [==============================] - 1s 854us/sample - loss: 0.1723 - combined_decoder_loss: 0.1722\n",
      "Epoch 1445/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1708 - combined_decoder_loss: 0.1708\n",
      "Epoch 1446/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1704 - combined_decoder_loss: 0.1703\n",
      "Epoch 1447/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1728 - combined_decoder_loss: 0.1726\n",
      "Epoch 1448/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1709 - combined_decoder_loss: 0.1704\n",
      "Epoch 1449/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1718 - combined_decoder_loss: 0.1714\n",
      "Epoch 1450/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1700 - combined_decoder_loss: 0.1696\n",
      "Epoch 1451/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1190/1190 [==============================] - 1s 856us/sample - loss: 0.1728 - combined_decoder_loss: 0.1725\n",
      "Epoch 1452/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1727 - combined_decoder_loss: 0.1724\n",
      "Epoch 1453/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1716 - combined_decoder_loss: 0.1711\n",
      "Epoch 1454/3000\n",
      "1190/1190 [==============================] - 1s 846us/sample - loss: 0.1742 - combined_decoder_loss: 0.1738\n",
      "Epoch 1455/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1695 - combined_decoder_loss: 0.1693\n",
      "Epoch 1456/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1723 - combined_decoder_loss: 0.1720\n",
      "Epoch 1457/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1733 - combined_decoder_loss: 0.1732\n",
      "Epoch 1458/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1706 - combined_decoder_loss: 0.1705\n",
      "Epoch 1459/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.1708 - combined_decoder_loss: 0.1708\n",
      "Epoch 1460/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1719 - combined_decoder_loss: 0.1726\n",
      "Epoch 1461/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.1708 - combined_decoder_loss: 0.1708\n",
      "Epoch 1462/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1730 - combined_decoder_loss: 0.1728\n",
      "Epoch 1463/3000\n",
      "1190/1190 [==============================] - 1s 846us/sample - loss: 0.1705 - combined_decoder_loss: 0.1703\n",
      "Epoch 1464/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1701 - combined_decoder_loss: 0.1699\n",
      "Epoch 1465/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1841 - combined_decoder_loss: 0.1836\n",
      "Epoch 1466/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1802 - combined_decoder_loss: 0.1798\n",
      "Epoch 1467/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1715 - combined_decoder_loss: 0.1716\n",
      "Epoch 1468/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1700 - combined_decoder_loss: 0.1699\n",
      "Epoch 1469/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1689 - combined_decoder_loss: 0.1692\n",
      "Epoch 1470/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1873 - combined_decoder_loss: 0.1870\n",
      "Epoch 1471/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1709 - combined_decoder_loss: 0.1708\n",
      "Epoch 1472/3000\n",
      "1190/1190 [==============================] - 1s 856us/sample - loss: 0.1691 - combined_decoder_loss: 0.1692\n",
      "Epoch 1473/3000\n",
      "1190/1190 [==============================] - 1s 854us/sample - loss: 0.1708 - combined_decoder_loss: 0.1708\n",
      "Epoch 1474/3000\n",
      "1190/1190 [==============================] - 1s 846us/sample - loss: 0.1717 - combined_decoder_loss: 0.1712\n",
      "Epoch 1475/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.1705 - combined_decoder_loss: 0.1711\n",
      "Epoch 1476/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1704 - combined_decoder_loss: 0.1700\n",
      "Epoch 1477/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1695 - combined_decoder_loss: 0.1695\n",
      "Epoch 1478/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1715 - combined_decoder_loss: 0.1717\n",
      "Epoch 1479/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1718 - combined_decoder_loss: 0.1717\n",
      "Epoch 1480/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1749 - combined_decoder_loss: 0.1752\n",
      "Epoch 1481/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.1727 - combined_decoder_loss: 0.1725\n",
      "Epoch 1482/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1704 - combined_decoder_loss: 0.1703\n",
      "Epoch 1483/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1712 - combined_decoder_loss: 0.1713\n",
      "Epoch 1484/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1704 - combined_decoder_loss: 0.1701\n",
      "Epoch 1485/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1699 - combined_decoder_loss: 0.1698\n",
      "Epoch 1486/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1702 - combined_decoder_loss: 0.1704\n",
      "Epoch 1487/3000\n",
      "1190/1190 [==============================] - 1s 849us/sample - loss: 0.1701 - combined_decoder_loss: 0.1702\n",
      "Epoch 1488/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1781 - combined_decoder_loss: 0.1780\n",
      "Epoch 1489/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1717 - combined_decoder_loss: 0.1723\n",
      "Epoch 1490/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1693 - combined_decoder_loss: 0.1693\n",
      "Epoch 1491/3000\n",
      "1190/1190 [==============================] - 1s 841us/sample - loss: 0.1727 - combined_decoder_loss: 0.1727\n",
      "Epoch 1492/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1710 - combined_decoder_loss: 0.1705\n",
      "Epoch 1493/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1729 - combined_decoder_loss: 0.1731\n",
      "Epoch 1494/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1742 - combined_decoder_loss: 0.1739\n",
      "Epoch 1495/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1700 - combined_decoder_loss: 0.1702\n",
      "Epoch 1496/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1698 - combined_decoder_loss: 0.1700\n",
      "Epoch 1497/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1759 - combined_decoder_loss: 0.1756\n",
      "Epoch 1498/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1722 - combined_decoder_loss: 0.1722\n",
      "Epoch 1499/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1701 - combined_decoder_loss: 0.1700\n",
      "Epoch 1500/3000\n",
      "1190/1190 [==============================] - 1s 854us/sample - loss: 0.1719 - combined_decoder_loss: 0.1719\n",
      "Epoch 1501/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1701 - combined_decoder_loss: 0.1700\n",
      "Epoch 1502/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1712 - combined_decoder_loss: 0.1712\n",
      "Epoch 1503/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1708 - combined_decoder_loss: 0.1707\n",
      "Epoch 1504/3000\n",
      "1190/1190 [==============================] - 1s 841us/sample - loss: 0.1689 - combined_decoder_loss: 0.1689\n",
      "Epoch 1505/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1701 - combined_decoder_loss: 0.1703\n",
      "Epoch 1506/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1701 - combined_decoder_loss: 0.1704\n",
      "Epoch 1507/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1698 - combined_decoder_loss: 0.1704\n",
      "Epoch 1508/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1725 - combined_decoder_loss: 0.1722\n",
      "Epoch 1509/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1709 - combined_decoder_loss: 0.1708\n",
      "Epoch 1510/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1705 - combined_decoder_loss: 0.1704\n",
      "Epoch 1511/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1716 - combined_decoder_loss: 0.1713\n",
      "Epoch 1512/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1711 - combined_decoder_loss: 0.1709\n",
      "Epoch 1513/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1683 - combined_decoder_loss: 0.1681\n",
      "Epoch 1514/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1799 - combined_decoder_loss: 0.1796\n",
      "Epoch 1515/3000\n",
      "1190/1190 [==============================] - 1s 854us/sample - loss: 0.1702 - combined_decoder_loss: 0.1698\n",
      "Epoch 1516/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1698 - combined_decoder_loss: 0.1699\n",
      "Epoch 1517/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1736 - combined_decoder_loss: 0.1735\n",
      "Epoch 1518/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1714 - combined_decoder_loss: 0.1711\n",
      "Epoch 1519/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1752 - combined_decoder_loss: 0.1751\n",
      "Epoch 1520/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.1725 - combined_decoder_loss: 0.1725\n",
      "Epoch 1521/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1707 - combined_decoder_loss: 0.1703\n",
      "Epoch 1522/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1714 - combined_decoder_loss: 0.1714\n",
      "Epoch 1523/3000\n",
      "1190/1190 [==============================] - 1s 855us/sample - loss: 0.1801 - combined_decoder_loss: 0.1798\n",
      "Epoch 1524/3000\n",
      "1190/1190 [==============================] - 1s 849us/sample - loss: 0.1707 - combined_decoder_loss: 0.1709\n",
      "Epoch 1525/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1693 - combined_decoder_loss: 0.1693\n",
      "Epoch 1526/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.1700 - combined_decoder_loss: 0.1704\n",
      "Epoch 1527/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1698 - combined_decoder_loss: 0.1695\n",
      "Epoch 1528/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1698 - combined_decoder_loss: 0.1696\n",
      "Epoch 1529/3000\n",
      "1190/1190 [==============================] - 1s 855us/sample - loss: 0.1700 - combined_decoder_loss: 0.1697\n",
      "Epoch 1530/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1701 - combined_decoder_loss: 0.1713\n",
      "Epoch 1531/3000\n",
      "1190/1190 [==============================] - 1s 849us/sample - loss: 0.1695 - combined_decoder_loss: 0.1701\n",
      "Epoch 1532/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.1705 - combined_decoder_loss: 0.1708\n",
      "Epoch 1533/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1734 - combined_decoder_loss: 0.1731\n",
      "Epoch 1534/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1719 - combined_decoder_loss: 0.1720\n",
      "Epoch 1535/3000\n",
      "1190/1190 [==============================] - 1s 854us/sample - loss: 0.1720 - combined_decoder_loss: 0.1720\n",
      "Epoch 1536/3000\n",
      "1190/1190 [==============================] - 1s 844us/sample - loss: 0.1718 - combined_decoder_loss: 0.1719\n",
      "Epoch 1537/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.1701 - combined_decoder_loss: 0.1700\n",
      "Epoch 1538/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1680 - combined_decoder_loss: 0.1679\n",
      "Epoch 1539/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.1720 - combined_decoder_loss: 0.1717\n",
      "Epoch 1540/3000\n",
      "1190/1190 [==============================] - 1s 854us/sample - loss: 0.1712 - combined_decoder_loss: 0.1720\n",
      "Epoch 1541/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1692 - combined_decoder_loss: 0.1698\n",
      "Epoch 1542/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1706 - combined_decoder_loss: 0.1703\n",
      "Epoch 1543/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.1693 - combined_decoder_loss: 0.1694\n",
      "Epoch 1544/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1708 - combined_decoder_loss: 0.1704\n",
      "Epoch 1545/3000\n",
      "1190/1190 [==============================] - 1s 762us/sample - loss: 0.1715 - combined_decoder_loss: 0.1715\n",
      "Epoch 1546/3000\n",
      "1190/1190 [==============================] - 1s 649us/sample - loss: 0.1697 - combined_decoder_loss: 0.1697\n",
      "Epoch 1547/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1692 - combined_decoder_loss: 0.1690\n",
      "Epoch 1548/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1713 - combined_decoder_loss: 0.1713\n",
      "Epoch 1549/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1714 - combined_decoder_loss: 0.1711\n",
      "Epoch 1550/3000\n",
      "1190/1190 [==============================] - 1s 858us/sample - loss: 0.1690 - combined_decoder_loss: 0.1692\n",
      "Epoch 1551/3000\n",
      "1190/1190 [==============================] - 1s 854us/sample - loss: 0.1762 - combined_decoder_loss: 0.1762\n",
      "Epoch 1552/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1684 - combined_decoder_loss: 0.1681\n",
      "Epoch 1553/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1727 - combined_decoder_loss: 0.1724\n",
      "Epoch 1554/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1704 - combined_decoder_loss: 0.1699\n",
      "Epoch 1555/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1712 - combined_decoder_loss: 0.1713\n",
      "Epoch 1556/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.1702 - combined_decoder_loss: 0.1702\n",
      "Epoch 1557/3000\n",
      "1190/1190 [==============================] - 1s 835us/sample - loss: 0.1686 - combined_decoder_loss: 0.1680\n",
      "Epoch 1558/3000\n",
      "1190/1190 [==============================] - 1s 831us/sample - loss: 0.1695 - combined_decoder_loss: 0.1694\n",
      "Epoch 1559/3000\n",
      "1190/1190 [==============================] - 1s 841us/sample - loss: 0.1673 - combined_decoder_loss: 0.1671\n",
      "Epoch 1560/3000\n",
      "1190/1190 [==============================] - 1s 834us/sample - loss: 0.1725 - combined_decoder_loss: 0.1730\n",
      "Epoch 1561/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1687 - combined_decoder_loss: 0.1682\n",
      "Epoch 1562/3000\n",
      "1190/1190 [==============================] - 1s 836us/sample - loss: 0.1695 - combined_decoder_loss: 0.1694\n",
      "Epoch 1563/3000\n",
      "1190/1190 [==============================] - 1s 834us/sample - loss: 0.1685 - combined_decoder_loss: 0.1687\n",
      "Epoch 1564/3000\n",
      "1190/1190 [==============================] - 1s 844us/sample - loss: 0.1910 - combined_decoder_loss: 0.1909\n",
      "Epoch 1565/3000\n",
      "1190/1190 [==============================] - 1s 834us/sample - loss: 0.1692 - combined_decoder_loss: 0.1691\n",
      "Epoch 1566/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1715 - combined_decoder_loss: 0.1710\n",
      "Epoch 1567/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.1693 - combined_decoder_loss: 0.1690\n",
      "Epoch 1568/3000\n",
      "1190/1190 [==============================] - 1s 846us/sample - loss: 0.1703 - combined_decoder_loss: 0.1702\n",
      "Epoch 1569/3000\n",
      "1190/1190 [==============================] - 1s 855us/sample - loss: 0.1701 - combined_decoder_loss: 0.1700\n",
      "Epoch 1570/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1700 - combined_decoder_loss: 0.1701\n",
      "Epoch 1571/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1714 - combined_decoder_loss: 0.1713\n",
      "Epoch 1572/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1715 - combined_decoder_loss: 0.1710\n",
      "Epoch 1573/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1701 - combined_decoder_loss: 0.1700\n",
      "Epoch 1574/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1697 - combined_decoder_loss: 0.1695\n",
      "Epoch 1575/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1691 - combined_decoder_loss: 0.1687\n",
      "Epoch 1576/3000\n",
      "1190/1190 [==============================] - 1s 867us/sample - loss: 0.1690 - combined_decoder_loss: 0.1691\n",
      "Epoch 1577/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1690 - combined_decoder_loss: 0.1688\n",
      "Epoch 1578/3000\n",
      "1190/1190 [==============================] - 1s 833us/sample - loss: 0.1752 - combined_decoder_loss: 0.1751\n",
      "Epoch 1579/3000\n",
      "1190/1190 [==============================] - 1s 841us/sample - loss: 0.1692 - combined_decoder_loss: 0.1689\n",
      "Epoch 1580/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1702 - combined_decoder_loss: 0.1697\n",
      "Epoch 1581/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1712 - combined_decoder_loss: 0.1712\n",
      "Epoch 1582/3000\n",
      "1190/1190 [==============================] - 1s 833us/sample - loss: 0.1734 - combined_decoder_loss: 0.1735\n",
      "Epoch 1583/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1678 - combined_decoder_loss: 0.1676\n",
      "Epoch 1584/3000\n",
      "1190/1190 [==============================] - 1s 843us/sample - loss: 0.1710 - combined_decoder_loss: 0.1707\n",
      "Epoch 1585/3000\n",
      "1190/1190 [==============================] - 1s 842us/sample - loss: 0.1706 - combined_decoder_loss: 0.1703\n",
      "Epoch 1586/3000\n",
      "1190/1190 [==============================] - 1s 841us/sample - loss: 0.1693 - combined_decoder_loss: 0.1693\n",
      "Epoch 1587/3000\n",
      "1190/1190 [==============================] - 1s 846us/sample - loss: 0.1729 - combined_decoder_loss: 0.1729\n",
      "Epoch 1588/3000\n",
      "1190/1190 [==============================] - 1s 851us/sample - loss: 0.1688 - combined_decoder_loss: 0.1687\n",
      "Epoch 1589/3000\n",
      "1190/1190 [==============================] - 1s 861us/sample - loss: 0.1687 - combined_decoder_loss: 0.1689\n",
      "Epoch 1590/3000\n",
      "1190/1190 [==============================] - 1s 850us/sample - loss: 0.1717 - combined_decoder_loss: 0.1716\n",
      "Epoch 1591/3000\n",
      "1190/1190 [==============================] - 1s 885us/sample - loss: 0.1714 - combined_decoder_loss: 0.1715\n",
      "Epoch 1592/3000\n",
      "1190/1190 [==============================] - 1s 859us/sample - loss: 0.1697 - combined_decoder_loss: 0.1697\n",
      "Epoch 1593/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1678 - combined_decoder_loss: 0.1680\n",
      "Epoch 1594/3000\n",
      "1190/1190 [==============================] - 1s 843us/sample - loss: 0.1681 - combined_decoder_loss: 0.1681\n",
      "Epoch 1595/3000\n",
      "1190/1190 [==============================] - 1s 841us/sample - loss: 0.1663 - combined_decoder_loss: 0.1662\n",
      "Epoch 1596/3000\n",
      "1190/1190 [==============================] - 1s 850us/sample - loss: 0.1698 - combined_decoder_loss: 0.1699\n",
      "Epoch 1597/3000\n",
      "1190/1190 [==============================] - 1s 836us/sample - loss: 0.1716 - combined_decoder_loss: 0.1715\n",
      "Epoch 1598/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1719 - combined_decoder_loss: 0.1718\n",
      "Epoch 1599/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1696 - combined_decoder_loss: 0.1701\n",
      "Epoch 1600/3000\n",
      "1190/1190 [==============================] - 1s 836us/sample - loss: 0.1709 - combined_decoder_loss: 0.1707\n",
      "Epoch 1601/3000\n",
      "1190/1190 [==============================] - 1s 835us/sample - loss: 0.1707 - combined_decoder_loss: 0.1703\n",
      "Epoch 1602/3000\n",
      "1190/1190 [==============================] - 1s 833us/sample - loss: 0.1709 - combined_decoder_loss: 0.1706\n",
      "Epoch 1603/3000\n",
      "1190/1190 [==============================] - 1s 836us/sample - loss: 0.1704 - combined_decoder_loss: 0.1705\n",
      "Epoch 1604/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1698 - combined_decoder_loss: 0.1699\n",
      "Epoch 1605/3000\n",
      "1190/1190 [==============================] - 1s 854us/sample - loss: 0.1745 - combined_decoder_loss: 0.1742\n",
      "Epoch 1606/3000\n",
      "1190/1190 [==============================] - 1s 866us/sample - loss: 0.1706 - combined_decoder_loss: 0.1705\n",
      "Epoch 1607/3000\n",
      "1190/1190 [==============================] - 1s 849us/sample - loss: 0.1701 - combined_decoder_loss: 0.1700\n",
      "Epoch 1608/3000\n",
      "1190/1190 [==============================] - 1s 836us/sample - loss: 0.1699 - combined_decoder_loss: 0.1701\n",
      "Epoch 1609/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1691 - combined_decoder_loss: 0.1694\n",
      "Epoch 1610/3000\n",
      "1190/1190 [==============================] - 1s 843us/sample - loss: 0.1707 - combined_decoder_loss: 0.1706\n",
      "Epoch 1611/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1691 - combined_decoder_loss: 0.1691\n",
      "Epoch 1612/3000\n",
      "1190/1190 [==============================] - 1s 843us/sample - loss: 0.1693 - combined_decoder_loss: 0.1701\n",
      "Epoch 1613/3000\n",
      "1190/1190 [==============================] - 1s 848us/sample - loss: 0.1698 - combined_decoder_loss: 0.1695\n",
      "Epoch 1614/3000\n",
      "1190/1190 [==============================] - 1s 835us/sample - loss: 0.1694 - combined_decoder_loss: 0.1689\n",
      "Epoch 1615/3000\n",
      "1190/1190 [==============================] - 1s 844us/sample - loss: 0.1695 - combined_decoder_loss: 0.1693\n",
      "Epoch 1616/3000\n",
      "1190/1190 [==============================] - 1s 858us/sample - loss: 0.2000 - combined_decoder_loss: 0.1992\n",
      "Epoch 1617/3000\n",
      "1190/1190 [==============================] - 1s 841us/sample - loss: 0.1679 - combined_decoder_loss: 0.1681\n",
      "Epoch 1618/3000\n",
      "1190/1190 [==============================] - 1s 868us/sample - loss: 0.1708 - combined_decoder_loss: 0.1708\n",
      "Epoch 1619/3000\n",
      "1190/1190 [==============================] - 1s 875us/sample - loss: 0.1699 - combined_decoder_loss: 0.1697\n",
      "Epoch 1620/3000\n",
      "1190/1190 [==============================] - 1s 854us/sample - loss: 0.1690 - combined_decoder_loss: 0.1696\n",
      "Epoch 1621/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1722 - combined_decoder_loss: 0.1720\n",
      "Epoch 1622/3000\n",
      "1190/1190 [==============================] - 1s 843us/sample - loss: 0.1679 - combined_decoder_loss: 0.1680\n",
      "Epoch 1623/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.1692 - combined_decoder_loss: 0.1693\n",
      "Epoch 1624/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1678 - combined_decoder_loss: 0.1680\n",
      "Epoch 1625/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1698 - combined_decoder_loss: 0.1699\n",
      "Epoch 1626/3000\n",
      "1190/1190 [==============================] - 1s 841us/sample - loss: 0.1696 - combined_decoder_loss: 0.1694\n",
      "Epoch 1627/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1753 - combined_decoder_loss: 0.1755\n",
      "Epoch 1628/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1697 - combined_decoder_loss: 0.1701\n",
      "Epoch 1629/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1675 - combined_decoder_loss: 0.1675\n",
      "Epoch 1630/3000\n",
      "1190/1190 [==============================] - 1s 842us/sample - loss: 0.1682 - combined_decoder_loss: 0.1679\n",
      "Epoch 1631/3000\n",
      "1190/1190 [==============================] - 1s 835us/sample - loss: 0.1727 - combined_decoder_loss: 0.1724\n",
      "Epoch 1632/3000\n",
      "1190/1190 [==============================] - 1s 848us/sample - loss: 0.1683 - combined_decoder_loss: 0.1684\n",
      "Epoch 1633/3000\n",
      "1190/1190 [==============================] - 1s 833us/sample - loss: 0.1690 - combined_decoder_loss: 0.1693\n",
      "Epoch 1634/3000\n",
      "1190/1190 [==============================] - 1s 848us/sample - loss: 0.1697 - combined_decoder_loss: 0.1698\n",
      "Epoch 1635/3000\n",
      "1190/1190 [==============================] - 1s 846us/sample - loss: 0.1666 - combined_decoder_loss: 0.1664\n",
      "Epoch 1636/3000\n",
      "1190/1190 [==============================] - 1s 833us/sample - loss: 0.1790 - combined_decoder_loss: 0.1796\n",
      "Epoch 1637/3000\n",
      "1190/1190 [==============================] - 1s 834us/sample - loss: 0.1685 - combined_decoder_loss: 0.1685\n",
      "Epoch 1638/3000\n",
      "1190/1190 [==============================] - 1s 841us/sample - loss: 0.1698 - combined_decoder_loss: 0.1696\n",
      "Epoch 1639/3000\n",
      "1190/1190 [==============================] - 1s 835us/sample - loss: 0.1719 - combined_decoder_loss: 0.1718\n",
      "Epoch 1640/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1719 - combined_decoder_loss: 0.1716\n",
      "Epoch 1641/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1699 - combined_decoder_loss: 0.1698\n",
      "Epoch 1642/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1703 - combined_decoder_loss: 0.1705\n",
      "Epoch 1643/3000\n",
      "1190/1190 [==============================] - 1s 835us/sample - loss: 0.1711 - combined_decoder_loss: 0.1709\n",
      "Epoch 1644/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1699 - combined_decoder_loss: 0.1702\n",
      "Epoch 1645/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1692 - combined_decoder_loss: 0.1689\n",
      "Epoch 1646/3000\n",
      "1190/1190 [==============================] - 1s 846us/sample - loss: 0.1677 - combined_decoder_loss: 0.1678\n",
      "Epoch 1647/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1788 - combined_decoder_loss: 0.1783\n",
      "Epoch 1648/3000\n",
      "1190/1190 [==============================] - 1s 836us/sample - loss: 0.1708 - combined_decoder_loss: 0.1708\n",
      "Epoch 1649/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1190/1190 [==============================] - 1s 855us/sample - loss: 0.1686 - combined_decoder_loss: 0.1708\n",
      "Epoch 1650/3000\n",
      "1190/1190 [==============================] - 1s 829us/sample - loss: 0.1792 - combined_decoder_loss: 0.1791\n",
      "Epoch 1651/3000\n",
      "1190/1190 [==============================] - 1s 831us/sample - loss: 0.1696 - combined_decoder_loss: 0.1694\n",
      "Epoch 1652/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1698 - combined_decoder_loss: 0.1697\n",
      "Epoch 1653/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1685 - combined_decoder_loss: 0.1688\n",
      "Epoch 1654/3000\n",
      "1190/1190 [==============================] - 1s 843us/sample - loss: 0.1725 - combined_decoder_loss: 0.1721\n",
      "Epoch 1655/3000\n",
      "1190/1190 [==============================] - 1s 844us/sample - loss: 0.1727 - combined_decoder_loss: 0.1724\n",
      "Epoch 1656/3000\n",
      "1190/1190 [==============================] - 1s 828us/sample - loss: 0.1685 - combined_decoder_loss: 0.1684\n",
      "Epoch 1657/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1678 - combined_decoder_loss: 0.1678\n",
      "Epoch 1658/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1723 - combined_decoder_loss: 0.1721\n",
      "Epoch 1659/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1678 - combined_decoder_loss: 0.1681\n",
      "Epoch 1660/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1706 - combined_decoder_loss: 0.1704\n",
      "Epoch 1661/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1693 - combined_decoder_loss: 0.1690\n",
      "Epoch 1662/3000\n",
      "1190/1190 [==============================] - 1s 835us/sample - loss: 0.1670 - combined_decoder_loss: 0.1670\n",
      "Epoch 1663/3000\n",
      "1190/1190 [==============================] - 1s 848us/sample - loss: 0.1693 - combined_decoder_loss: 0.1694\n",
      "Epoch 1664/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1666 - combined_decoder_loss: 0.1664\n",
      "Epoch 1665/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1692 - combined_decoder_loss: 0.1696\n",
      "Epoch 1666/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1686 - combined_decoder_loss: 0.1685\n",
      "Epoch 1667/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1737 - combined_decoder_loss: 0.1735\n",
      "Epoch 1668/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1870 - combined_decoder_loss: 0.1863\n",
      "Epoch 1669/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1699 - combined_decoder_loss: 0.1696\n",
      "Epoch 1670/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.1702 - combined_decoder_loss: 0.1707\n",
      "Epoch 1671/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1704 - combined_decoder_loss: 0.1703\n",
      "Epoch 1672/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1694 - combined_decoder_loss: 0.1694\n",
      "Epoch 1673/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1688 - combined_decoder_loss: 0.1695\n",
      "Epoch 1674/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1693 - combined_decoder_loss: 0.1692\n",
      "Epoch 1675/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1686 - combined_decoder_loss: 0.1683\n",
      "Epoch 1676/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1745 - combined_decoder_loss: 0.1741\n",
      "Epoch 1677/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1691 - combined_decoder_loss: 0.1688\n",
      "Epoch 1678/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1683 - combined_decoder_loss: 0.1680\n",
      "Epoch 1679/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1693 - combined_decoder_loss: 0.1690\n",
      "Epoch 1680/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1674 - combined_decoder_loss: 0.1673\n",
      "Epoch 1681/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1684 - combined_decoder_loss: 0.1686\n",
      "Epoch 1682/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1685 - combined_decoder_loss: 0.1688\n",
      "Epoch 1683/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1724 - combined_decoder_loss: 0.1722\n",
      "Epoch 1684/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1676 - combined_decoder_loss: 0.1672\n",
      "Epoch 1685/3000\n",
      "1190/1190 [==============================] - 1s 834us/sample - loss: 0.1700 - combined_decoder_loss: 0.1700\n",
      "Epoch 1686/3000\n",
      "1190/1190 [==============================] - 1s 828us/sample - loss: 0.1954 - combined_decoder_loss: 0.1949\n",
      "Epoch 1687/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1675 - combined_decoder_loss: 0.1671\n",
      "Epoch 1688/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1667 - combined_decoder_loss: 0.1665\n",
      "Epoch 1689/3000\n",
      "1190/1190 [==============================] - 1s 846us/sample - loss: 0.1683 - combined_decoder_loss: 0.1683\n",
      "Epoch 1690/3000\n",
      "1190/1190 [==============================] - 1s 835us/sample - loss: 0.1677 - combined_decoder_loss: 0.1677\n",
      "Epoch 1691/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1700 - combined_decoder_loss: 0.1701\n",
      "Epoch 1692/3000\n",
      "1190/1190 [==============================] - 1s 846us/sample - loss: 0.1687 - combined_decoder_loss: 0.1699\n",
      "Epoch 1693/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1727 - combined_decoder_loss: 0.1726\n",
      "Epoch 1694/3000\n",
      "1190/1190 [==============================] - 1s 833us/sample - loss: 0.1707 - combined_decoder_loss: 0.1707\n",
      "Epoch 1695/3000\n",
      "1190/1190 [==============================] - 1s 836us/sample - loss: 0.1677 - combined_decoder_loss: 0.1678\n",
      "Epoch 1696/3000\n",
      "1190/1190 [==============================] - 1s 848us/sample - loss: 0.1708 - combined_decoder_loss: 0.1709\n",
      "Epoch 1697/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1697 - combined_decoder_loss: 0.1696\n",
      "Epoch 1698/3000\n",
      "1190/1190 [==============================] - 1s 848us/sample - loss: 0.1695 - combined_decoder_loss: 0.1697\n",
      "Epoch 1699/3000\n",
      "1190/1190 [==============================] - 1s 846us/sample - loss: 0.1695 - combined_decoder_loss: 0.1694\n",
      "Epoch 1700/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1687 - combined_decoder_loss: 0.1688\n",
      "Epoch 1701/3000\n",
      "1190/1190 [==============================] - 1s 853us/sample - loss: 0.1671 - combined_decoder_loss: 0.1676\n",
      "Epoch 1702/3000\n",
      "1190/1190 [==============================] - 1s 885us/sample - loss: 0.1713 - combined_decoder_loss: 0.1711\n",
      "Epoch 1703/3000\n",
      "1190/1190 [==============================] - 1s 884us/sample - loss: 0.1688 - combined_decoder_loss: 0.1691\n",
      "Epoch 1704/3000\n",
      "1190/1190 [==============================] - 1s 888us/sample - loss: 0.1681 - combined_decoder_loss: 0.1680\n",
      "Epoch 1705/3000\n",
      "1190/1190 [==============================] - 1s 927us/sample - loss: 0.1767 - combined_decoder_loss: 0.1762\n",
      "Epoch 1706/3000\n",
      "1190/1190 [==============================] - 1s 919us/sample - loss: 0.1682 - combined_decoder_loss: 0.1679\n",
      "Epoch 1707/3000\n",
      "1190/1190 [==============================] - 1s 855us/sample - loss: 0.1691 - combined_decoder_loss: 0.1690\n",
      "Epoch 1708/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1695 - combined_decoder_loss: 0.1689\n",
      "Epoch 1709/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1686 - combined_decoder_loss: 0.1681\n",
      "Epoch 1710/3000\n",
      "1190/1190 [==============================] - 1s 841us/sample - loss: 0.1706 - combined_decoder_loss: 0.1702\n",
      "Epoch 1711/3000\n",
      "1190/1190 [==============================] - 1s 841us/sample - loss: 0.1679 - combined_decoder_loss: 0.1681\n",
      "Epoch 1712/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1668 - combined_decoder_loss: 0.1669\n",
      "Epoch 1713/3000\n",
      "1190/1190 [==============================] - 1s 841us/sample - loss: 0.1701 - combined_decoder_loss: 0.1706\n",
      "Epoch 1714/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1689 - combined_decoder_loss: 0.1686\n",
      "Epoch 1715/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1682 - combined_decoder_loss: 0.1685\n",
      "Epoch 1716/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1676 - combined_decoder_loss: 0.1674\n",
      "Epoch 1717/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1745 - combined_decoder_loss: 0.1741\n",
      "Epoch 1718/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1700 - combined_decoder_loss: 0.1700\n",
      "Epoch 1719/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1693 - combined_decoder_loss: 0.1695\n",
      "Epoch 1720/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1681 - combined_decoder_loss: 0.1685\n",
      "Epoch 1721/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1715 - combined_decoder_loss: 0.1711\n",
      "Epoch 1722/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1705 - combined_decoder_loss: 0.1702\n",
      "Epoch 1723/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1673 - combined_decoder_loss: 0.1675\n",
      "Epoch 1724/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1677 - combined_decoder_loss: 0.1679\n",
      "Epoch 1725/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.1732 - combined_decoder_loss: 0.1729\n",
      "Epoch 1726/3000\n",
      "1190/1190 [==============================] - 1s 873us/sample - loss: 0.1688 - combined_decoder_loss: 0.1690\n",
      "Epoch 1727/3000\n",
      "1190/1190 [==============================] - 1s 853us/sample - loss: 0.1676 - combined_decoder_loss: 0.1672\n",
      "Epoch 1728/3000\n",
      "1190/1190 [==============================] - 1s 856us/sample - loss: 0.1718 - combined_decoder_loss: 0.1722\n",
      "Epoch 1729/3000\n",
      "1190/1190 [==============================] - 1s 866us/sample - loss: 0.1689 - combined_decoder_loss: 0.1690\n",
      "Epoch 1730/3000\n",
      "1190/1190 [==============================] - 1s 865us/sample - loss: 0.1698 - combined_decoder_loss: 0.1697\n",
      "Epoch 1731/3000\n",
      "1190/1190 [==============================] - 1s 835us/sample - loss: 0.1681 - combined_decoder_loss: 0.1675\n",
      "Epoch 1732/3000\n",
      "1190/1190 [==============================] - 1s 846us/sample - loss: 0.1685 - combined_decoder_loss: 0.1683\n",
      "Epoch 1733/3000\n",
      "1190/1190 [==============================] - 1s 853us/sample - loss: 0.1687 - combined_decoder_loss: 0.1690\n",
      "Epoch 1734/3000\n",
      "1190/1190 [==============================] - 1s 854us/sample - loss: 0.1698 - combined_decoder_loss: 0.1704\n",
      "Epoch 1735/3000\n",
      "1190/1190 [==============================] - 1s 864us/sample - loss: 0.1701 - combined_decoder_loss: 0.1708\n",
      "Epoch 1736/3000\n",
      "1190/1190 [==============================] - 1s 879us/sample - loss: 0.1689 - combined_decoder_loss: 0.1690\n",
      "Epoch 1737/3000\n",
      "1190/1190 [==============================] - 1s 855us/sample - loss: 0.1728 - combined_decoder_loss: 0.1726\n",
      "Epoch 1738/3000\n",
      "1190/1190 [==============================] - 1s 872us/sample - loss: 0.1723 - combined_decoder_loss: 0.1719\n",
      "Epoch 1739/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1686 - combined_decoder_loss: 0.1681\n",
      "Epoch 1740/3000\n",
      "1190/1190 [==============================] - 1s 852us/sample - loss: 0.1659 - combined_decoder_loss: 0.1656\n",
      "Epoch 1741/3000\n",
      "1190/1190 [==============================] - 1s 848us/sample - loss: 0.1697 - combined_decoder_loss: 0.1705\n",
      "Epoch 1742/3000\n",
      "1190/1190 [==============================] - 1s 834us/sample - loss: 0.1888 - combined_decoder_loss: 0.1887\n",
      "Epoch 1743/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.1687 - combined_decoder_loss: 0.1683\n",
      "Epoch 1744/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1685 - combined_decoder_loss: 0.1687\n",
      "Epoch 1745/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1727 - combined_decoder_loss: 0.1726\n",
      "Epoch 1746/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1676 - combined_decoder_loss: 0.1672\n",
      "Epoch 1747/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1675 - combined_decoder_loss: 0.1678\n",
      "Epoch 1748/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1692 - combined_decoder_loss: 0.1689\n",
      "Epoch 1749/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1686 - combined_decoder_loss: 0.1687\n",
      "Epoch 1750/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.1702 - combined_decoder_loss: 0.1698\n",
      "Epoch 1751/3000\n",
      "1190/1190 [==============================] - 1s 834us/sample - loss: 0.1682 - combined_decoder_loss: 0.1679\n",
      "Epoch 1752/3000\n",
      "1190/1190 [==============================] - 1s 885us/sample - loss: 0.1780 - combined_decoder_loss: 0.1779\n",
      "Epoch 1753/3000\n",
      "1190/1190 [==============================] - 1s 920us/sample - loss: 0.1687 - combined_decoder_loss: 0.1689\n",
      "Epoch 1754/3000\n",
      "1190/1190 [==============================] - 1s 890us/sample - loss: 0.1700 - combined_decoder_loss: 0.1695\n",
      "Epoch 1755/3000\n",
      "1190/1190 [==============================] - 1s 860us/sample - loss: 0.1666 - combined_decoder_loss: 0.1663\n",
      "Epoch 1756/3000\n",
      "1190/1190 [==============================] - 1s 876us/sample - loss: 0.1729 - combined_decoder_loss: 0.1724\n",
      "Epoch 1757/3000\n",
      "1190/1190 [==============================] - 1s 869us/sample - loss: 0.1677 - combined_decoder_loss: 0.1673\n",
      "Epoch 1758/3000\n",
      "1190/1190 [==============================] - 1s 849us/sample - loss: 0.1671 - combined_decoder_loss: 0.1674\n",
      "Epoch 1759/3000\n",
      "1190/1190 [==============================] - 1s 860us/sample - loss: 0.1684 - combined_decoder_loss: 0.1687\n",
      "Epoch 1760/3000\n",
      "1190/1190 [==============================] - 1s 855us/sample - loss: 0.1688 - combined_decoder_loss: 0.1682\n",
      "Epoch 1761/3000\n",
      "1190/1190 [==============================] - 1s 854us/sample - loss: 0.1732 - combined_decoder_loss: 0.1731\n",
      "Epoch 1762/3000\n",
      "1190/1190 [==============================] - 1s 852us/sample - loss: 0.1689 - combined_decoder_loss: 0.1687\n",
      "Epoch 1763/3000\n",
      "1190/1190 [==============================] - 1s 862us/sample - loss: 0.1705 - combined_decoder_loss: 0.1700\n",
      "Epoch 1764/3000\n",
      "1190/1190 [==============================] - 1s 851us/sample - loss: 0.1718 - combined_decoder_loss: 0.1717\n",
      "Epoch 1765/3000\n",
      "1190/1190 [==============================] - 1s 849us/sample - loss: 0.1728 - combined_decoder_loss: 0.1726\n",
      "Epoch 1766/3000\n",
      "1190/1190 [==============================] - 1s 861us/sample - loss: 0.1699 - combined_decoder_loss: 0.1697\n",
      "Epoch 1767/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1680 - combined_decoder_loss: 0.1679\n",
      "Epoch 1768/3000\n",
      "1190/1190 [==============================] - 1s 841us/sample - loss: 0.1688 - combined_decoder_loss: 0.1683\n",
      "Epoch 1769/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1682 - combined_decoder_loss: 0.1683\n",
      "Epoch 1770/3000\n",
      "1190/1190 [==============================] - 1s 849us/sample - loss: 0.1682 - combined_decoder_loss: 0.1682\n",
      "Epoch 1771/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1679 - combined_decoder_loss: 0.1676\n",
      "Epoch 1772/3000\n",
      "1190/1190 [==============================] - 1s 844us/sample - loss: 0.1680 - combined_decoder_loss: 0.1679\n",
      "Epoch 1773/3000\n",
      "1190/1190 [==============================] - 1s 885us/sample - loss: 0.1678 - combined_decoder_loss: 0.1677\n",
      "Epoch 1774/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.1696 - combined_decoder_loss: 0.1695\n",
      "Epoch 1775/3000\n",
      "1190/1190 [==============================] - 1s 853us/sample - loss: 0.1685 - combined_decoder_loss: 0.1685\n",
      "Epoch 1776/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1678 - combined_decoder_loss: 0.1676\n",
      "Epoch 1777/3000\n",
      "1190/1190 [==============================] - 1s 852us/sample - loss: 0.1676 - combined_decoder_loss: 0.1689\n",
      "Epoch 1778/3000\n",
      "1190/1190 [==============================] - 1s 846us/sample - loss: 0.1693 - combined_decoder_loss: 0.1689\n",
      "Epoch 1779/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1688 - combined_decoder_loss: 0.1690\n",
      "Epoch 1780/3000\n",
      "1190/1190 [==============================] - 1s 855us/sample - loss: 0.1684 - combined_decoder_loss: 0.1690\n",
      "Epoch 1781/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1190/1190 [==============================] - 1s 843us/sample - loss: 0.1734 - combined_decoder_loss: 0.1733\n",
      "Epoch 1782/3000\n",
      "1190/1190 [==============================] - 1s 848us/sample - loss: 0.1690 - combined_decoder_loss: 0.1692\n",
      "Epoch 1783/3000\n",
      "1190/1190 [==============================] - 1s 843us/sample - loss: 0.1669 - combined_decoder_loss: 0.1670\n",
      "Epoch 1784/3000\n",
      "1190/1190 [==============================] - 1s 843us/sample - loss: 0.1728 - combined_decoder_loss: 0.1727\n",
      "Epoch 1785/3000\n",
      "1190/1190 [==============================] - 1s 833us/sample - loss: 0.1671 - combined_decoder_loss: 0.1669\n",
      "Epoch 1786/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1678 - combined_decoder_loss: 0.1677\n",
      "Epoch 1787/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1682 - combined_decoder_loss: 0.1689\n",
      "Epoch 1788/3000\n",
      "1190/1190 [==============================] - 1s 846us/sample - loss: 0.1675 - combined_decoder_loss: 0.1672\n",
      "Epoch 1789/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1686 - combined_decoder_loss: 0.1683\n",
      "Epoch 1790/3000\n",
      "1190/1190 [==============================] - 1s 844us/sample - loss: 0.1687 - combined_decoder_loss: 0.1681\n",
      "Epoch 1791/3000\n",
      "1190/1190 [==============================] - 1s 843us/sample - loss: 0.1674 - combined_decoder_loss: 0.1685\n",
      "Epoch 1792/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.1679 - combined_decoder_loss: 0.1675\n",
      "Epoch 1793/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1702 - combined_decoder_loss: 0.1703\n",
      "Epoch 1794/3000\n",
      "1190/1190 [==============================] - 1s 834us/sample - loss: 0.1692 - combined_decoder_loss: 0.1692\n",
      "Epoch 1795/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1695 - combined_decoder_loss: 0.1695\n",
      "Epoch 1796/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1669 - combined_decoder_loss: 0.1666\n",
      "Epoch 1797/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1673 - combined_decoder_loss: 0.1673\n",
      "Epoch 1798/3000\n",
      "1190/1190 [==============================] - 1s 835us/sample - loss: 0.1703 - combined_decoder_loss: 0.1707\n",
      "Epoch 1799/3000\n",
      "1190/1190 [==============================] - 1s 843us/sample - loss: 0.1686 - combined_decoder_loss: 0.1689\n",
      "Epoch 1800/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1758 - combined_decoder_loss: 0.1757\n",
      "Epoch 1801/3000\n",
      "1190/1190 [==============================] - 1s 854us/sample - loss: 0.1678 - combined_decoder_loss: 0.1682\n",
      "Epoch 1802/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1698 - combined_decoder_loss: 0.1700\n",
      "Epoch 1803/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1699 - combined_decoder_loss: 0.1699\n",
      "Epoch 1804/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1693 - combined_decoder_loss: 0.1691\n",
      "Epoch 1805/3000\n",
      "1190/1190 [==============================] - 1s 843us/sample - loss: 0.1663 - combined_decoder_loss: 0.1666\n",
      "Epoch 1806/3000\n",
      "1190/1190 [==============================] - 1s 842us/sample - loss: 0.1701 - combined_decoder_loss: 0.1699\n",
      "Epoch 1807/3000\n",
      "1190/1190 [==============================] - 1s 835us/sample - loss: 0.1690 - combined_decoder_loss: 0.1690\n",
      "Epoch 1808/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.1697 - combined_decoder_loss: 0.1696\n",
      "Epoch 1809/3000\n",
      "1190/1190 [==============================] - 1s 842us/sample - loss: 0.1691 - combined_decoder_loss: 0.1691\n",
      "Epoch 1810/3000\n",
      "1190/1190 [==============================] - 1s 841us/sample - loss: 0.1822 - combined_decoder_loss: 0.1818\n",
      "Epoch 1811/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1729 - combined_decoder_loss: 0.1728\n",
      "Epoch 1812/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1680 - combined_decoder_loss: 0.1680\n",
      "Epoch 1813/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1686 - combined_decoder_loss: 0.1684\n",
      "Epoch 1814/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.1679 - combined_decoder_loss: 0.1678\n",
      "Epoch 1815/3000\n",
      "1190/1190 [==============================] - 1s 836us/sample - loss: 0.1799 - combined_decoder_loss: 0.1800\n",
      "Epoch 1816/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1687 - combined_decoder_loss: 0.1688\n",
      "Epoch 1817/3000\n",
      "1190/1190 [==============================] - 1s 843us/sample - loss: 0.1682 - combined_decoder_loss: 0.1679\n",
      "Epoch 1818/3000\n",
      "1190/1190 [==============================] - 1s 841us/sample - loss: 0.1853 - combined_decoder_loss: 0.1849\n",
      "Epoch 1819/3000\n",
      "1190/1190 [==============================] - 1s 841us/sample - loss: 0.1666 - combined_decoder_loss: 0.1664\n",
      "Epoch 1820/3000\n",
      "1190/1190 [==============================] - 1s 834us/sample - loss: 0.1689 - combined_decoder_loss: 0.1689\n",
      "Epoch 1821/3000\n",
      "1190/1190 [==============================] - 1s 842us/sample - loss: 0.1670 - combined_decoder_loss: 0.1667\n",
      "Epoch 1822/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1696 - combined_decoder_loss: 0.1692\n",
      "Epoch 1823/3000\n",
      "1190/1190 [==============================] - 1s 836us/sample - loss: 0.1689 - combined_decoder_loss: 0.1686\n",
      "Epoch 1824/3000\n",
      "1190/1190 [==============================] - 1s 843us/sample - loss: 0.1700 - combined_decoder_loss: 0.1700\n",
      "Epoch 1825/3000\n",
      "1190/1190 [==============================] - 1s 836us/sample - loss: 0.1718 - combined_decoder_loss: 0.1718\n",
      "Epoch 1826/3000\n",
      "1190/1190 [==============================] - 1s 836us/sample - loss: 0.1722 - combined_decoder_loss: 0.1717\n",
      "Epoch 1827/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1679 - combined_decoder_loss: 0.1678\n",
      "Epoch 1828/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1735 - combined_decoder_loss: 0.1730\n",
      "Epoch 1829/3000\n",
      "1190/1190 [==============================] - 1s 842us/sample - loss: 0.1684 - combined_decoder_loss: 0.1691\n",
      "Epoch 1830/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1678 - combined_decoder_loss: 0.1674\n",
      "Epoch 1831/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.1689 - combined_decoder_loss: 0.1687\n",
      "Epoch 1832/3000\n",
      "1190/1190 [==============================] - 1s 836us/sample - loss: 0.1691 - combined_decoder_loss: 0.1691\n",
      "Epoch 1833/3000\n",
      "1190/1190 [==============================] - 1s 841us/sample - loss: 0.1712 - combined_decoder_loss: 0.1709\n",
      "Epoch 1834/3000\n",
      "1190/1190 [==============================] - 1s 844us/sample - loss: 0.1676 - combined_decoder_loss: 0.1676\n",
      "Epoch 1835/3000\n",
      "1190/1190 [==============================] - 1s 844us/sample - loss: 0.1712 - combined_decoder_loss: 0.1709\n",
      "Epoch 1836/3000\n",
      "1190/1190 [==============================] - 1s 834us/sample - loss: 0.1671 - combined_decoder_loss: 0.1672\n",
      "Epoch 1837/3000\n",
      "1190/1190 [==============================] - 1s 827us/sample - loss: 0.1683 - combined_decoder_loss: 0.1681\n",
      "Epoch 1838/3000\n",
      "1190/1190 [==============================] - 1s 852us/sample - loss: 0.1704 - combined_decoder_loss: 0.1701\n",
      "Epoch 1839/3000\n",
      "1190/1190 [==============================] - 1s 848us/sample - loss: 0.1663 - combined_decoder_loss: 0.1665\n",
      "Epoch 1840/3000\n",
      "1190/1190 [==============================] - 1s 843us/sample - loss: 0.1690 - combined_decoder_loss: 0.1688\n",
      "Epoch 1841/3000\n",
      "1190/1190 [==============================] - 1s 835us/sample - loss: 0.1744 - combined_decoder_loss: 0.1740\n",
      "Epoch 1842/3000\n",
      "1190/1190 [==============================] - 1s 842us/sample - loss: 0.1694 - combined_decoder_loss: 0.1697\n",
      "Epoch 1843/3000\n",
      "1190/1190 [==============================] - 1s 835us/sample - loss: 0.1703 - combined_decoder_loss: 0.1701\n",
      "Epoch 1844/3000\n",
      "1190/1190 [==============================] - 1s 842us/sample - loss: 0.1689 - combined_decoder_loss: 0.1691\n",
      "Epoch 1845/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1756 - combined_decoder_loss: 0.1753\n",
      "Epoch 1846/3000\n",
      "1190/1190 [==============================] - 1s 833us/sample - loss: 0.1685 - combined_decoder_loss: 0.1689\n",
      "Epoch 1847/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1190/1190 [==============================] - 1s 836us/sample - loss: 0.1686 - combined_decoder_loss: 0.1685\n",
      "Epoch 1848/3000\n",
      "1190/1190 [==============================] - 1s 852us/sample - loss: 0.1688 - combined_decoder_loss: 0.1684\n",
      "Epoch 1849/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.1712 - combined_decoder_loss: 0.1711\n",
      "Epoch 1850/3000\n",
      "1190/1190 [==============================] - 1s 841us/sample - loss: 0.1694 - combined_decoder_loss: 0.1690\n",
      "Epoch 1851/3000\n",
      "1190/1190 [==============================] - 1s 842us/sample - loss: 0.1683 - combined_decoder_loss: 0.1683\n",
      "Epoch 1852/3000\n",
      "1190/1190 [==============================] - 1s 835us/sample - loss: 0.1700 - combined_decoder_loss: 0.1697\n",
      "Epoch 1853/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1666 - combined_decoder_loss: 0.1674\n",
      "Epoch 1854/3000\n",
      "1190/1190 [==============================] - 1s 834us/sample - loss: 0.1727 - combined_decoder_loss: 0.1730\n",
      "Epoch 1855/3000\n",
      "1190/1190 [==============================] - 1s 850us/sample - loss: 0.1694 - combined_decoder_loss: 0.1692\n",
      "Epoch 1856/3000\n",
      "1190/1190 [==============================] - 1s 853us/sample - loss: 0.1677 - combined_decoder_loss: 0.1675\n",
      "Epoch 1857/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1702 - combined_decoder_loss: 0.1707\n",
      "Epoch 1858/3000\n",
      "1190/1190 [==============================] - 1s 833us/sample - loss: 0.1696 - combined_decoder_loss: 0.1697\n",
      "Epoch 1859/3000\n",
      "1190/1190 [==============================] - 1s 848us/sample - loss: 0.1678 - combined_decoder_loss: 0.1675\n",
      "Epoch 1860/3000\n",
      "1190/1190 [==============================] - 1s 835us/sample - loss: 0.1703 - combined_decoder_loss: 0.1703\n",
      "Epoch 1861/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1696 - combined_decoder_loss: 0.1701\n",
      "Epoch 1862/3000\n",
      "1190/1190 [==============================] - 1s 843us/sample - loss: 0.1673 - combined_decoder_loss: 0.1674\n",
      "Epoch 1863/3000\n",
      "1190/1190 [==============================] - 1s 841us/sample - loss: 0.1724 - combined_decoder_loss: 0.1723\n",
      "Epoch 1864/3000\n",
      "1190/1190 [==============================] - 1s 844us/sample - loss: 0.1685 - combined_decoder_loss: 0.1682\n",
      "Epoch 1865/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1730 - combined_decoder_loss: 0.1729\n",
      "Epoch 1866/3000\n",
      "1190/1190 [==============================] - 1s 831us/sample - loss: 0.1679 - combined_decoder_loss: 0.1680\n",
      "Epoch 1867/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1660 - combined_decoder_loss: 0.1656\n",
      "Epoch 1868/3000\n",
      "1190/1190 [==============================] - 1s 844us/sample - loss: 0.1682 - combined_decoder_loss: 0.1680\n",
      "Epoch 1869/3000\n",
      "1190/1190 [==============================] - 1s 857us/sample - loss: 0.1756 - combined_decoder_loss: 0.1756\n",
      "Epoch 1870/3000\n",
      "1190/1190 [==============================] - 1s 865us/sample - loss: 0.1673 - combined_decoder_loss: 0.1681\n",
      "Epoch 1871/3000\n",
      "1190/1190 [==============================] - 1s 866us/sample - loss: 0.1671 - combined_decoder_loss: 0.1669\n",
      "Epoch 1872/3000\n",
      "1190/1190 [==============================] - 1s 856us/sample - loss: 0.1681 - combined_decoder_loss: 0.1678\n",
      "Epoch 1873/3000\n",
      "1190/1190 [==============================] - 1s 842us/sample - loss: 0.1794 - combined_decoder_loss: 0.1788\n",
      "Epoch 1874/3000\n",
      "1190/1190 [==============================] - 1s 857us/sample - loss: 0.1689 - combined_decoder_loss: 0.1688\n",
      "Epoch 1875/3000\n",
      "1190/1190 [==============================] - 1s 848us/sample - loss: 0.1691 - combined_decoder_loss: 0.1691\n",
      "Epoch 1876/3000\n",
      "1190/1190 [==============================] - 1s 836us/sample - loss: 0.1681 - combined_decoder_loss: 0.1678\n",
      "Epoch 1877/3000\n",
      "1190/1190 [==============================] - 1s 855us/sample - loss: 0.1683 - combined_decoder_loss: 0.1682\n",
      "Epoch 1878/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1702 - combined_decoder_loss: 0.1697\n",
      "Epoch 1879/3000\n",
      "1190/1190 [==============================] - 1s 848us/sample - loss: 0.1668 - combined_decoder_loss: 0.1667\n",
      "Epoch 1880/3000\n",
      "1190/1190 [==============================] - 1s 863us/sample - loss: 0.1688 - combined_decoder_loss: 0.1687\n",
      "Epoch 1881/3000\n",
      "1190/1190 [==============================] - 1s 852us/sample - loss: 0.1678 - combined_decoder_loss: 0.1675\n",
      "Epoch 1882/3000\n",
      "1190/1190 [==============================] - 1s 849us/sample - loss: 0.1703 - combined_decoder_loss: 0.1703\n",
      "Epoch 1883/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1721 - combined_decoder_loss: 0.1726\n",
      "Epoch 1884/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1703 - combined_decoder_loss: 0.1700\n",
      "Epoch 1885/3000\n",
      "1190/1190 [==============================] - 1s 834us/sample - loss: 0.1695 - combined_decoder_loss: 0.1692\n",
      "Epoch 1886/3000\n",
      "1190/1190 [==============================] - 1s 844us/sample - loss: 0.1717 - combined_decoder_loss: 0.1715\n",
      "Epoch 1887/3000\n",
      "1190/1190 [==============================] - 1s 852us/sample - loss: 0.1685 - combined_decoder_loss: 0.1685\n",
      "Epoch 1888/3000\n",
      "1190/1190 [==============================] - 1s 853us/sample - loss: 0.1679 - combined_decoder_loss: 0.1676\n",
      "Epoch 1889/3000\n",
      "1190/1190 [==============================] - 1s 849us/sample - loss: 0.1739 - combined_decoder_loss: 0.1740\n",
      "Epoch 1890/3000\n",
      "1190/1190 [==============================] - 1s 851us/sample - loss: 0.1665 - combined_decoder_loss: 0.1663\n",
      "Epoch 1891/3000\n",
      "1190/1190 [==============================] - 1s 842us/sample - loss: 0.1679 - combined_decoder_loss: 0.1680\n",
      "Epoch 1892/3000\n",
      "1190/1190 [==============================] - 1s 844us/sample - loss: 0.1741 - combined_decoder_loss: 0.1735\n",
      "Epoch 1893/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1670 - combined_decoder_loss: 0.1670\n",
      "Epoch 1894/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1697 - combined_decoder_loss: 0.1702\n",
      "Epoch 1895/3000\n",
      "1190/1190 [==============================] - 1s 855us/sample - loss: 0.1671 - combined_decoder_loss: 0.1671\n",
      "Epoch 1896/3000\n",
      "1190/1190 [==============================] - 1s 850us/sample - loss: 0.1683 - combined_decoder_loss: 0.1686\n",
      "Epoch 1897/3000\n",
      "1190/1190 [==============================] - 1s 841us/sample - loss: 0.1861 - combined_decoder_loss: 0.1853\n",
      "Epoch 1898/3000\n",
      "1190/1190 [==============================] - 1s 844us/sample - loss: 0.1675 - combined_decoder_loss: 0.1672\n",
      "Epoch 1899/3000\n",
      "1190/1190 [==============================] - 1s 844us/sample - loss: 0.1687 - combined_decoder_loss: 0.1689\n",
      "Epoch 1900/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1686 - combined_decoder_loss: 0.1685\n",
      "Epoch 1901/3000\n",
      "1190/1190 [==============================] - 1s 854us/sample - loss: 0.1717 - combined_decoder_loss: 0.1717\n",
      "Epoch 1902/3000\n",
      "1190/1190 [==============================] - 1s 851us/sample - loss: 0.1674 - combined_decoder_loss: 0.1672\n",
      "Epoch 1903/3000\n",
      "1190/1190 [==============================] - 1s 842us/sample - loss: 0.1678 - combined_decoder_loss: 0.1681\n",
      "Epoch 1904/3000\n",
      "1190/1190 [==============================] - 1s 841us/sample - loss: 0.1686 - combined_decoder_loss: 0.1690\n",
      "Epoch 1905/3000\n",
      "1190/1190 [==============================] - 1s 848us/sample - loss: 0.1693 - combined_decoder_loss: 0.1698\n",
      "Epoch 1906/3000\n",
      "1190/1190 [==============================] - 1s 842us/sample - loss: 0.1668 - combined_decoder_loss: 0.1664\n",
      "Epoch 1907/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.1694 - combined_decoder_loss: 0.1699\n",
      "Epoch 1908/3000\n",
      "1190/1190 [==============================] - 1s 851us/sample - loss: 0.1686 - combined_decoder_loss: 0.1685\n",
      "Epoch 1909/3000\n",
      "1190/1190 [==============================] - 1s 823us/sample - loss: 0.1692 - combined_decoder_loss: 0.1691\n",
      "Epoch 1910/3000\n",
      "1190/1190 [==============================] - 1s 841us/sample - loss: 0.1685 - combined_decoder_loss: 0.1685\n",
      "Epoch 1911/3000\n",
      "1190/1190 [==============================] - 1s 829us/sample - loss: 0.1684 - combined_decoder_loss: 0.1680\n",
      "Epoch 1912/3000\n",
      "1190/1190 [==============================] - 1s 835us/sample - loss: 0.1691 - combined_decoder_loss: 0.1690\n",
      "Epoch 1913/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1688 - combined_decoder_loss: 0.1684\n",
      "Epoch 1914/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1678 - combined_decoder_loss: 0.1676\n",
      "Epoch 1915/3000\n",
      "1190/1190 [==============================] - 1s 848us/sample - loss: 0.1691 - combined_decoder_loss: 0.1695\n",
      "Epoch 1916/3000\n",
      "1190/1190 [==============================] - 1s 841us/sample - loss: 0.1702 - combined_decoder_loss: 0.1702\n",
      "Epoch 1917/3000\n",
      "1190/1190 [==============================] - 1s 848us/sample - loss: 0.1710 - combined_decoder_loss: 0.1707\n",
      "Epoch 1918/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.1676 - combined_decoder_loss: 0.1677\n",
      "Epoch 1919/3000\n",
      "1190/1190 [==============================] - 1s 835us/sample - loss: 0.1693 - combined_decoder_loss: 0.1692\n",
      "Epoch 1920/3000\n",
      "1190/1190 [==============================] - 1s 848us/sample - loss: 0.1684 - combined_decoder_loss: 0.1678\n",
      "Epoch 1921/3000\n",
      "1190/1190 [==============================] - 1s 868us/sample - loss: 0.1668 - combined_decoder_loss: 0.1666\n",
      "Epoch 1922/3000\n",
      "1190/1190 [==============================] - 1s 846us/sample - loss: 0.1675 - combined_decoder_loss: 0.1673\n",
      "Epoch 1923/3000\n",
      "1190/1190 [==============================] - 1s 868us/sample - loss: 0.1670 - combined_decoder_loss: 0.1667\n",
      "Epoch 1924/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.1675 - combined_decoder_loss: 0.1680\n",
      "Epoch 1925/3000\n",
      "1190/1190 [==============================] - 1s 843us/sample - loss: 0.1675 - combined_decoder_loss: 0.1676\n",
      "Epoch 1926/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1693 - combined_decoder_loss: 0.1694\n",
      "Epoch 1927/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1684 - combined_decoder_loss: 0.1684\n",
      "Epoch 1928/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1690 - combined_decoder_loss: 0.1687\n",
      "Epoch 1929/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1679 - combined_decoder_loss: 0.1687\n",
      "Epoch 1930/3000\n",
      "1190/1190 [==============================] - 1s 846us/sample - loss: 0.1679 - combined_decoder_loss: 0.1679\n",
      "Epoch 1931/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1730 - combined_decoder_loss: 0.1728\n",
      "Epoch 1932/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1674 - combined_decoder_loss: 0.1672\n",
      "Epoch 1933/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1679 - combined_decoder_loss: 0.1678\n",
      "Epoch 1934/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1691 - combined_decoder_loss: 0.1687\n",
      "Epoch 1935/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.1707 - combined_decoder_loss: 0.1706\n",
      "Epoch 1936/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1678 - combined_decoder_loss: 0.1677\n",
      "Epoch 1937/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1673 - combined_decoder_loss: 0.1677\n",
      "Epoch 1938/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.1703 - combined_decoder_loss: 0.1705\n",
      "Epoch 1939/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1677 - combined_decoder_loss: 0.1682\n",
      "Epoch 1940/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1680 - combined_decoder_loss: 0.1683\n",
      "Epoch 1941/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1682 - combined_decoder_loss: 0.1680\n",
      "Epoch 1942/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1691 - combined_decoder_loss: 0.1694\n",
      "Epoch 1943/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1686 - combined_decoder_loss: 0.1690\n",
      "Epoch 1944/3000\n",
      "1190/1190 [==============================] - 1s 841us/sample - loss: 0.1682 - combined_decoder_loss: 0.1679\n",
      "Epoch 1945/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1668 - combined_decoder_loss: 0.1663\n",
      "Epoch 1946/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1694 - combined_decoder_loss: 0.1696\n",
      "Epoch 1947/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1685 - combined_decoder_loss: 0.1682\n",
      "Epoch 1948/3000\n",
      "1190/1190 [==============================] - 1s 833us/sample - loss: 0.1694 - combined_decoder_loss: 0.1695\n",
      "Epoch 1949/3000\n",
      "1190/1190 [==============================] - 1s 833us/sample - loss: 0.1699 - combined_decoder_loss: 0.1695\n",
      "Epoch 1950/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1671 - combined_decoder_loss: 0.1670\n",
      "Epoch 1951/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1697 - combined_decoder_loss: 0.1695\n",
      "Epoch 1952/3000\n",
      "1190/1190 [==============================] - 1s 841us/sample - loss: 0.1757 - combined_decoder_loss: 0.1756\n",
      "Epoch 1953/3000\n",
      "1190/1190 [==============================] - 1s 829us/sample - loss: 0.1666 - combined_decoder_loss: 0.1674\n",
      "Epoch 1954/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1692 - combined_decoder_loss: 0.1690\n",
      "Epoch 1955/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1681 - combined_decoder_loss: 0.1685\n",
      "Epoch 1956/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1686 - combined_decoder_loss: 0.1689\n",
      "Epoch 1957/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.1725 - combined_decoder_loss: 0.1727\n",
      "Epoch 1958/3000\n",
      "1190/1190 [==============================] - 1s 849us/sample - loss: 0.1700 - combined_decoder_loss: 0.1699\n",
      "Epoch 1959/3000\n",
      "1190/1190 [==============================] - 1s 859us/sample - loss: 0.1687 - combined_decoder_loss: 0.1688\n",
      "Epoch 1960/3000\n",
      "1190/1190 [==============================] - 1s 860us/sample - loss: 0.1668 - combined_decoder_loss: 0.1666\n",
      "Epoch 1961/3000\n",
      "1190/1190 [==============================] - 1s 871us/sample - loss: 0.1671 - combined_decoder_loss: 0.1681\n",
      "Epoch 1962/3000\n",
      "1190/1190 [==============================] - 1s 863us/sample - loss: 0.1686 - combined_decoder_loss: 0.1689\n",
      "Epoch 1963/3000\n",
      "1190/1190 [==============================] - 1s 853us/sample - loss: 0.1697 - combined_decoder_loss: 0.1694\n",
      "Epoch 1964/3000\n",
      "1190/1190 [==============================] - 1s 850us/sample - loss: 0.1655 - combined_decoder_loss: 0.1652\n",
      "Epoch 1965/3000\n",
      "1190/1190 [==============================] - 1s 851us/sample - loss: 0.1683 - combined_decoder_loss: 0.1681\n",
      "Epoch 1966/3000\n",
      "1190/1190 [==============================] - 1s 873us/sample - loss: 0.1687 - combined_decoder_loss: 0.1685\n",
      "Epoch 1967/3000\n",
      "1190/1190 [==============================] - 1s 849us/sample - loss: 0.1717 - combined_decoder_loss: 0.1718\n",
      "Epoch 1968/3000\n",
      "1190/1190 [==============================] - 1s 841us/sample - loss: 0.1683 - combined_decoder_loss: 0.1681\n",
      "Epoch 1969/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.1693 - combined_decoder_loss: 0.1694\n",
      "Epoch 1970/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.1664 - combined_decoder_loss: 0.1674\n",
      "Epoch 1971/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1675 - combined_decoder_loss: 0.1672\n",
      "Epoch 1972/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1680 - combined_decoder_loss: 0.1678\n",
      "Epoch 1973/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1680 - combined_decoder_loss: 0.1682\n",
      "Epoch 1974/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1703 - combined_decoder_loss: 0.1705\n",
      "Epoch 1975/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1795 - combined_decoder_loss: 0.1788\n",
      "Epoch 1976/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1660 - combined_decoder_loss: 0.1659\n",
      "Epoch 1977/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1681 - combined_decoder_loss: 0.1677\n",
      "Epoch 1978/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1664 - combined_decoder_loss: 0.1661\n",
      "Epoch 1979/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1190/1190 [==============================] - 1s 831us/sample - loss: 0.1686 - combined_decoder_loss: 0.1691\n",
      "Epoch 1980/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1715 - combined_decoder_loss: 0.1712\n",
      "Epoch 1981/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1675 - combined_decoder_loss: 0.1677\n",
      "Epoch 1982/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1730 - combined_decoder_loss: 0.1733\n",
      "Epoch 1983/3000\n",
      "1190/1190 [==============================] - 1s 846us/sample - loss: 0.1684 - combined_decoder_loss: 0.1685\n",
      "Epoch 1984/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1687 - combined_decoder_loss: 0.1695\n",
      "Epoch 1985/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1679 - combined_decoder_loss: 0.1676\n",
      "Epoch 1986/3000\n",
      "1190/1190 [==============================] - 1s 846us/sample - loss: 0.1669 - combined_decoder_loss: 0.1668\n",
      "Epoch 1987/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.1671 - combined_decoder_loss: 0.1668\n",
      "Epoch 1988/3000\n",
      "1190/1190 [==============================] - 1s 846us/sample - loss: 0.1700 - combined_decoder_loss: 0.1699\n",
      "Epoch 1989/3000\n",
      "1190/1190 [==============================] - 1s 836us/sample - loss: 0.1666 - combined_decoder_loss: 0.1677\n",
      "Epoch 1990/3000\n",
      "1190/1190 [==============================] - 1s 849us/sample - loss: 0.1717 - combined_decoder_loss: 0.1718\n",
      "Epoch 1991/3000\n",
      "1190/1190 [==============================] - 1s 853us/sample - loss: 0.1665 - combined_decoder_loss: 0.1662\n",
      "Epoch 1992/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1697 - combined_decoder_loss: 0.1703\n",
      "Epoch 1993/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1679 - combined_decoder_loss: 0.1677\n",
      "Epoch 1994/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1663 - combined_decoder_loss: 0.1663\n",
      "Epoch 1995/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1680 - combined_decoder_loss: 0.1678\n",
      "Epoch 1996/3000\n",
      "1190/1190 [==============================] - 1s 843us/sample - loss: 0.1680 - combined_decoder_loss: 0.1678\n",
      "Epoch 1997/3000\n",
      "1190/1190 [==============================] - 1s 877us/sample - loss: 0.1779 - combined_decoder_loss: 0.1775\n",
      "Epoch 1998/3000\n",
      "1190/1190 [==============================] - 1s 859us/sample - loss: 0.1676 - combined_decoder_loss: 0.1675\n",
      "Epoch 1999/3000\n",
      "1190/1190 [==============================] - 1s 851us/sample - loss: 0.1719 - combined_decoder_loss: 0.1718\n",
      "Epoch 2000/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1688 - combined_decoder_loss: 0.1685\n",
      "Epoch 2001/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1696 - combined_decoder_loss: 0.1693\n",
      "Epoch 2002/3000\n",
      "1190/1190 [==============================] - 1s 861us/sample - loss: 0.1701 - combined_decoder_loss: 0.1703\n",
      "Epoch 2003/3000\n",
      "1190/1190 [==============================] - 1s 843us/sample - loss: 0.1665 - combined_decoder_loss: 0.1667\n",
      "Epoch 2004/3000\n",
      "1190/1190 [==============================] - 1s 859us/sample - loss: 0.1689 - combined_decoder_loss: 0.1688\n",
      "Epoch 2005/3000\n",
      "1190/1190 [==============================] - 1s 849us/sample - loss: 0.1677 - combined_decoder_loss: 0.1675\n",
      "Epoch 2006/3000\n",
      "1190/1190 [==============================] - 1s 849us/sample - loss: 0.1699 - combined_decoder_loss: 0.1702\n",
      "Epoch 2007/3000\n",
      "1190/1190 [==============================] - 1s 855us/sample - loss: 0.1696 - combined_decoder_loss: 0.1695\n",
      "Epoch 2008/3000\n",
      "1190/1190 [==============================] - 1s 850us/sample - loss: 0.1675 - combined_decoder_loss: 0.1672\n",
      "Epoch 2009/3000\n",
      "1190/1190 [==============================] - 1s 855us/sample - loss: 0.1686 - combined_decoder_loss: 0.1682\n",
      "Epoch 2010/3000\n",
      "1190/1190 [==============================] - 1s 853us/sample - loss: 0.1674 - combined_decoder_loss: 0.1673\n",
      "Epoch 2011/3000\n",
      "1190/1190 [==============================] - 1s 846us/sample - loss: 0.1665 - combined_decoder_loss: 0.1664\n",
      "Epoch 2012/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.1677 - combined_decoder_loss: 0.1673\n",
      "Epoch 2013/3000\n",
      "1190/1190 [==============================] - 1s 848us/sample - loss: 0.1661 - combined_decoder_loss: 0.1667\n",
      "Epoch 2014/3000\n",
      "1190/1190 [==============================] - 1s 852us/sample - loss: 0.1682 - combined_decoder_loss: 0.1679\n",
      "Epoch 2015/3000\n",
      "1190/1190 [==============================] - 1s 857us/sample - loss: 0.1695 - combined_decoder_loss: 0.1696\n",
      "Epoch 2016/3000\n",
      "1190/1190 [==============================] - 1s 848us/sample - loss: 0.1696 - combined_decoder_loss: 0.1695\n",
      "Epoch 2017/3000\n",
      "1190/1190 [==============================] - 1s 851us/sample - loss: 0.1664 - combined_decoder_loss: 0.1666\n",
      "Epoch 2018/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.1677 - combined_decoder_loss: 0.1678\n",
      "Epoch 2019/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1669 - combined_decoder_loss: 0.1671\n",
      "Epoch 2020/3000\n",
      "1190/1190 [==============================] - 1s 852us/sample - loss: 0.1679 - combined_decoder_loss: 0.1673\n",
      "Epoch 2021/3000\n",
      "1190/1190 [==============================] - 1s 844us/sample - loss: 0.1696 - combined_decoder_loss: 0.1696\n",
      "Epoch 2022/3000\n",
      "1190/1190 [==============================] - 1s 864us/sample - loss: 0.1674 - combined_decoder_loss: 0.1682\n",
      "Epoch 2023/3000\n",
      "1190/1190 [==============================] - 1s 848us/sample - loss: 0.1671 - combined_decoder_loss: 0.1666\n",
      "Epoch 2024/3000\n",
      "1190/1190 [==============================] - 1s 841us/sample - loss: 0.1689 - combined_decoder_loss: 0.1692\n",
      "Epoch 2025/3000\n",
      "1190/1190 [==============================] - 1s 844us/sample - loss: 0.1672 - combined_decoder_loss: 0.1671\n",
      "Epoch 2026/3000\n",
      "1190/1190 [==============================] - 1s 844us/sample - loss: 0.1684 - combined_decoder_loss: 0.1682\n",
      "Epoch 2027/3000\n",
      "1190/1190 [==============================] - 1s 853us/sample - loss: 0.1701 - combined_decoder_loss: 0.1702\n",
      "Epoch 2028/3000\n",
      "1190/1190 [==============================] - 1s 865us/sample - loss: 0.1818 - combined_decoder_loss: 0.1818\n",
      "Epoch 2029/3000\n",
      "1190/1190 [==============================] - 1s 854us/sample - loss: 0.1677 - combined_decoder_loss: 0.1674\n",
      "Epoch 2030/3000\n",
      "1190/1190 [==============================] - 1s 846us/sample - loss: 0.1699 - combined_decoder_loss: 0.1699\n",
      "Epoch 2031/3000\n",
      "1190/1190 [==============================] - 1s 842us/sample - loss: 0.1670 - combined_decoder_loss: 0.1668\n",
      "Epoch 2032/3000\n",
      "1190/1190 [==============================] - 1s 848us/sample - loss: 0.1670 - combined_decoder_loss: 0.1670\n",
      "Epoch 2033/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.1670 - combined_decoder_loss: 0.1669\n",
      "Epoch 2034/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1669 - combined_decoder_loss: 0.1667\n",
      "Epoch 2035/3000\n",
      "1190/1190 [==============================] - 1s 844us/sample - loss: 0.1694 - combined_decoder_loss: 0.1695\n",
      "Epoch 2036/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1720 - combined_decoder_loss: 0.1717\n",
      "Epoch 2037/3000\n",
      "1190/1190 [==============================] - 1s 843us/sample - loss: 0.1691 - combined_decoder_loss: 0.1688\n",
      "Epoch 2038/3000\n",
      "1190/1190 [==============================] - 1s 824us/sample - loss: 0.1666 - combined_decoder_loss: 0.1669\n",
      "Epoch 2039/3000\n",
      "1190/1190 [==============================] - 1s 831us/sample - loss: 0.1673 - combined_decoder_loss: 0.1675\n",
      "Epoch 2040/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1676 - combined_decoder_loss: 0.1674\n",
      "Epoch 2041/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1770 - combined_decoder_loss: 0.1769\n",
      "Epoch 2042/3000\n",
      "1190/1190 [==============================] - 1s 846us/sample - loss: 0.1667 - combined_decoder_loss: 0.1665\n",
      "Epoch 2043/3000\n",
      "1190/1190 [==============================] - 1s 833us/sample - loss: 0.1656 - combined_decoder_loss: 0.1654\n",
      "Epoch 2044/3000\n",
      "1190/1190 [==============================] - 1s 841us/sample - loss: 0.1689 - combined_decoder_loss: 0.1688\n",
      "Epoch 2045/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1744 - combined_decoder_loss: 0.1741\n",
      "Epoch 2046/3000\n",
      "1190/1190 [==============================] - 1s 836us/sample - loss: 0.1705 - combined_decoder_loss: 0.1703\n",
      "Epoch 2047/3000\n",
      "1190/1190 [==============================] - 1s 841us/sample - loss: 0.1671 - combined_decoder_loss: 0.1670\n",
      "Epoch 2048/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1790 - combined_decoder_loss: 0.1787\n",
      "Epoch 2049/3000\n",
      "1190/1190 [==============================] - 1s 846us/sample - loss: 0.1658 - combined_decoder_loss: 0.1664\n",
      "Epoch 2050/3000\n",
      "1190/1190 [==============================] - 1s 831us/sample - loss: 0.1678 - combined_decoder_loss: 0.1676\n",
      "Epoch 2051/3000\n",
      "1190/1190 [==============================] - 1s 824us/sample - loss: 0.1722 - combined_decoder_loss: 0.1717\n",
      "Epoch 2052/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1676 - combined_decoder_loss: 0.1673\n",
      "Epoch 2053/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1674 - combined_decoder_loss: 0.1673\n",
      "Epoch 2054/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1687 - combined_decoder_loss: 0.1683\n",
      "Epoch 2055/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1665 - combined_decoder_loss: 0.1664\n",
      "Epoch 2056/3000\n",
      "1190/1190 [==============================] - 1s 843us/sample - loss: 0.1673 - combined_decoder_loss: 0.1671\n",
      "Epoch 2057/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1674 - combined_decoder_loss: 0.1676\n",
      "Epoch 2058/3000\n",
      "1190/1190 [==============================] - 1s 841us/sample - loss: 0.1683 - combined_decoder_loss: 0.1681\n",
      "Epoch 2059/3000\n",
      "1190/1190 [==============================] - 1s 848us/sample - loss: 0.1743 - combined_decoder_loss: 0.1739\n",
      "Epoch 2060/3000\n",
      "1190/1190 [==============================] - 1s 863us/sample - loss: 0.1690 - combined_decoder_loss: 0.1691\n",
      "Epoch 2061/3000\n",
      "1190/1190 [==============================] - 1s 844us/sample - loss: 0.1672 - combined_decoder_loss: 0.1672\n",
      "Epoch 2062/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1660 - combined_decoder_loss: 0.1660\n",
      "Epoch 2063/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1727 - combined_decoder_loss: 0.1723\n",
      "Epoch 2064/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1690 - combined_decoder_loss: 0.1695\n",
      "Epoch 2065/3000\n",
      "1190/1190 [==============================] - 1s 836us/sample - loss: 0.1683 - combined_decoder_loss: 0.1685\n",
      "Epoch 2066/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1697 - combined_decoder_loss: 0.1696\n",
      "Epoch 2067/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.1691 - combined_decoder_loss: 0.1700\n",
      "Epoch 2068/3000\n",
      "1190/1190 [==============================] - 1s 826us/sample - loss: 0.1676 - combined_decoder_loss: 0.1677\n",
      "Epoch 2069/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1674 - combined_decoder_loss: 0.1671\n",
      "Epoch 2070/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1676 - combined_decoder_loss: 0.1679\n",
      "Epoch 2071/3000\n",
      "1190/1190 [==============================] - 1s 835us/sample - loss: 0.1675 - combined_decoder_loss: 0.1677\n",
      "Epoch 2072/3000\n",
      "1190/1190 [==============================] - 1s 833us/sample - loss: 0.1679 - combined_decoder_loss: 0.1677\n",
      "Epoch 2073/3000\n",
      "1190/1190 [==============================] - 1s 834us/sample - loss: 0.1677 - combined_decoder_loss: 0.1694\n",
      "Epoch 2074/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1693 - combined_decoder_loss: 0.1690\n",
      "Epoch 2075/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1682 - combined_decoder_loss: 0.1682\n",
      "Epoch 2076/3000\n",
      "1190/1190 [==============================] - 1s 851us/sample - loss: 0.1687 - combined_decoder_loss: 0.1687\n",
      "Epoch 2077/3000\n",
      "1190/1190 [==============================] - 1s 829us/sample - loss: 0.1691 - combined_decoder_loss: 0.1688\n",
      "Epoch 2078/3000\n",
      "1190/1190 [==============================] - 1s 831us/sample - loss: 0.1673 - combined_decoder_loss: 0.1674\n",
      "Epoch 2079/3000\n",
      "1190/1190 [==============================] - 1s 848us/sample - loss: 0.1658 - combined_decoder_loss: 0.1656\n",
      "Epoch 2080/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1681 - combined_decoder_loss: 0.1676\n",
      "Epoch 2081/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1740 - combined_decoder_loss: 0.1739\n",
      "Epoch 2082/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1707 - combined_decoder_loss: 0.1704\n",
      "Epoch 2083/3000\n",
      "1190/1190 [==============================] - 1s 831us/sample - loss: 0.1685 - combined_decoder_loss: 0.1683\n",
      "Epoch 2084/3000\n",
      "1190/1190 [==============================] - 1s 846us/sample - loss: 0.1707 - combined_decoder_loss: 0.1704\n",
      "Epoch 2085/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1666 - combined_decoder_loss: 0.1666\n",
      "Epoch 2086/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1701 - combined_decoder_loss: 0.1700\n",
      "Epoch 2087/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1674 - combined_decoder_loss: 0.1675\n",
      "Epoch 2088/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1699 - combined_decoder_loss: 0.1701\n",
      "Epoch 2089/3000\n",
      "1190/1190 [==============================] - 1s 841us/sample - loss: 0.1670 - combined_decoder_loss: 0.1671\n",
      "Epoch 2090/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1739 - combined_decoder_loss: 0.1738\n",
      "Epoch 2091/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1671 - combined_decoder_loss: 0.1669\n",
      "Epoch 2092/3000\n",
      "1190/1190 [==============================] - 1s 836us/sample - loss: 0.1670 - combined_decoder_loss: 0.1670\n",
      "Epoch 2093/3000\n",
      "1190/1190 [==============================] - 1s 844us/sample - loss: 0.1668 - combined_decoder_loss: 0.1668\n",
      "Epoch 2094/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1688 - combined_decoder_loss: 0.1683\n",
      "Epoch 2095/3000\n",
      "1190/1190 [==============================] - 1s 844us/sample - loss: 0.1659 - combined_decoder_loss: 0.1658\n",
      "Epoch 2096/3000\n",
      "1190/1190 [==============================] - 1s 843us/sample - loss: 0.1696 - combined_decoder_loss: 0.1695\n",
      "Epoch 2097/3000\n",
      "1190/1190 [==============================] - 1s 843us/sample - loss: 0.1663 - combined_decoder_loss: 0.1659\n",
      "Epoch 2098/3000\n",
      "1190/1190 [==============================] - 1s 853us/sample - loss: 0.1669 - combined_decoder_loss: 0.1669\n",
      "Epoch 2099/3000\n",
      "1190/1190 [==============================] - 1s 842us/sample - loss: 0.1661 - combined_decoder_loss: 0.1658\n",
      "Epoch 2100/3000\n",
      "1190/1190 [==============================] - 1s 833us/sample - loss: 0.1670 - combined_decoder_loss: 0.1674\n",
      "Epoch 2101/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1676 - combined_decoder_loss: 0.1676\n",
      "Epoch 2102/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1703 - combined_decoder_loss: 0.1703\n",
      "Epoch 2103/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1679 - combined_decoder_loss: 0.1677\n",
      "Epoch 2104/3000\n",
      "1190/1190 [==============================] - 1s 833us/sample - loss: 0.1677 - combined_decoder_loss: 0.1675\n",
      "Epoch 2105/3000\n",
      "1190/1190 [==============================] - 1s 835us/sample - loss: 0.1729 - combined_decoder_loss: 0.1728\n",
      "Epoch 2106/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1769 - combined_decoder_loss: 0.1769\n",
      "Epoch 2107/3000\n",
      "1190/1190 [==============================] - 1s 867us/sample - loss: 0.1668 - combined_decoder_loss: 0.1684\n",
      "Epoch 2108/3000\n",
      "1190/1190 [==============================] - 1s 880us/sample - loss: 0.1673 - combined_decoder_loss: 0.1684\n",
      "Epoch 2109/3000\n",
      "1190/1190 [==============================] - 1s 868us/sample - loss: 0.1675 - combined_decoder_loss: 0.1674\n",
      "Epoch 2110/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1700 - combined_decoder_loss: 0.1700\n",
      "Epoch 2111/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1190/1190 [==============================] - 1s 861us/sample - loss: 0.1658 - combined_decoder_loss: 0.1653\n",
      "Epoch 2112/3000\n",
      "1190/1190 [==============================] - 1s 861us/sample - loss: 0.1680 - combined_decoder_loss: 0.1679\n",
      "Epoch 2113/3000\n",
      "1190/1190 [==============================] - 1s 868us/sample - loss: 0.1688 - combined_decoder_loss: 0.1689\n",
      "Epoch 2114/3000\n",
      "1190/1190 [==============================] - 1s 871us/sample - loss: 0.1656 - combined_decoder_loss: 0.1658\n",
      "Epoch 2115/3000\n",
      "1190/1190 [==============================] - 1s 860us/sample - loss: 0.1835 - combined_decoder_loss: 0.1832\n",
      "Epoch 2116/3000\n",
      "1190/1190 [==============================] - 1s 868us/sample - loss: 0.1671 - combined_decoder_loss: 0.1672\n",
      "Epoch 2117/3000\n",
      "1190/1190 [==============================] - 1s 872us/sample - loss: 0.1705 - combined_decoder_loss: 0.1707\n",
      "Epoch 2118/3000\n",
      "1190/1190 [==============================] - 1s 862us/sample - loss: 0.1724 - combined_decoder_loss: 0.1723\n",
      "Epoch 2119/3000\n",
      "1190/1190 [==============================] - 1s 875us/sample - loss: 0.1670 - combined_decoder_loss: 0.1669\n",
      "Epoch 2120/3000\n",
      "1190/1190 [==============================] - 1s 848us/sample - loss: 0.1676 - combined_decoder_loss: 0.1675\n",
      "Epoch 2121/3000\n",
      "1190/1190 [==============================] - 1s 854us/sample - loss: 0.1674 - combined_decoder_loss: 0.1674\n",
      "Epoch 2122/3000\n",
      "1190/1190 [==============================] - 1s 860us/sample - loss: 0.1679 - combined_decoder_loss: 0.1684\n",
      "Epoch 2123/3000\n",
      "1190/1190 [==============================] - 1s 880us/sample - loss: 0.1657 - combined_decoder_loss: 0.1658\n",
      "Epoch 2124/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1684 - combined_decoder_loss: 0.1682\n",
      "Epoch 2125/3000\n",
      "1190/1190 [==============================] - 1s 861us/sample - loss: 0.1664 - combined_decoder_loss: 0.1660\n",
      "Epoch 2126/3000\n",
      "1190/1190 [==============================] - 1s 841us/sample - loss: 0.1694 - combined_decoder_loss: 0.1699\n",
      "Epoch 2127/3000\n",
      "1190/1190 [==============================] - 1s 844us/sample - loss: 0.1691 - combined_decoder_loss: 0.1690\n",
      "Epoch 2128/3000\n",
      "1190/1190 [==============================] - 1s 842us/sample - loss: 0.1694 - combined_decoder_loss: 0.1694\n",
      "Epoch 2129/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1676 - combined_decoder_loss: 0.1677\n",
      "Epoch 2130/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1741 - combined_decoder_loss: 0.1738\n",
      "Epoch 2131/3000\n",
      "1190/1190 [==============================] - 1s 833us/sample - loss: 0.1699 - combined_decoder_loss: 0.1700\n",
      "Epoch 2132/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1705 - combined_decoder_loss: 0.1711\n",
      "Epoch 2133/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1688 - combined_decoder_loss: 0.1691\n",
      "Epoch 2134/3000\n",
      "1190/1190 [==============================] - 1s 842us/sample - loss: 0.1693 - combined_decoder_loss: 0.1694\n",
      "Epoch 2135/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1688 - combined_decoder_loss: 0.1686\n",
      "Epoch 2136/3000\n",
      "1190/1190 [==============================] - 1s 835us/sample - loss: 0.1673 - combined_decoder_loss: 0.1675\n",
      "Epoch 2137/3000\n",
      "1190/1190 [==============================] - 1s 833us/sample - loss: 0.1674 - combined_decoder_loss: 0.1672\n",
      "Epoch 2138/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1659 - combined_decoder_loss: 0.1662\n",
      "Epoch 2139/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1824 - combined_decoder_loss: 0.1819\n",
      "Epoch 2140/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1697 - combined_decoder_loss: 0.1695\n",
      "Epoch 2141/3000\n",
      "1190/1190 [==============================] - 1s 833us/sample - loss: 0.1683 - combined_decoder_loss: 0.1682\n",
      "Epoch 2142/3000\n",
      "1190/1190 [==============================] - 1s 854us/sample - loss: 0.1658 - combined_decoder_loss: 0.1658\n",
      "Epoch 2143/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1673 - combined_decoder_loss: 0.1670\n",
      "Epoch 2144/3000\n",
      "1190/1190 [==============================] - 1s 836us/sample - loss: 0.1685 - combined_decoder_loss: 0.1689\n",
      "Epoch 2145/3000\n",
      "1190/1190 [==============================] - 1s 849us/sample - loss: 0.1726 - combined_decoder_loss: 0.1724\n",
      "Epoch 2146/3000\n",
      "1190/1190 [==============================] - 1s 827us/sample - loss: 0.1675 - combined_decoder_loss: 0.1678\n",
      "Epoch 2147/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1708 - combined_decoder_loss: 0.1703\n",
      "Epoch 2148/3000\n",
      "1190/1190 [==============================] - 1s 846us/sample - loss: 0.1680 - combined_decoder_loss: 0.1680\n",
      "Epoch 2149/3000\n",
      "1190/1190 [==============================] - 1s 849us/sample - loss: 0.1664 - combined_decoder_loss: 0.1664\n",
      "Epoch 2150/3000\n",
      "1190/1190 [==============================] - 1s 841us/sample - loss: 0.1682 - combined_decoder_loss: 0.1679\n",
      "Epoch 2151/3000\n",
      "1190/1190 [==============================] - 1s 852us/sample - loss: 0.1671 - combined_decoder_loss: 0.1672\n",
      "Epoch 2152/3000\n",
      "1190/1190 [==============================] - 1s 842us/sample - loss: 0.1691 - combined_decoder_loss: 0.1688\n",
      "Epoch 2153/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.1670 - combined_decoder_loss: 0.1669\n",
      "Epoch 2154/3000\n",
      "1190/1190 [==============================] - 1s 833us/sample - loss: 0.1657 - combined_decoder_loss: 0.1660\n",
      "Epoch 2155/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1683 - combined_decoder_loss: 0.1680\n",
      "Epoch 2156/3000\n",
      "1190/1190 [==============================] - 1s 843us/sample - loss: 0.1687 - combined_decoder_loss: 0.1696\n",
      "Epoch 2157/3000\n",
      "1190/1190 [==============================] - 1s 842us/sample - loss: 0.1739 - combined_decoder_loss: 0.1738\n",
      "Epoch 2158/3000\n",
      "1190/1190 [==============================] - 1s 852us/sample - loss: 0.1696 - combined_decoder_loss: 0.1698\n",
      "Epoch 2159/3000\n",
      "1190/1190 [==============================] - 1s 876us/sample - loss: 0.1689 - combined_decoder_loss: 0.1687\n",
      "Epoch 2160/3000\n",
      "1190/1190 [==============================] - 1s 868us/sample - loss: 0.1667 - combined_decoder_loss: 0.1664\n",
      "Epoch 2161/3000\n",
      "1190/1190 [==============================] - 1s 852us/sample - loss: 0.1648 - combined_decoder_loss: 0.1653\n",
      "Epoch 2162/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1769 - combined_decoder_loss: 0.1769\n",
      "Epoch 2163/3000\n",
      "1190/1190 [==============================] - 1s 831us/sample - loss: 0.1685 - combined_decoder_loss: 0.1682\n",
      "Epoch 2164/3000\n",
      "1190/1190 [==============================] - 1s 846us/sample - loss: 0.1754 - combined_decoder_loss: 0.1756\n",
      "Epoch 2165/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1666 - combined_decoder_loss: 0.1667\n",
      "Epoch 2166/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1695 - combined_decoder_loss: 0.1698\n",
      "Epoch 2167/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1690 - combined_decoder_loss: 0.1685\n",
      "Epoch 2168/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1682 - combined_decoder_loss: 0.1679\n",
      "Epoch 2169/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1680 - combined_decoder_loss: 0.1681\n",
      "Epoch 2170/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1692 - combined_decoder_loss: 0.1699\n",
      "Epoch 2171/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1673 - combined_decoder_loss: 0.1676\n",
      "Epoch 2172/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1663 - combined_decoder_loss: 0.1664\n",
      "Epoch 2173/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1678 - combined_decoder_loss: 0.1679\n",
      "Epoch 2174/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1672 - combined_decoder_loss: 0.1671\n",
      "Epoch 2175/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1676 - combined_decoder_loss: 0.1674\n",
      "Epoch 2176/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1729 - combined_decoder_loss: 0.1737\n",
      "Epoch 2177/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1665 - combined_decoder_loss: 0.1664\n",
      "Epoch 2178/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1709 - combined_decoder_loss: 0.1710\n",
      "Epoch 2179/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1686 - combined_decoder_loss: 0.1683\n",
      "Epoch 2180/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1675 - combined_decoder_loss: 0.1675\n",
      "Epoch 2181/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1663 - combined_decoder_loss: 0.1663\n",
      "Epoch 2182/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1683 - combined_decoder_loss: 0.1681\n",
      "Epoch 2183/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1696 - combined_decoder_loss: 0.1700\n",
      "Epoch 2184/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1662 - combined_decoder_loss: 0.1659\n",
      "Epoch 2185/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1666 - combined_decoder_loss: 0.1665\n",
      "Epoch 2186/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1675 - combined_decoder_loss: 0.1672\n",
      "Epoch 2187/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1688 - combined_decoder_loss: 0.1691\n",
      "Epoch 2188/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1663 - combined_decoder_loss: 0.1687\n",
      "Epoch 2189/3000\n",
      "1190/1190 [==============================] - 1s 857us/sample - loss: 0.1708 - combined_decoder_loss: 0.1706\n",
      "Epoch 2190/3000\n",
      "1190/1190 [==============================] - 1s 846us/sample - loss: 0.1675 - combined_decoder_loss: 0.1672\n",
      "Epoch 2191/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1688 - combined_decoder_loss: 0.1688\n",
      "Epoch 2192/3000\n",
      "1190/1190 [==============================] - 1s 841us/sample - loss: 0.1683 - combined_decoder_loss: 0.1683\n",
      "Epoch 2193/3000\n",
      "1190/1190 [==============================] - 1s 836us/sample - loss: 0.1685 - combined_decoder_loss: 0.1682\n",
      "Epoch 2194/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1686 - combined_decoder_loss: 0.1691\n",
      "Epoch 2195/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1701 - combined_decoder_loss: 0.1698\n",
      "Epoch 2196/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1661 - combined_decoder_loss: 0.1656\n",
      "Epoch 2197/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1672 - combined_decoder_loss: 0.1670\n",
      "Epoch 2198/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1690 - combined_decoder_loss: 0.1693\n",
      "Epoch 2199/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1655 - combined_decoder_loss: 0.1654\n",
      "Epoch 2200/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1675 - combined_decoder_loss: 0.1674\n",
      "Epoch 2201/3000\n",
      "1190/1190 [==============================] - 1s 831us/sample - loss: 0.1886 - combined_decoder_loss: 0.1879\n",
      "Epoch 2202/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1661 - combined_decoder_loss: 0.1659\n",
      "Epoch 2203/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1666 - combined_decoder_loss: 0.1664\n",
      "Epoch 2204/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1667 - combined_decoder_loss: 0.1667\n",
      "Epoch 2205/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1670 - combined_decoder_loss: 0.1670\n",
      "Epoch 2206/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1649 - combined_decoder_loss: 0.1647\n",
      "Epoch 2207/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1679 - combined_decoder_loss: 0.1679\n",
      "Epoch 2208/3000\n",
      "1190/1190 [==============================] - 1s 833us/sample - loss: 0.1682 - combined_decoder_loss: 0.1679\n",
      "Epoch 2209/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1655 - combined_decoder_loss: 0.1660\n",
      "Epoch 2210/3000\n",
      "1190/1190 [==============================] - 1s 841us/sample - loss: 0.1663 - combined_decoder_loss: 0.1660\n",
      "Epoch 2211/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1698 - combined_decoder_loss: 0.1697\n",
      "Epoch 2212/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1666 - combined_decoder_loss: 0.1668\n",
      "Epoch 2213/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1677 - combined_decoder_loss: 0.1680\n",
      "Epoch 2214/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1665 - combined_decoder_loss: 0.1673\n",
      "Epoch 2215/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1670 - combined_decoder_loss: 0.1666\n",
      "Epoch 2216/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1660 - combined_decoder_loss: 0.1659\n",
      "Epoch 2217/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1681 - combined_decoder_loss: 0.1680\n",
      "Epoch 2218/3000\n",
      "1190/1190 [==============================] - 1s 822us/sample - loss: 0.1667 - combined_decoder_loss: 0.1672\n",
      "Epoch 2219/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1674 - combined_decoder_loss: 0.1672\n",
      "Epoch 2220/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1654 - combined_decoder_loss: 0.1657\n",
      "Epoch 2221/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1679 - combined_decoder_loss: 0.1674\n",
      "Epoch 2222/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1731 - combined_decoder_loss: 0.1736\n",
      "Epoch 2223/3000\n",
      "1190/1190 [==============================] - 1s 831us/sample - loss: 0.1668 - combined_decoder_loss: 0.1669\n",
      "Epoch 2224/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1685 - combined_decoder_loss: 0.1682\n",
      "Epoch 2225/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1745 - combined_decoder_loss: 0.1741\n",
      "Epoch 2226/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1657 - combined_decoder_loss: 0.1651\n",
      "Epoch 2227/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1665 - combined_decoder_loss: 0.1666\n",
      "Epoch 2228/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1667 - combined_decoder_loss: 0.1664\n",
      "Epoch 2229/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1690 - combined_decoder_loss: 0.1694\n",
      "Epoch 2230/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1680 - combined_decoder_loss: 0.1679\n",
      "Epoch 2231/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1668 - combined_decoder_loss: 0.1667\n",
      "Epoch 2232/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1656 - combined_decoder_loss: 0.1658\n",
      "Epoch 2233/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1677 - combined_decoder_loss: 0.1678\n",
      "Epoch 2234/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1646 - combined_decoder_loss: 0.1646\n",
      "Epoch 2235/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1704 - combined_decoder_loss: 0.1701\n",
      "Epoch 2236/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1711 - combined_decoder_loss: 0.1710\n",
      "Epoch 2237/3000\n",
      "1190/1190 [==============================] - 1s 842us/sample - loss: 0.1659 - combined_decoder_loss: 0.1655\n",
      "Epoch 2238/3000\n",
      "1190/1190 [==============================] - 1s 836us/sample - loss: 0.1693 - combined_decoder_loss: 0.1690\n",
      "Epoch 2239/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1675 - combined_decoder_loss: 0.1673\n",
      "Epoch 2240/3000\n",
      "1190/1190 [==============================] - 1s 848us/sample - loss: 0.1640 - combined_decoder_loss: 0.1639\n",
      "Epoch 2241/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1673 - combined_decoder_loss: 0.1669\n",
      "Epoch 2242/3000\n",
      "1190/1190 [==============================] - 1s 857us/sample - loss: 0.1694 - combined_decoder_loss: 0.1710\n",
      "Epoch 2243/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1190/1190 [==============================] - 1s 848us/sample - loss: 0.1675 - combined_decoder_loss: 0.1676\n",
      "Epoch 2244/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1647 - combined_decoder_loss: 0.1647\n",
      "Epoch 2245/3000\n",
      "1190/1190 [==============================] - 1s 857us/sample - loss: 0.1663 - combined_decoder_loss: 0.1658\n",
      "Epoch 2246/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1669 - combined_decoder_loss: 0.1669\n",
      "Epoch 2247/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1706 - combined_decoder_loss: 0.1708\n",
      "Epoch 2248/3000\n",
      "1190/1190 [==============================] - 1s 852us/sample - loss: 0.1665 - combined_decoder_loss: 0.1666\n",
      "Epoch 2249/3000\n",
      "1190/1190 [==============================] - 1s 848us/sample - loss: 0.2048 - combined_decoder_loss: 0.2040\n",
      "Epoch 2250/3000\n",
      "1190/1190 [==============================] - 1s 849us/sample - loss: 0.1666 - combined_decoder_loss: 0.1665\n",
      "Epoch 2251/3000\n",
      "1190/1190 [==============================] - 1s 846us/sample - loss: 0.1673 - combined_decoder_loss: 0.1675\n",
      "Epoch 2252/3000\n",
      "1190/1190 [==============================] - 1s 843us/sample - loss: 0.1656 - combined_decoder_loss: 0.1654\n",
      "Epoch 2253/3000\n",
      "1190/1190 [==============================] - 1s 841us/sample - loss: 0.1672 - combined_decoder_loss: 0.1676\n",
      "Epoch 2254/3000\n",
      "1190/1190 [==============================] - 1s 842us/sample - loss: 0.1698 - combined_decoder_loss: 0.1698\n",
      "Epoch 2255/3000\n",
      "1190/1190 [==============================] - 1s 842us/sample - loss: 0.1635 - combined_decoder_loss: 0.1638\n",
      "Epoch 2256/3000\n",
      "1190/1190 [==============================] - 1s 854us/sample - loss: 0.1682 - combined_decoder_loss: 0.1679\n",
      "Epoch 2257/3000\n",
      "1190/1190 [==============================] - 1s 842us/sample - loss: 0.1678 - combined_decoder_loss: 0.1676\n",
      "Epoch 2258/3000\n",
      "1190/1190 [==============================] - 1s 850us/sample - loss: 0.1712 - combined_decoder_loss: 0.1712\n",
      "Epoch 2259/3000\n",
      "1190/1190 [==============================] - 1s 835us/sample - loss: 0.1681 - combined_decoder_loss: 0.1678\n",
      "Epoch 2260/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1742 - combined_decoder_loss: 0.1741\n",
      "Epoch 2261/3000\n",
      "1190/1190 [==============================] - 1s 848us/sample - loss: 0.1657 - combined_decoder_loss: 0.1655\n",
      "Epoch 2262/3000\n",
      "1190/1190 [==============================] - 1s 841us/sample - loss: 0.1677 - combined_decoder_loss: 0.1678\n",
      "Epoch 2263/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1685 - combined_decoder_loss: 0.1686\n",
      "Epoch 2264/3000\n",
      "1190/1190 [==============================] - 1s 844us/sample - loss: 0.1679 - combined_decoder_loss: 0.1677\n",
      "Epoch 2265/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1674 - combined_decoder_loss: 0.1673\n",
      "Epoch 2266/3000\n",
      "1190/1190 [==============================] - 1s 835us/sample - loss: 0.1676 - combined_decoder_loss: 0.1677\n",
      "Epoch 2267/3000\n",
      "1190/1190 [==============================] - 1s 849us/sample - loss: 0.1653 - combined_decoder_loss: 0.1650\n",
      "Epoch 2268/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.1656 - combined_decoder_loss: 0.1654\n",
      "Epoch 2269/3000\n",
      "1190/1190 [==============================] - 1s 852us/sample - loss: 0.1668 - combined_decoder_loss: 0.1667\n",
      "Epoch 2270/3000\n",
      "1190/1190 [==============================] - 1s 841us/sample - loss: 0.1707 - combined_decoder_loss: 0.1703\n",
      "Epoch 2271/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1663 - combined_decoder_loss: 0.1663\n",
      "Epoch 2272/3000\n",
      "1190/1190 [==============================] - 1s 844us/sample - loss: 0.1745 - combined_decoder_loss: 0.1744\n",
      "Epoch 2273/3000\n",
      "1190/1190 [==============================] - 1s 843us/sample - loss: 0.1699 - combined_decoder_loss: 0.1694\n",
      "Epoch 2274/3000\n",
      "1190/1190 [==============================] - 1s 844us/sample - loss: 0.1675 - combined_decoder_loss: 0.1672\n",
      "Epoch 2275/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1664 - combined_decoder_loss: 0.1664\n",
      "Epoch 2276/3000\n",
      "1190/1190 [==============================] - 1s 850us/sample - loss: 0.1726 - combined_decoder_loss: 0.1721\n",
      "Epoch 2277/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1686 - combined_decoder_loss: 0.1686\n",
      "Epoch 2278/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1702 - combined_decoder_loss: 0.1701\n",
      "Epoch 2279/3000\n",
      "1190/1190 [==============================] - 1s 849us/sample - loss: 0.1687 - combined_decoder_loss: 0.1686\n",
      "Epoch 2280/3000\n",
      "1190/1190 [==============================] - 1s 842us/sample - loss: 0.1705 - combined_decoder_loss: 0.1707\n",
      "Epoch 2281/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1669 - combined_decoder_loss: 0.1670\n",
      "Epoch 2282/3000\n",
      "1190/1190 [==============================] - 1s 831us/sample - loss: 0.1687 - combined_decoder_loss: 0.1685\n",
      "Epoch 2283/3000\n",
      "1190/1190 [==============================] - 1s 843us/sample - loss: 0.1663 - combined_decoder_loss: 0.1662\n",
      "Epoch 2284/3000\n",
      "1190/1190 [==============================] - 1s 835us/sample - loss: 0.1673 - combined_decoder_loss: 0.1673\n",
      "Epoch 2285/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1747 - combined_decoder_loss: 0.1740\n",
      "Epoch 2286/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1656 - combined_decoder_loss: 0.1657\n",
      "Epoch 2287/3000\n",
      "1190/1190 [==============================] - 1s 842us/sample - loss: 0.1674 - combined_decoder_loss: 0.1677\n",
      "Epoch 2288/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1666 - combined_decoder_loss: 0.1664\n",
      "Epoch 2289/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1677 - combined_decoder_loss: 0.1674\n",
      "Epoch 2290/3000\n",
      "1190/1190 [==============================] - 1s 834us/sample - loss: 0.1680 - combined_decoder_loss: 0.1675\n",
      "Epoch 2291/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1652 - combined_decoder_loss: 0.1655\n",
      "Epoch 2292/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1666 - combined_decoder_loss: 0.1667\n",
      "Epoch 2293/3000\n",
      "1190/1190 [==============================] - 1s 850us/sample - loss: 0.1735 - combined_decoder_loss: 0.1737\n",
      "Epoch 2294/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1675 - combined_decoder_loss: 0.1677\n",
      "Epoch 2295/3000\n",
      "1190/1190 [==============================] - 1s 835us/sample - loss: 0.1718 - combined_decoder_loss: 0.1721\n",
      "Epoch 2296/3000\n",
      "1190/1190 [==============================] - 1s 834us/sample - loss: 0.1666 - combined_decoder_loss: 0.1667\n",
      "Epoch 2297/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1672 - combined_decoder_loss: 0.1668\n",
      "Epoch 2298/3000\n",
      "1190/1190 [==============================] - 1s 849us/sample - loss: 0.1675 - combined_decoder_loss: 0.1673\n",
      "Epoch 2299/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1665 - combined_decoder_loss: 0.1665\n",
      "Epoch 2300/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1692 - combined_decoder_loss: 0.1687\n",
      "Epoch 2301/3000\n",
      "1190/1190 [==============================] - 1s 836us/sample - loss: 0.1696 - combined_decoder_loss: 0.1693\n",
      "Epoch 2302/3000\n",
      "1190/1190 [==============================] - 1s 842us/sample - loss: 0.1658 - combined_decoder_loss: 0.1663\n",
      "Epoch 2303/3000\n",
      "1190/1190 [==============================] - 1s 846us/sample - loss: 0.1671 - combined_decoder_loss: 0.1672\n",
      "Epoch 2304/3000\n",
      "1190/1190 [==============================] - 1s 855us/sample - loss: 0.1655 - combined_decoder_loss: 0.1653\n",
      "Epoch 2305/3000\n",
      "1190/1190 [==============================] - 1s 822us/sample - loss: 0.1701 - combined_decoder_loss: 0.1699\n",
      "Epoch 2306/3000\n",
      "1190/1190 [==============================] - 1s 846us/sample - loss: 0.1719 - combined_decoder_loss: 0.1719\n",
      "Epoch 2307/3000\n",
      "1190/1190 [==============================] - 1s 859us/sample - loss: 0.1659 - combined_decoder_loss: 0.1659\n",
      "Epoch 2308/3000\n",
      "1190/1190 [==============================] - 1s 865us/sample - loss: 0.1653 - combined_decoder_loss: 0.1656\n",
      "Epoch 2309/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1190/1190 [==============================] - 1s 876us/sample - loss: 0.1710 - combined_decoder_loss: 0.1709\n",
      "Epoch 2310/3000\n",
      "1190/1190 [==============================] - 1s 878us/sample - loss: 0.1707 - combined_decoder_loss: 0.1703\n",
      "Epoch 2311/3000\n",
      "1190/1190 [==============================] - 1s 849us/sample - loss: 0.1691 - combined_decoder_loss: 0.1691\n",
      "Epoch 2312/3000\n",
      "1190/1190 [==============================] - 1s 868us/sample - loss: 0.1716 - combined_decoder_loss: 0.1715\n",
      "Epoch 2313/3000\n",
      "1190/1190 [==============================] - 1s 836us/sample - loss: 0.1667 - combined_decoder_loss: 0.1666\n",
      "Epoch 2314/3000\n",
      "1190/1190 [==============================] - 1s 850us/sample - loss: 0.1717 - combined_decoder_loss: 0.1719\n",
      "Epoch 2315/3000\n",
      "1190/1190 [==============================] - 1s 865us/sample - loss: 0.1646 - combined_decoder_loss: 0.1649\n",
      "Epoch 2316/3000\n",
      "1190/1190 [==============================] - 1s 859us/sample - loss: 0.1687 - combined_decoder_loss: 0.1690\n",
      "Epoch 2317/3000\n",
      "1190/1190 [==============================] - 1s 851us/sample - loss: 0.1672 - combined_decoder_loss: 0.1668\n",
      "Epoch 2318/3000\n",
      "1190/1190 [==============================] - 1s 855us/sample - loss: 0.1664 - combined_decoder_loss: 0.1657\n",
      "Epoch 2319/3000\n",
      "1190/1190 [==============================] - 1s 875us/sample - loss: 0.1694 - combined_decoder_loss: 0.1689\n",
      "Epoch 2320/3000\n",
      "1190/1190 [==============================] - 1s 876us/sample - loss: 0.1662 - combined_decoder_loss: 0.1659\n",
      "Epoch 2321/3000\n",
      "1190/1190 [==============================] - 1s 862us/sample - loss: 0.1672 - combined_decoder_loss: 0.1670\n",
      "Epoch 2322/3000\n",
      "1190/1190 [==============================] - 1s 857us/sample - loss: 0.1691 - combined_decoder_loss: 0.1693\n",
      "Epoch 2323/3000\n",
      "1190/1190 [==============================] - 1s 854us/sample - loss: 0.1694 - combined_decoder_loss: 0.1690\n",
      "Epoch 2324/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1660 - combined_decoder_loss: 0.1659\n",
      "Epoch 2325/3000\n",
      "1190/1190 [==============================] - 1s 835us/sample - loss: 0.1686 - combined_decoder_loss: 0.1683\n",
      "Epoch 2326/3000\n",
      "1190/1190 [==============================] - 1s 842us/sample - loss: 0.1663 - combined_decoder_loss: 0.1663\n",
      "Epoch 2327/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1678 - combined_decoder_loss: 0.1683\n",
      "Epoch 2328/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1670 - combined_decoder_loss: 0.1671\n",
      "Epoch 2329/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1709 - combined_decoder_loss: 0.1711\n",
      "Epoch 2330/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1793 - combined_decoder_loss: 0.1793\n",
      "Epoch 2331/3000\n",
      "1190/1190 [==============================] - 1s 828us/sample - loss: 0.1677 - combined_decoder_loss: 0.1675\n",
      "Epoch 2332/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1674 - combined_decoder_loss: 0.1672\n",
      "Epoch 2333/3000\n",
      "1190/1190 [==============================] - 1s 834us/sample - loss: 0.1664 - combined_decoder_loss: 0.1664\n",
      "Epoch 2334/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1651 - combined_decoder_loss: 0.1647\n",
      "Epoch 2335/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1699 - combined_decoder_loss: 0.1696\n",
      "Epoch 2336/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1674 - combined_decoder_loss: 0.1673\n",
      "Epoch 2337/3000\n",
      "1190/1190 [==============================] - 1s 835us/sample - loss: 0.1763 - combined_decoder_loss: 0.1760\n",
      "Epoch 2338/3000\n",
      "1190/1190 [==============================] - 1s 833us/sample - loss: 0.1677 - combined_decoder_loss: 0.1680\n",
      "Epoch 2339/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1665 - combined_decoder_loss: 0.1665\n",
      "Epoch 2340/3000\n",
      "1190/1190 [==============================] - 1s 823us/sample - loss: 0.1691 - combined_decoder_loss: 0.1690\n",
      "Epoch 2341/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1660 - combined_decoder_loss: 0.1659\n",
      "Epoch 2342/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.1697 - combined_decoder_loss: 0.1698\n",
      "Epoch 2343/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1670 - combined_decoder_loss: 0.1671\n",
      "Epoch 2344/3000\n",
      "1190/1190 [==============================] - 1s 833us/sample - loss: 0.1682 - combined_decoder_loss: 0.1681\n",
      "Epoch 2345/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1760 - combined_decoder_loss: 0.1760\n",
      "Epoch 2346/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1666 - combined_decoder_loss: 0.1667\n",
      "Epoch 2347/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1762 - combined_decoder_loss: 0.1760\n",
      "Epoch 2348/3000\n",
      "1190/1190 [==============================] - 1s 831us/sample - loss: 0.1671 - combined_decoder_loss: 0.1670\n",
      "Epoch 2349/3000\n",
      "1190/1190 [==============================] - 1s 822us/sample - loss: 0.1678 - combined_decoder_loss: 0.1676\n",
      "Epoch 2350/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1672 - combined_decoder_loss: 0.1670\n",
      "Epoch 2351/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1671 - combined_decoder_loss: 0.1668\n",
      "Epoch 2352/3000\n",
      "1190/1190 [==============================] - 1s 828us/sample - loss: 0.1687 - combined_decoder_loss: 0.1690\n",
      "Epoch 2353/3000\n",
      "1190/1190 [==============================] - 1s 831us/sample - loss: 0.1674 - combined_decoder_loss: 0.1677\n",
      "Epoch 2354/3000\n",
      "1190/1190 [==============================] - 1s 851us/sample - loss: 0.1672 - combined_decoder_loss: 0.1670\n",
      "Epoch 2355/3000\n",
      "1190/1190 [==============================] - 1s 849us/sample - loss: 0.1666 - combined_decoder_loss: 0.1664\n",
      "Epoch 2356/3000\n",
      "1190/1190 [==============================] - 1s 823us/sample - loss: 0.1677 - combined_decoder_loss: 0.1675\n",
      "Epoch 2357/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1677 - combined_decoder_loss: 0.1676\n",
      "Epoch 2358/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1679 - combined_decoder_loss: 0.1710\n",
      "Epoch 2359/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1664 - combined_decoder_loss: 0.1665\n",
      "Epoch 2360/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1668 - combined_decoder_loss: 0.1682\n",
      "Epoch 2361/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1660 - combined_decoder_loss: 0.1657\n",
      "Epoch 2362/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1699 - combined_decoder_loss: 0.1697\n",
      "Epoch 2363/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1720 - combined_decoder_loss: 0.1723\n",
      "Epoch 2364/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1668 - combined_decoder_loss: 0.1665\n",
      "Epoch 2365/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1743 - combined_decoder_loss: 0.1740\n",
      "Epoch 2366/3000\n",
      "1190/1190 [==============================] - 1s 823us/sample - loss: 0.1674 - combined_decoder_loss: 0.1674\n",
      "Epoch 2367/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1682 - combined_decoder_loss: 0.1682\n",
      "Epoch 2368/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.1776 - combined_decoder_loss: 0.1774\n",
      "Epoch 2369/3000\n",
      "1190/1190 [==============================] - 1s 831us/sample - loss: 0.1672 - combined_decoder_loss: 0.1678\n",
      "Epoch 2370/3000\n",
      "1190/1190 [==============================] - 1s 829us/sample - loss: 0.1696 - combined_decoder_loss: 0.1691\n",
      "Epoch 2371/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1683 - combined_decoder_loss: 0.1687\n",
      "Epoch 2372/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1684 - combined_decoder_loss: 0.1683\n",
      "Epoch 2373/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1674 - combined_decoder_loss: 0.1672\n",
      "Epoch 2374/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1669 - combined_decoder_loss: 0.1666\n",
      "Epoch 2375/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1190/1190 [==============================] - 1s 831us/sample - loss: 0.1649 - combined_decoder_loss: 0.1647\n",
      "Epoch 2376/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1739 - combined_decoder_loss: 0.1740\n",
      "Epoch 2377/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1666 - combined_decoder_loss: 0.1668\n",
      "Epoch 2378/3000\n",
      "1190/1190 [==============================] - 1s 842us/sample - loss: 0.1661 - combined_decoder_loss: 0.1658\n",
      "Epoch 2379/3000\n",
      "1190/1190 [==============================] - 1s 833us/sample - loss: 0.1662 - combined_decoder_loss: 0.1661\n",
      "Epoch 2380/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1670 - combined_decoder_loss: 0.1669\n",
      "Epoch 2381/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1688 - combined_decoder_loss: 0.1689\n",
      "Epoch 2382/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1701 - combined_decoder_loss: 0.1702\n",
      "Epoch 2383/3000\n",
      "1190/1190 [==============================] - 1s 829us/sample - loss: 0.1663 - combined_decoder_loss: 0.1665\n",
      "Epoch 2384/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1673 - combined_decoder_loss: 0.1674\n",
      "Epoch 2385/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1708 - combined_decoder_loss: 0.1708\n",
      "Epoch 2386/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1668 - combined_decoder_loss: 0.1667\n",
      "Epoch 2387/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1650 - combined_decoder_loss: 0.1655\n",
      "Epoch 2388/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1682 - combined_decoder_loss: 0.1679\n",
      "Epoch 2389/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1672 - combined_decoder_loss: 0.1674\n",
      "Epoch 2390/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1680 - combined_decoder_loss: 0.1677\n",
      "Epoch 2391/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1763 - combined_decoder_loss: 0.1757\n",
      "Epoch 2392/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1732 - combined_decoder_loss: 0.1726\n",
      "Epoch 2393/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1687 - combined_decoder_loss: 0.1686\n",
      "Epoch 2394/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1677 - combined_decoder_loss: 0.1678\n",
      "Epoch 2395/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1662 - combined_decoder_loss: 0.1660\n",
      "Epoch 2396/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1662 - combined_decoder_loss: 0.1661\n",
      "Epoch 2397/3000\n",
      "1190/1190 [==============================] - 1s 846us/sample - loss: 0.1710 - combined_decoder_loss: 0.1710\n",
      "Epoch 2398/3000\n",
      "1190/1190 [==============================] - 1s 846us/sample - loss: 0.1680 - combined_decoder_loss: 0.1678\n",
      "Epoch 2399/3000\n",
      "1190/1190 [==============================] - 1s 833us/sample - loss: 0.1684 - combined_decoder_loss: 0.1686\n",
      "Epoch 2400/3000\n",
      "1190/1190 [==============================] - 1s 843us/sample - loss: 0.1692 - combined_decoder_loss: 0.1691\n",
      "Epoch 2401/3000\n",
      "1190/1190 [==============================] - 1s 828us/sample - loss: 0.1695 - combined_decoder_loss: 0.1700\n",
      "Epoch 2402/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1672 - combined_decoder_loss: 0.1668\n",
      "Epoch 2403/3000\n",
      "1190/1190 [==============================] - 1s 844us/sample - loss: 0.1702 - combined_decoder_loss: 0.1699\n",
      "Epoch 2404/3000\n",
      "1190/1190 [==============================] - 1s 858us/sample - loss: 0.1667 - combined_decoder_loss: 0.1669\n",
      "Epoch 2405/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1736 - combined_decoder_loss: 0.1733\n",
      "Epoch 2406/3000\n",
      "1190/1190 [==============================] - 1s 828us/sample - loss: 0.1680 - combined_decoder_loss: 0.1679\n",
      "Epoch 2407/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1681 - combined_decoder_loss: 0.1680\n",
      "Epoch 2408/3000\n",
      "1190/1190 [==============================] - 1s 855us/sample - loss: 0.1677 - combined_decoder_loss: 0.1675\n",
      "Epoch 2409/3000\n",
      "1190/1190 [==============================] - 1s 850us/sample - loss: 0.1679 - combined_decoder_loss: 0.1677\n",
      "Epoch 2410/3000\n",
      "1190/1190 [==============================] - 1s 849us/sample - loss: 0.1686 - combined_decoder_loss: 0.1686\n",
      "Epoch 2411/3000\n",
      "1190/1190 [==============================] - 1s 844us/sample - loss: 0.1671 - combined_decoder_loss: 0.1670\n",
      "Epoch 2412/3000\n",
      "1190/1190 [==============================] - 1s 828us/sample - loss: 0.1682 - combined_decoder_loss: 0.1682\n",
      "Epoch 2413/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1695 - combined_decoder_loss: 0.1692\n",
      "Epoch 2414/3000\n",
      "1190/1190 [==============================] - 1s 848us/sample - loss: 0.1702 - combined_decoder_loss: 0.1701\n",
      "Epoch 2415/3000\n",
      "1190/1190 [==============================] - 1s 851us/sample - loss: 0.1674 - combined_decoder_loss: 0.1677\n",
      "Epoch 2416/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1806 - combined_decoder_loss: 0.1805\n",
      "Epoch 2417/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1670 - combined_decoder_loss: 0.1674\n",
      "Epoch 2418/3000\n",
      "1190/1190 [==============================] - 1s 851us/sample - loss: 0.1687 - combined_decoder_loss: 0.1684\n",
      "Epoch 2419/3000\n",
      "1190/1190 [==============================] - 1s 849us/sample - loss: 0.1695 - combined_decoder_loss: 0.1694\n",
      "Epoch 2420/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1686 - combined_decoder_loss: 0.1686\n",
      "Epoch 2421/3000\n",
      "1190/1190 [==============================] - 1s 849us/sample - loss: 0.1663 - combined_decoder_loss: 0.1661\n",
      "Epoch 2422/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1667 - combined_decoder_loss: 0.1665\n",
      "Epoch 2423/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.1663 - combined_decoder_loss: 0.1662\n",
      "Epoch 2424/3000\n",
      "1190/1190 [==============================] - 1s 849us/sample - loss: 0.1670 - combined_decoder_loss: 0.1667\n",
      "Epoch 2425/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1699 - combined_decoder_loss: 0.1698\n",
      "Epoch 2426/3000\n",
      "1190/1190 [==============================] - 1s 852us/sample - loss: 0.1672 - combined_decoder_loss: 0.1672\n",
      "Epoch 2427/3000\n",
      "1190/1190 [==============================] - 1s 844us/sample - loss: 0.1708 - combined_decoder_loss: 0.1707\n",
      "Epoch 2428/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1690 - combined_decoder_loss: 0.1688\n",
      "Epoch 2429/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1672 - combined_decoder_loss: 0.1670\n",
      "Epoch 2430/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1716 - combined_decoder_loss: 0.1716\n",
      "Epoch 2431/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1700 - combined_decoder_loss: 0.1698\n",
      "Epoch 2432/3000\n",
      "1190/1190 [==============================] - 1s 846us/sample - loss: 0.1681 - combined_decoder_loss: 0.1680\n",
      "Epoch 2433/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1693 - combined_decoder_loss: 0.1782\n",
      "Epoch 2434/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1710 - combined_decoder_loss: 0.1711\n",
      "Epoch 2435/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1674 - combined_decoder_loss: 0.1677\n",
      "Epoch 2436/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1661 - combined_decoder_loss: 0.1660\n",
      "Epoch 2437/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1698 - combined_decoder_loss: 0.1700\n",
      "Epoch 2438/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1701 - combined_decoder_loss: 0.1703\n",
      "Epoch 2439/3000\n",
      "1190/1190 [==============================] - 1s 846us/sample - loss: 0.1675 - combined_decoder_loss: 0.1683\n",
      "Epoch 2440/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.1665 - combined_decoder_loss: 0.1669\n",
      "Epoch 2441/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1667 - combined_decoder_loss: 0.1664\n",
      "Epoch 2442/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1699 - combined_decoder_loss: 0.1704\n",
      "Epoch 2443/3000\n",
      "1190/1190 [==============================] - 1s 713us/sample - loss: 0.1757 - combined_decoder_loss: 0.1761\n",
      "Epoch 2444/3000\n",
      "1190/1190 [==============================] - 1s 704us/sample - loss: 0.1681 - combined_decoder_loss: 0.1679\n",
      "Epoch 2445/3000\n",
      "1190/1190 [==============================] - 1s 841us/sample - loss: 0.1673 - combined_decoder_loss: 0.1674\n",
      "Epoch 2446/3000\n",
      "1190/1190 [==============================] - 1s 834us/sample - loss: 0.1843 - combined_decoder_loss: 0.1839\n",
      "Epoch 2447/3000\n",
      "1190/1190 [==============================] - 1s 853us/sample - loss: 0.1687 - combined_decoder_loss: 0.1695\n",
      "Epoch 2448/3000\n",
      "1190/1190 [==============================] - 1s 821us/sample - loss: 0.1676 - combined_decoder_loss: 0.1673\n",
      "Epoch 2449/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1678 - combined_decoder_loss: 0.1675\n",
      "Epoch 2450/3000\n",
      "1190/1190 [==============================] - 1s 831us/sample - loss: 0.1655 - combined_decoder_loss: 0.1661\n",
      "Epoch 2451/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1673 - combined_decoder_loss: 0.1675\n",
      "Epoch 2452/3000\n",
      "1190/1190 [==============================] - 1s 852us/sample - loss: 0.1674 - combined_decoder_loss: 0.1673\n",
      "Epoch 2453/3000\n",
      "1190/1190 [==============================] - 1s 823us/sample - loss: 0.1702 - combined_decoder_loss: 0.1700\n",
      "Epoch 2454/3000\n",
      "1190/1190 [==============================] - 1s 846us/sample - loss: 0.1667 - combined_decoder_loss: 0.1665\n",
      "Epoch 2455/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.1706 - combined_decoder_loss: 0.1702\n",
      "Epoch 2456/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1671 - combined_decoder_loss: 0.1672\n",
      "Epoch 2457/3000\n",
      "1190/1190 [==============================] - 1s 842us/sample - loss: 0.1659 - combined_decoder_loss: 0.1656\n",
      "Epoch 2458/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1675 - combined_decoder_loss: 0.1673\n",
      "Epoch 2459/3000\n",
      "1190/1190 [==============================] - 1s 856us/sample - loss: 0.1670 - combined_decoder_loss: 0.1669\n",
      "Epoch 2460/3000\n",
      "1190/1190 [==============================] - 1s 829us/sample - loss: 0.1701 - combined_decoder_loss: 0.1699\n",
      "Epoch 2461/3000\n",
      "1190/1190 [==============================] - 1s 836us/sample - loss: 0.1678 - combined_decoder_loss: 0.1676\n",
      "Epoch 2462/3000\n",
      "1190/1190 [==============================] - 1s 831us/sample - loss: 0.1679 - combined_decoder_loss: 0.1677\n",
      "Epoch 2463/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1724 - combined_decoder_loss: 0.1725\n",
      "Epoch 2464/3000\n",
      "1190/1190 [==============================] - 1s 856us/sample - loss: 0.1663 - combined_decoder_loss: 0.1661\n",
      "Epoch 2465/3000\n",
      "1190/1190 [==============================] - 1s 856us/sample - loss: 0.1673 - combined_decoder_loss: 0.1673\n",
      "Epoch 2466/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1668 - combined_decoder_loss: 0.1667\n",
      "Epoch 2467/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1692 - combined_decoder_loss: 0.1701\n",
      "Epoch 2468/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1681 - combined_decoder_loss: 0.1679\n",
      "Epoch 2469/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1666 - combined_decoder_loss: 0.1670\n",
      "Epoch 2470/3000\n",
      "1190/1190 [==============================] - 1s 835us/sample - loss: 0.1665 - combined_decoder_loss: 0.1662\n",
      "Epoch 2471/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1919 - combined_decoder_loss: 0.1917\n",
      "Epoch 2472/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1676 - combined_decoder_loss: 0.1672\n",
      "Epoch 2473/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1735 - combined_decoder_loss: 0.1735\n",
      "Epoch 2474/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1657 - combined_decoder_loss: 0.1657\n",
      "Epoch 2475/3000\n",
      "1190/1190 [==============================] - 1s 833us/sample - loss: 0.1696 - combined_decoder_loss: 0.1697\n",
      "Epoch 2476/3000\n",
      "1190/1190 [==============================] - 1s 836us/sample - loss: 0.1673 - combined_decoder_loss: 0.1676\n",
      "Epoch 2477/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1724 - combined_decoder_loss: 0.1723\n",
      "Epoch 2478/3000\n",
      "1190/1190 [==============================] - 1s 831us/sample - loss: 0.1687 - combined_decoder_loss: 0.1685\n",
      "Epoch 2479/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.1677 - combined_decoder_loss: 0.1675\n",
      "Epoch 2480/3000\n",
      "1190/1190 [==============================] - 1s 842us/sample - loss: 0.1675 - combined_decoder_loss: 0.1677\n",
      "Epoch 2481/3000\n",
      "1190/1190 [==============================] - 1s 829us/sample - loss: 0.1674 - combined_decoder_loss: 0.1673\n",
      "Epoch 2482/3000\n",
      "1190/1190 [==============================] - 1s 813us/sample - loss: 0.1687 - combined_decoder_loss: 0.1685\n",
      "Epoch 2483/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1673 - combined_decoder_loss: 0.1675\n",
      "Epoch 2484/3000\n",
      "1190/1190 [==============================] - 1s 836us/sample - loss: 0.1661 - combined_decoder_loss: 0.1664\n",
      "Epoch 2485/3000\n",
      "1190/1190 [==============================] - 1s 833us/sample - loss: 0.1663 - combined_decoder_loss: 0.1661\n",
      "Epoch 2486/3000\n",
      "1190/1190 [==============================] - 1s 829us/sample - loss: 0.1691 - combined_decoder_loss: 0.1692\n",
      "Epoch 2487/3000\n",
      "1190/1190 [==============================] - 1s 836us/sample - loss: 0.1663 - combined_decoder_loss: 0.1661\n",
      "Epoch 2488/3000\n",
      "1190/1190 [==============================] - 1s 821us/sample - loss: 0.1660 - combined_decoder_loss: 0.1667\n",
      "Epoch 2489/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1679 - combined_decoder_loss: 0.1679\n",
      "Epoch 2490/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1696 - combined_decoder_loss: 0.1694\n",
      "Epoch 2491/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1678 - combined_decoder_loss: 0.1676\n",
      "Epoch 2492/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1692 - combined_decoder_loss: 0.1693\n",
      "Epoch 2493/3000\n",
      "1190/1190 [==============================] - 1s 855us/sample - loss: 0.1666 - combined_decoder_loss: 0.1667\n",
      "Epoch 2494/3000\n",
      "1190/1190 [==============================] - 1s 836us/sample - loss: 0.1912 - combined_decoder_loss: 0.1904\n",
      "Epoch 2495/3000\n",
      "1190/1190 [==============================] - 1s 834us/sample - loss: 0.1658 - combined_decoder_loss: 0.1659\n",
      "Epoch 2496/3000\n",
      "1190/1190 [==============================] - 1s 833us/sample - loss: 0.1656 - combined_decoder_loss: 0.1654\n",
      "Epoch 2497/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1690 - combined_decoder_loss: 0.1688\n",
      "Epoch 2498/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1795 - combined_decoder_loss: 0.1795\n",
      "Epoch 2499/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1697 - combined_decoder_loss: 0.1693\n",
      "Epoch 2500/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1729 - combined_decoder_loss: 0.1727\n",
      "Epoch 2501/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1656 - combined_decoder_loss: 0.1657\n",
      "Epoch 2502/3000\n",
      "1190/1190 [==============================] - 1s 846us/sample - loss: 0.1723 - combined_decoder_loss: 0.1718\n",
      "Epoch 2503/3000\n",
      "1190/1190 [==============================] - 1s 831us/sample - loss: 0.1662 - combined_decoder_loss: 0.1661\n",
      "Epoch 2504/3000\n",
      "1190/1190 [==============================] - 1s 815us/sample - loss: 0.1646 - combined_decoder_loss: 0.1646\n",
      "Epoch 2505/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1672 - combined_decoder_loss: 0.1679\n",
      "Epoch 2506/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1713 - combined_decoder_loss: 0.1711\n",
      "Epoch 2507/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1670 - combined_decoder_loss: 0.1670\n",
      "Epoch 2508/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1688 - combined_decoder_loss: 0.1688\n",
      "Epoch 2509/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1783 - combined_decoder_loss: 0.1780\n",
      "Epoch 2510/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1697 - combined_decoder_loss: 0.1692\n",
      "Epoch 2511/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1656 - combined_decoder_loss: 0.1658\n",
      "Epoch 2512/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1713 - combined_decoder_loss: 0.1713\n",
      "Epoch 2513/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1671 - combined_decoder_loss: 0.1668\n",
      "Epoch 2514/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1702 - combined_decoder_loss: 0.1699\n",
      "Epoch 2515/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1679 - combined_decoder_loss: 0.1678\n",
      "Epoch 2516/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1689 - combined_decoder_loss: 0.1687\n",
      "Epoch 2517/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1701 - combined_decoder_loss: 0.1700\n",
      "Epoch 2518/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1671 - combined_decoder_loss: 0.1675\n",
      "Epoch 2519/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1678 - combined_decoder_loss: 0.1676\n",
      "Epoch 2520/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1696 - combined_decoder_loss: 0.1696\n",
      "Epoch 2521/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1678 - combined_decoder_loss: 0.1672\n",
      "Epoch 2522/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1670 - combined_decoder_loss: 0.1667\n",
      "Epoch 2523/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1718 - combined_decoder_loss: 0.1714\n",
      "Epoch 2524/3000\n",
      "1190/1190 [==============================] - 1s 823us/sample - loss: 0.1659 - combined_decoder_loss: 0.1659\n",
      "Epoch 2525/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1670 - combined_decoder_loss: 0.1669\n",
      "Epoch 2526/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1669 - combined_decoder_loss: 0.1671\n",
      "Epoch 2527/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1673 - combined_decoder_loss: 0.1674\n",
      "Epoch 2528/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1685 - combined_decoder_loss: 0.1684\n",
      "Epoch 2529/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1669 - combined_decoder_loss: 0.1667\n",
      "Epoch 2530/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1683 - combined_decoder_loss: 0.1682\n",
      "Epoch 2531/3000\n",
      "1190/1190 [==============================] - 1s 823us/sample - loss: 0.1688 - combined_decoder_loss: 0.1687\n",
      "Epoch 2532/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1674 - combined_decoder_loss: 0.1679\n",
      "Epoch 2533/3000\n",
      "1190/1190 [==============================] - 1s 813us/sample - loss: 0.1683 - combined_decoder_loss: 0.1685\n",
      "Epoch 2534/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1688 - combined_decoder_loss: 0.1686\n",
      "Epoch 2535/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1676 - combined_decoder_loss: 0.1674\n",
      "Epoch 2536/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1672 - combined_decoder_loss: 0.1673\n",
      "Epoch 2537/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1705 - combined_decoder_loss: 0.1707\n",
      "Epoch 2538/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1679 - combined_decoder_loss: 0.1676\n",
      "Epoch 2539/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1691 - combined_decoder_loss: 0.1687\n",
      "Epoch 2540/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1768 - combined_decoder_loss: 0.1766\n",
      "Epoch 2541/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1676 - combined_decoder_loss: 0.1675\n",
      "Epoch 2542/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1684 - combined_decoder_loss: 0.1687\n",
      "Epoch 2543/3000\n",
      "1190/1190 [==============================] - 1s 846us/sample - loss: 0.1798 - combined_decoder_loss: 0.1794\n",
      "Epoch 2544/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1701 - combined_decoder_loss: 0.1704\n",
      "Epoch 2545/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1666 - combined_decoder_loss: 0.1666\n",
      "Epoch 2546/3000\n",
      "1190/1190 [==============================] - 1s 835us/sample - loss: 0.1688 - combined_decoder_loss: 0.1689\n",
      "Epoch 2547/3000\n",
      "1190/1190 [==============================] - 1s 862us/sample - loss: 0.1656 - combined_decoder_loss: 0.1661\n",
      "Epoch 2548/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1855 - combined_decoder_loss: 0.1854\n",
      "Epoch 2549/3000\n",
      "1190/1190 [==============================] - 1s 831us/sample - loss: 0.1668 - combined_decoder_loss: 0.1665\n",
      "Epoch 2550/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1664 - combined_decoder_loss: 0.1662\n",
      "Epoch 2551/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1728 - combined_decoder_loss: 0.1727\n",
      "Epoch 2552/3000\n",
      "1190/1190 [==============================] - 1s 871us/sample - loss: 0.1656 - combined_decoder_loss: 0.1658\n",
      "Epoch 2553/3000\n",
      "1190/1190 [==============================] - 1s 834us/sample - loss: 0.1650 - combined_decoder_loss: 0.1647\n",
      "Epoch 2554/3000\n",
      "1190/1190 [==============================] - 1s 831us/sample - loss: 0.1676 - combined_decoder_loss: 0.1671\n",
      "Epoch 2555/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1663 - combined_decoder_loss: 0.1665\n",
      "Epoch 2556/3000\n",
      "1190/1190 [==============================] - 1s 852us/sample - loss: 0.1697 - combined_decoder_loss: 0.1695\n",
      "Epoch 2557/3000\n",
      "1190/1190 [==============================] - 1s 856us/sample - loss: 0.1664 - combined_decoder_loss: 0.1664\n",
      "Epoch 2558/3000\n",
      "1190/1190 [==============================] - 1s 851us/sample - loss: 0.1672 - combined_decoder_loss: 0.1671\n",
      "Epoch 2559/3000\n",
      "1190/1190 [==============================] - 1s 841us/sample - loss: 0.1716 - combined_decoder_loss: 0.1716\n",
      "Epoch 2560/3000\n",
      "1190/1190 [==============================] - 1s 831us/sample - loss: 0.1665 - combined_decoder_loss: 0.1670\n",
      "Epoch 2561/3000\n",
      "1190/1190 [==============================] - 1s 846us/sample - loss: 0.1684 - combined_decoder_loss: 0.1683\n",
      "Epoch 2562/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1675 - combined_decoder_loss: 0.1671\n",
      "Epoch 2563/3000\n",
      "1190/1190 [==============================] - 1s 854us/sample - loss: 0.1696 - combined_decoder_loss: 0.1696\n",
      "Epoch 2564/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1655 - combined_decoder_loss: 0.1653\n",
      "Epoch 2565/3000\n",
      "1190/1190 [==============================] - 1s 850us/sample - loss: 0.1659 - combined_decoder_loss: 0.1656\n",
      "Epoch 2566/3000\n",
      "1190/1190 [==============================] - 1s 841us/sample - loss: 0.1708 - combined_decoder_loss: 0.1706\n",
      "Epoch 2567/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1650 - combined_decoder_loss: 0.1650\n",
      "Epoch 2568/3000\n",
      "1190/1190 [==============================] - 1s 822us/sample - loss: 0.1645 - combined_decoder_loss: 0.1645\n",
      "Epoch 2569/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1667 - combined_decoder_loss: 0.1668\n",
      "Epoch 2570/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1683 - combined_decoder_loss: 0.1683\n",
      "Epoch 2571/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1662 - combined_decoder_loss: 0.1663\n",
      "Epoch 2572/3000\n",
      "1190/1190 [==============================] - 1s 831us/sample - loss: 0.1711 - combined_decoder_loss: 0.1716\n",
      "Epoch 2573/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1647 - combined_decoder_loss: 0.1643\n",
      "Epoch 2574/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1731 - combined_decoder_loss: 0.1731\n",
      "Epoch 2575/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1658 - combined_decoder_loss: 0.1658\n",
      "Epoch 2576/3000\n",
      "1190/1190 [==============================] - 1s 842us/sample - loss: 0.1667 - combined_decoder_loss: 0.1664\n",
      "Epoch 2577/3000\n",
      "1190/1190 [==============================] - 1s 843us/sample - loss: 0.1647 - combined_decoder_loss: 0.1646\n",
      "Epoch 2578/3000\n",
      "1190/1190 [==============================] - 1s 833us/sample - loss: 0.1666 - combined_decoder_loss: 0.1665\n",
      "Epoch 2579/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1662 - combined_decoder_loss: 0.1663\n",
      "Epoch 2580/3000\n",
      "1190/1190 [==============================] - 1s 864us/sample - loss: 0.1654 - combined_decoder_loss: 0.1655\n",
      "Epoch 2581/3000\n",
      "1190/1190 [==============================] - 1s 850us/sample - loss: 0.1729 - combined_decoder_loss: 0.1725\n",
      "Epoch 2582/3000\n",
      "1190/1190 [==============================] - 1s 863us/sample - loss: 0.1671 - combined_decoder_loss: 0.1668\n",
      "Epoch 2583/3000\n",
      "1190/1190 [==============================] - 1s 862us/sample - loss: 0.1672 - combined_decoder_loss: 0.1671\n",
      "Epoch 2584/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1676 - combined_decoder_loss: 0.1674\n",
      "Epoch 2585/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1679 - combined_decoder_loss: 0.1678\n",
      "Epoch 2586/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1663 - combined_decoder_loss: 0.1675\n",
      "Epoch 2587/3000\n",
      "1190/1190 [==============================] - 1s 829us/sample - loss: 0.1879 - combined_decoder_loss: 0.1872\n",
      "Epoch 2588/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1708 - combined_decoder_loss: 0.1706\n",
      "Epoch 2589/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1700 - combined_decoder_loss: 0.1698\n",
      "Epoch 2590/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1663 - combined_decoder_loss: 0.1659\n",
      "Epoch 2591/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1660 - combined_decoder_loss: 0.1658\n",
      "Epoch 2592/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1655 - combined_decoder_loss: 0.1653\n",
      "Epoch 2593/3000\n",
      "1190/1190 [==============================] - 1s 834us/sample - loss: 0.1719 - combined_decoder_loss: 0.1720\n",
      "Epoch 2594/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.1657 - combined_decoder_loss: 0.1656\n",
      "Epoch 2595/3000\n",
      "1190/1190 [==============================] - 1s 828us/sample - loss: 0.1665 - combined_decoder_loss: 0.1670\n",
      "Epoch 2596/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1672 - combined_decoder_loss: 0.1688\n",
      "Epoch 2597/3000\n",
      "1190/1190 [==============================] - 1s 831us/sample - loss: 0.1678 - combined_decoder_loss: 0.1675\n",
      "Epoch 2598/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1698 - combined_decoder_loss: 0.1696\n",
      "Epoch 2599/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1681 - combined_decoder_loss: 0.1687\n",
      "Epoch 2600/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1668 - combined_decoder_loss: 0.1667\n",
      "Epoch 2601/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1681 - combined_decoder_loss: 0.1679\n",
      "Epoch 2602/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1674 - combined_decoder_loss: 0.1679\n",
      "Epoch 2603/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1661 - combined_decoder_loss: 0.1661\n",
      "Epoch 2604/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1681 - combined_decoder_loss: 0.1681\n",
      "Epoch 2605/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1660 - combined_decoder_loss: 0.1660\n",
      "Epoch 2606/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1727 - combined_decoder_loss: 0.1722\n",
      "Epoch 2607/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1674 - combined_decoder_loss: 0.1673\n",
      "Epoch 2608/3000\n",
      "1190/1190 [==============================] - 1s 842us/sample - loss: 0.1668 - combined_decoder_loss: 0.1667\n",
      "Epoch 2609/3000\n",
      "1190/1190 [==============================] - 1s 843us/sample - loss: 0.1672 - combined_decoder_loss: 0.1671\n",
      "Epoch 2610/3000\n",
      "1190/1190 [==============================] - 1s 828us/sample - loss: 0.1675 - combined_decoder_loss: 0.1675\n",
      "Epoch 2611/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1691 - combined_decoder_loss: 0.1693\n",
      "Epoch 2612/3000\n",
      "1190/1190 [==============================] - 1s 843us/sample - loss: 0.1707 - combined_decoder_loss: 0.1705\n",
      "Epoch 2613/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1681 - combined_decoder_loss: 0.1679\n",
      "Epoch 2614/3000\n",
      "1190/1190 [==============================] - 1s 827us/sample - loss: 0.1658 - combined_decoder_loss: 0.1657\n",
      "Epoch 2615/3000\n",
      "1190/1190 [==============================] - 1s 831us/sample - loss: 0.1664 - combined_decoder_loss: 0.1663\n",
      "Epoch 2616/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1673 - combined_decoder_loss: 0.1674\n",
      "Epoch 2617/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1665 - combined_decoder_loss: 0.1666\n",
      "Epoch 2618/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1681 - combined_decoder_loss: 0.1682\n",
      "Epoch 2619/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1663 - combined_decoder_loss: 0.1663\n",
      "Epoch 2620/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1831 - combined_decoder_loss: 0.1826\n",
      "Epoch 2621/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1675 - combined_decoder_loss: 0.1672\n",
      "Epoch 2622/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1658 - combined_decoder_loss: 0.1657\n",
      "Epoch 2623/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1663 - combined_decoder_loss: 0.1658\n",
      "Epoch 2624/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1660 - combined_decoder_loss: 0.1664\n",
      "Epoch 2625/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1664 - combined_decoder_loss: 0.1665\n",
      "Epoch 2626/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1675 - combined_decoder_loss: 0.1672\n",
      "Epoch 2627/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1656 - combined_decoder_loss: 0.1657\n",
      "Epoch 2628/3000\n",
      "1190/1190 [==============================] - 1s 828us/sample - loss: 0.1668 - combined_decoder_loss: 0.1671\n",
      "Epoch 2629/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1652 - combined_decoder_loss: 0.1652\n",
      "Epoch 2630/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1672 - combined_decoder_loss: 0.1673\n",
      "Epoch 2631/3000\n",
      "1190/1190 [==============================] - 1s 829us/sample - loss: 0.1650 - combined_decoder_loss: 0.1648\n",
      "Epoch 2632/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.2193 - combined_decoder_loss: 0.2187\n",
      "Epoch 2633/3000\n",
      "1190/1190 [==============================] - 1s 823us/sample - loss: 0.1677 - combined_decoder_loss: 0.1673\n",
      "Epoch 2634/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1649 - combined_decoder_loss: 0.1647\n",
      "Epoch 2635/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1659 - combined_decoder_loss: 0.1656\n",
      "Epoch 2636/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1681 - combined_decoder_loss: 0.1678\n",
      "Epoch 2637/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1668 - combined_decoder_loss: 0.1670\n",
      "Epoch 2638/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1687 - combined_decoder_loss: 0.1689\n",
      "Epoch 2639/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1190/1190 [==============================] - 1s 849us/sample - loss: 0.1669 - combined_decoder_loss: 0.1667\n",
      "Epoch 2640/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1667 - combined_decoder_loss: 0.1667\n",
      "Epoch 2641/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1683 - combined_decoder_loss: 0.1688\n",
      "Epoch 2642/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1709 - combined_decoder_loss: 0.1707\n",
      "Epoch 2643/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1655 - combined_decoder_loss: 0.1656\n",
      "Epoch 2644/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1666 - combined_decoder_loss: 0.1665\n",
      "Epoch 2645/3000\n",
      "1190/1190 [==============================] - 1s 823us/sample - loss: 0.1659 - combined_decoder_loss: 0.1658\n",
      "Epoch 2646/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1706 - combined_decoder_loss: 0.1703\n",
      "Epoch 2647/3000\n",
      "1190/1190 [==============================] - 1s 831us/sample - loss: 0.1651 - combined_decoder_loss: 0.1650\n",
      "Epoch 2648/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1709 - combined_decoder_loss: 0.1706\n",
      "Epoch 2649/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1685 - combined_decoder_loss: 0.1681\n",
      "Epoch 2650/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1776 - combined_decoder_loss: 0.1770\n",
      "Epoch 2651/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1667 - combined_decoder_loss: 0.1667\n",
      "Epoch 2652/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1670 - combined_decoder_loss: 0.1668\n",
      "Epoch 2653/3000\n",
      "1190/1190 [==============================] - 1s 854us/sample - loss: 0.1667 - combined_decoder_loss: 0.1668\n",
      "Epoch 2654/3000\n",
      "1190/1190 [==============================] - 1s 876us/sample - loss: 0.1656 - combined_decoder_loss: 0.1653\n",
      "Epoch 2655/3000\n",
      "1190/1190 [==============================] - 1s 843us/sample - loss: 0.1660 - combined_decoder_loss: 0.1660\n",
      "Epoch 2656/3000\n",
      "1190/1190 [==============================] - 1s 834us/sample - loss: 0.1694 - combined_decoder_loss: 0.1693\n",
      "Epoch 2657/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1677 - combined_decoder_loss: 0.1679\n",
      "Epoch 2658/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1693 - combined_decoder_loss: 0.1693\n",
      "Epoch 2659/3000\n",
      "1190/1190 [==============================] - 1s 836us/sample - loss: 0.1652 - combined_decoder_loss: 0.1656\n",
      "Epoch 2660/3000\n",
      "1190/1190 [==============================] - 1s 831us/sample - loss: 0.1683 - combined_decoder_loss: 0.1682\n",
      "Epoch 2661/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1675 - combined_decoder_loss: 0.1670\n",
      "Epoch 2662/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1658 - combined_decoder_loss: 0.1658\n",
      "Epoch 2663/3000\n",
      "1190/1190 [==============================] - 1s 849us/sample - loss: 0.1680 - combined_decoder_loss: 0.1677\n",
      "Epoch 2664/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1671 - combined_decoder_loss: 0.1669\n",
      "Epoch 2665/3000\n",
      "1190/1190 [==============================] - 1s 848us/sample - loss: 0.1655 - combined_decoder_loss: 0.1653\n",
      "Epoch 2666/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1738 - combined_decoder_loss: 0.1736\n",
      "Epoch 2667/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1681 - combined_decoder_loss: 0.1680\n",
      "Epoch 2668/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1673 - combined_decoder_loss: 0.1677\n",
      "Epoch 2669/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1695 - combined_decoder_loss: 0.1696\n",
      "Epoch 2670/3000\n",
      "1190/1190 [==============================] - 1s 846us/sample - loss: 0.1674 - combined_decoder_loss: 0.1672\n",
      "Epoch 2671/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1671 - combined_decoder_loss: 0.1669\n",
      "Epoch 2672/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1672 - combined_decoder_loss: 0.1671\n",
      "Epoch 2673/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1667 - combined_decoder_loss: 0.1664\n",
      "Epoch 2674/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1717 - combined_decoder_loss: 0.1716\n",
      "Epoch 2675/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1679 - combined_decoder_loss: 0.1682\n",
      "Epoch 2676/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1651 - combined_decoder_loss: 0.1649\n",
      "Epoch 2677/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1674 - combined_decoder_loss: 0.1672\n",
      "Epoch 2678/3000\n",
      "1190/1190 [==============================] - 1s 829us/sample - loss: 0.1705 - combined_decoder_loss: 0.1705\n",
      "Epoch 2679/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1666 - combined_decoder_loss: 0.1665\n",
      "Epoch 2680/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1657 - combined_decoder_loss: 0.1656\n",
      "Epoch 2681/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1649 - combined_decoder_loss: 0.1648\n",
      "Epoch 2682/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1660 - combined_decoder_loss: 0.1663\n",
      "Epoch 2683/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1648 - combined_decoder_loss: 0.1655\n",
      "Epoch 2684/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1697 - combined_decoder_loss: 0.1695\n",
      "Epoch 2685/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1676 - combined_decoder_loss: 0.1677\n",
      "Epoch 2686/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1673 - combined_decoder_loss: 0.1673\n",
      "Epoch 2687/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1648 - combined_decoder_loss: 0.1650\n",
      "Epoch 2688/3000\n",
      "1190/1190 [==============================] - 1s 846us/sample - loss: 0.1657 - combined_decoder_loss: 0.1654\n",
      "Epoch 2689/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.2182 - combined_decoder_loss: 0.2168\n",
      "Epoch 2690/3000\n",
      "1190/1190 [==============================] - 1s 829us/sample - loss: 0.1652 - combined_decoder_loss: 0.1655\n",
      "Epoch 2691/3000\n",
      "1190/1190 [==============================] - 1s 821us/sample - loss: 0.1659 - combined_decoder_loss: 0.1656\n",
      "Epoch 2692/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1671 - combined_decoder_loss: 0.1672\n",
      "Epoch 2693/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1677 - combined_decoder_loss: 0.1674\n",
      "Epoch 2694/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1685 - combined_decoder_loss: 0.1685\n",
      "Epoch 2695/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1654 - combined_decoder_loss: 0.1659\n",
      "Epoch 2696/3000\n",
      "1190/1190 [==============================] - 1s 846us/sample - loss: 0.1661 - combined_decoder_loss: 0.1661\n",
      "Epoch 2697/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.1677 - combined_decoder_loss: 0.1676\n",
      "Epoch 2698/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1663 - combined_decoder_loss: 0.1661\n",
      "Epoch 2699/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1669 - combined_decoder_loss: 0.1665\n",
      "Epoch 2700/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1660 - combined_decoder_loss: 0.1656\n",
      "Epoch 2701/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1656 - combined_decoder_loss: 0.1656\n",
      "Epoch 2702/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1995 - combined_decoder_loss: 0.1987\n",
      "Epoch 2703/3000\n",
      "1190/1190 [==============================] - 1s 836us/sample - loss: 0.1655 - combined_decoder_loss: 0.1651\n",
      "Epoch 2704/3000\n",
      "1190/1190 [==============================] - 1s 831us/sample - loss: 0.1650 - combined_decoder_loss: 0.1645\n",
      "Epoch 2705/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1696 - combined_decoder_loss: 0.1698\n",
      "Epoch 2706/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1669 - combined_decoder_loss: 0.1672\n",
      "Epoch 2707/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1674 - combined_decoder_loss: 0.1671\n",
      "Epoch 2708/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1704 - combined_decoder_loss: 0.1702\n",
      "Epoch 2709/3000\n",
      "1190/1190 [==============================] - 1s 846us/sample - loss: 0.1754 - combined_decoder_loss: 0.1748\n",
      "Epoch 2710/3000\n",
      "1190/1190 [==============================] - 1s 862us/sample - loss: 0.1675 - combined_decoder_loss: 0.1680\n",
      "Epoch 2711/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1697 - combined_decoder_loss: 0.1696\n",
      "Epoch 2712/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1753 - combined_decoder_loss: 0.1753\n",
      "Epoch 2713/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1673 - combined_decoder_loss: 0.1671\n",
      "Epoch 2714/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1677 - combined_decoder_loss: 0.1677\n",
      "Epoch 2715/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1688 - combined_decoder_loss: 0.1685\n",
      "Epoch 2716/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1682 - combined_decoder_loss: 0.1684\n",
      "Epoch 2717/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1683 - combined_decoder_loss: 0.1683\n",
      "Epoch 2718/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1650 - combined_decoder_loss: 0.1646\n",
      "Epoch 2719/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1773 - combined_decoder_loss: 0.1766\n",
      "Epoch 2720/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.1646 - combined_decoder_loss: 0.1643\n",
      "Epoch 2721/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1664 - combined_decoder_loss: 0.1665\n",
      "Epoch 2722/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1674 - combined_decoder_loss: 0.1675\n",
      "Epoch 2723/3000\n",
      "1190/1190 [==============================] - 1s 841us/sample - loss: 0.1694 - combined_decoder_loss: 0.1688\n",
      "Epoch 2724/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1690 - combined_decoder_loss: 0.1689\n",
      "Epoch 2725/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1671 - combined_decoder_loss: 0.1676\n",
      "Epoch 2726/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1658 - combined_decoder_loss: 0.1657\n",
      "Epoch 2727/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1679 - combined_decoder_loss: 0.1675\n",
      "Epoch 2728/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1662 - combined_decoder_loss: 0.1660\n",
      "Epoch 2729/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1642 - combined_decoder_loss: 0.1648\n",
      "Epoch 2730/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1691 - combined_decoder_loss: 0.1687\n",
      "Epoch 2731/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1679 - combined_decoder_loss: 0.1680\n",
      "Epoch 2732/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1739 - combined_decoder_loss: 0.1734\n",
      "Epoch 2733/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1672 - combined_decoder_loss: 0.1671\n",
      "Epoch 2734/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1668 - combined_decoder_loss: 0.1666\n",
      "Epoch 2735/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1713 - combined_decoder_loss: 0.1707\n",
      "Epoch 2736/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1654 - combined_decoder_loss: 0.1655\n",
      "Epoch 2737/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1657 - combined_decoder_loss: 0.1657\n",
      "Epoch 2738/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1692 - combined_decoder_loss: 0.1687\n",
      "Epoch 2739/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1673 - combined_decoder_loss: 0.1678\n",
      "Epoch 2740/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1672 - combined_decoder_loss: 0.1669\n",
      "Epoch 2741/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1685 - combined_decoder_loss: 0.1691\n",
      "Epoch 2742/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.1681 - combined_decoder_loss: 0.1681\n",
      "Epoch 2743/3000\n",
      "1190/1190 [==============================] - 1s 834us/sample - loss: 0.1654 - combined_decoder_loss: 0.1651\n",
      "Epoch 2744/3000\n",
      "1190/1190 [==============================] - 1s 833us/sample - loss: 0.1668 - combined_decoder_loss: 0.1664\n",
      "Epoch 2745/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1676 - combined_decoder_loss: 0.1684\n",
      "Epoch 2746/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1659 - combined_decoder_loss: 0.1660\n",
      "Epoch 2747/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1679 - combined_decoder_loss: 0.1678\n",
      "Epoch 2748/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1733 - combined_decoder_loss: 0.1732\n",
      "Epoch 2749/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1651 - combined_decoder_loss: 0.1654\n",
      "Epoch 2750/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1725 - combined_decoder_loss: 0.1720\n",
      "Epoch 2751/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1678 - combined_decoder_loss: 0.1678\n",
      "Epoch 2752/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1650 - combined_decoder_loss: 0.1654\n",
      "Epoch 2753/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1693 - combined_decoder_loss: 0.1690\n",
      "Epoch 2754/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1661 - combined_decoder_loss: 0.1664\n",
      "Epoch 2755/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1655 - combined_decoder_loss: 0.1652\n",
      "Epoch 2756/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1698 - combined_decoder_loss: 0.1695\n",
      "Epoch 2757/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.1645 - combined_decoder_loss: 0.1643\n",
      "Epoch 2758/3000\n",
      "1190/1190 [==============================] - 1s 831us/sample - loss: 0.1656 - combined_decoder_loss: 0.1656\n",
      "Epoch 2759/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1728 - combined_decoder_loss: 0.1727\n",
      "Epoch 2760/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1778 - combined_decoder_loss: 0.1781\n",
      "Epoch 2761/3000\n",
      "1190/1190 [==============================] - 1s 823us/sample - loss: 0.1652 - combined_decoder_loss: 0.1651\n",
      "Epoch 2762/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1663 - combined_decoder_loss: 0.1660\n",
      "Epoch 2763/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1665 - combined_decoder_loss: 0.1669\n",
      "Epoch 2764/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1663 - combined_decoder_loss: 0.1667\n",
      "Epoch 2765/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1676 - combined_decoder_loss: 0.1673\n",
      "Epoch 2766/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1671 - combined_decoder_loss: 0.1669\n",
      "Epoch 2767/3000\n",
      "1190/1190 [==============================] - 1s 848us/sample - loss: 0.1659 - combined_decoder_loss: 0.1658\n",
      "Epoch 2768/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1668 - combined_decoder_loss: 0.1665\n",
      "Epoch 2769/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1688 - combined_decoder_loss: 0.1688\n",
      "Epoch 2770/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1681 - combined_decoder_loss: 0.1679\n",
      "Epoch 2771/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1655 - combined_decoder_loss: 0.1653\n",
      "Epoch 2772/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1736 - combined_decoder_loss: 0.1734\n",
      "Epoch 2773/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1652 - combined_decoder_loss: 0.1648\n",
      "Epoch 2774/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1659 - combined_decoder_loss: 0.1658\n",
      "Epoch 2775/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1676 - combined_decoder_loss: 0.1692\n",
      "Epoch 2776/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1668 - combined_decoder_loss: 0.1666\n",
      "Epoch 2777/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1693 - combined_decoder_loss: 0.1688\n",
      "Epoch 2778/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1667 - combined_decoder_loss: 0.1668\n",
      "Epoch 2779/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1715 - combined_decoder_loss: 0.1715\n",
      "Epoch 2780/3000\n",
      "1190/1190 [==============================] - 1s 843us/sample - loss: 0.1679 - combined_decoder_loss: 0.1676\n",
      "Epoch 2781/3000\n",
      "1190/1190 [==============================] - 1s 852us/sample - loss: 0.1689 - combined_decoder_loss: 0.1687\n",
      "Epoch 2782/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1746 - combined_decoder_loss: 0.1744\n",
      "Epoch 2783/3000\n",
      "1190/1190 [==============================] - 1s 833us/sample - loss: 0.1650 - combined_decoder_loss: 0.1647\n",
      "Epoch 2784/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1668 - combined_decoder_loss: 0.1664\n",
      "Epoch 2785/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1675 - combined_decoder_loss: 0.1676\n",
      "Epoch 2786/3000\n",
      "1190/1190 [==============================] - 1s 822us/sample - loss: 0.1685 - combined_decoder_loss: 0.1687\n",
      "Epoch 2787/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1660 - combined_decoder_loss: 0.1657\n",
      "Epoch 2788/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1655 - combined_decoder_loss: 0.1664\n",
      "Epoch 2789/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1673 - combined_decoder_loss: 0.1670\n",
      "Epoch 2790/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1703 - combined_decoder_loss: 0.1710\n",
      "Epoch 2791/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1725 - combined_decoder_loss: 0.1721\n",
      "Epoch 2792/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1708 - combined_decoder_loss: 0.1707\n",
      "Epoch 2793/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1669 - combined_decoder_loss: 0.1668\n",
      "Epoch 2794/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1668 - combined_decoder_loss: 0.1668\n",
      "Epoch 2795/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1656 - combined_decoder_loss: 0.1654\n",
      "Epoch 2796/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1669 - combined_decoder_loss: 0.1665\n",
      "Epoch 2797/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1728 - combined_decoder_loss: 0.1724\n",
      "Epoch 2798/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1669 - combined_decoder_loss: 0.1665\n",
      "Epoch 2799/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1689 - combined_decoder_loss: 0.1686\n",
      "Epoch 2800/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1652 - combined_decoder_loss: 0.1652\n",
      "Epoch 2801/3000\n",
      "1190/1190 [==============================] - 1s 831us/sample - loss: 0.1712 - combined_decoder_loss: 0.1712\n",
      "Epoch 2802/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1697 - combined_decoder_loss: 0.1698\n",
      "Epoch 2803/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1643 - combined_decoder_loss: 0.1648\n",
      "Epoch 2804/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1680 - combined_decoder_loss: 0.1680\n",
      "Epoch 2805/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1644 - combined_decoder_loss: 0.1644\n",
      "Epoch 2806/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1651 - combined_decoder_loss: 0.1651\n",
      "Epoch 2807/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1693 - combined_decoder_loss: 0.1698\n",
      "Epoch 2808/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1680 - combined_decoder_loss: 0.1677\n",
      "Epoch 2809/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1670 - combined_decoder_loss: 0.1669\n",
      "Epoch 2810/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1667 - combined_decoder_loss: 0.1667\n",
      "Epoch 2811/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1743 - combined_decoder_loss: 0.1739\n",
      "Epoch 2812/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1668 - combined_decoder_loss: 0.1668\n",
      "Epoch 2813/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1670 - combined_decoder_loss: 0.1670\n",
      "Epoch 2814/3000\n",
      "1190/1190 [==============================] - 1s 831us/sample - loss: 0.1649 - combined_decoder_loss: 0.1645\n",
      "Epoch 2815/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1687 - combined_decoder_loss: 0.1685\n",
      "Epoch 2816/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1839 - combined_decoder_loss: 0.1835\n",
      "Epoch 2817/3000\n",
      "1190/1190 [==============================] - 1s 831us/sample - loss: 0.1675 - combined_decoder_loss: 0.1671\n",
      "Epoch 2818/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1649 - combined_decoder_loss: 0.1650\n",
      "Epoch 2819/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1684 - combined_decoder_loss: 0.1695\n",
      "Epoch 2820/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1641 - combined_decoder_loss: 0.1643\n",
      "Epoch 2821/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1674 - combined_decoder_loss: 0.1675\n",
      "Epoch 2822/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1657 - combined_decoder_loss: 0.1656\n",
      "Epoch 2823/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1662 - combined_decoder_loss: 0.1661\n",
      "Epoch 2824/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1670 - combined_decoder_loss: 0.1667\n",
      "Epoch 2825/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1665 - combined_decoder_loss: 0.1664\n",
      "Epoch 2826/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1642 - combined_decoder_loss: 0.1639\n",
      "Epoch 2827/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1681 - combined_decoder_loss: 0.1677\n",
      "Epoch 2828/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1703 - combined_decoder_loss: 0.1701\n",
      "Epoch 2829/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1655 - combined_decoder_loss: 0.1655\n",
      "Epoch 2830/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1667 - combined_decoder_loss: 0.1674\n",
      "Epoch 2831/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1671 - combined_decoder_loss: 0.1672\n",
      "Epoch 2832/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1652 - combined_decoder_loss: 0.1653\n",
      "Epoch 2833/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1652 - combined_decoder_loss: 0.1649\n",
      "Epoch 2834/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1665 - combined_decoder_loss: 0.1666\n",
      "Epoch 2835/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1758 - combined_decoder_loss: 0.1752\n",
      "Epoch 2836/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1685 - combined_decoder_loss: 0.1688\n",
      "Epoch 2837/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1660 - combined_decoder_loss: 0.1660\n",
      "Epoch 2838/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1659 - combined_decoder_loss: 0.1664\n",
      "Epoch 2839/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1784 - combined_decoder_loss: 0.1786\n",
      "Epoch 2840/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1659 - combined_decoder_loss: 0.1662\n",
      "Epoch 2841/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1670 - combined_decoder_loss: 0.1670\n",
      "Epoch 2842/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1652 - combined_decoder_loss: 0.1651\n",
      "Epoch 2843/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1737 - combined_decoder_loss: 0.1737\n",
      "Epoch 2844/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1653 - combined_decoder_loss: 0.1657\n",
      "Epoch 2845/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1677 - combined_decoder_loss: 0.1682\n",
      "Epoch 2846/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1680 - combined_decoder_loss: 0.1680\n",
      "Epoch 2847/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1682 - combined_decoder_loss: 0.1683\n",
      "Epoch 2848/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1673 - combined_decoder_loss: 0.1667\n",
      "Epoch 2849/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1687 - combined_decoder_loss: 0.1683\n",
      "Epoch 2850/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1674 - combined_decoder_loss: 0.1671\n",
      "Epoch 2851/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1712 - combined_decoder_loss: 0.1709\n",
      "Epoch 2852/3000\n",
      "1190/1190 [==============================] - 1s 834us/sample - loss: 0.1703 - combined_decoder_loss: 0.1701\n",
      "Epoch 2853/3000\n",
      "1190/1190 [==============================] - 1s 833us/sample - loss: 0.1671 - combined_decoder_loss: 0.1680\n",
      "Epoch 2854/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1659 - combined_decoder_loss: 0.1660\n",
      "Epoch 2855/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1690 - combined_decoder_loss: 0.1688\n",
      "Epoch 2856/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1759 - combined_decoder_loss: 0.1756\n",
      "Epoch 2857/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1650 - combined_decoder_loss: 0.1651\n",
      "Epoch 2858/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1644 - combined_decoder_loss: 0.1642\n",
      "Epoch 2859/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1701 - combined_decoder_loss: 0.1701\n",
      "Epoch 2860/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1686 - combined_decoder_loss: 0.1684\n",
      "Epoch 2861/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1686 - combined_decoder_loss: 0.1684\n",
      "Epoch 2862/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1654 - combined_decoder_loss: 0.1657\n",
      "Epoch 2863/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1670 - combined_decoder_loss: 0.1667\n",
      "Epoch 2864/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1729 - combined_decoder_loss: 0.1728\n",
      "Epoch 2865/3000\n",
      "1190/1190 [==============================] - 1s 846us/sample - loss: 0.1669 - combined_decoder_loss: 0.1670\n",
      "Epoch 2866/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1648 - combined_decoder_loss: 0.1648\n",
      "Epoch 2867/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1653 - combined_decoder_loss: 0.1647\n",
      "Epoch 2868/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1680 - combined_decoder_loss: 0.1678\n",
      "Epoch 2869/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.1681 - combined_decoder_loss: 0.1678\n",
      "Epoch 2870/3000\n",
      "1190/1190 [==============================] - 1s 846us/sample - loss: 0.1648 - combined_decoder_loss: 0.1650\n",
      "Epoch 2871/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1655 - combined_decoder_loss: 0.1655\n",
      "Epoch 2872/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1682 - combined_decoder_loss: 0.1695\n",
      "Epoch 2873/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1656 - combined_decoder_loss: 0.1653\n",
      "Epoch 2874/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1656 - combined_decoder_loss: 0.1653\n",
      "Epoch 2875/3000\n",
      "1190/1190 [==============================] - 1s 848us/sample - loss: 0.1656 - combined_decoder_loss: 0.1658\n",
      "Epoch 2876/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1679 - combined_decoder_loss: 0.1676\n",
      "Epoch 2877/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1641 - combined_decoder_loss: 0.1640\n",
      "Epoch 2878/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1649 - combined_decoder_loss: 0.1648\n",
      "Epoch 2879/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1680 - combined_decoder_loss: 0.1682\n",
      "Epoch 2880/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1671 - combined_decoder_loss: 0.1673\n",
      "Epoch 2881/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1661 - combined_decoder_loss: 0.1673\n",
      "Epoch 2882/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1677 - combined_decoder_loss: 0.1675\n",
      "Epoch 2883/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1659 - combined_decoder_loss: 0.1661\n",
      "Epoch 2884/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1644 - combined_decoder_loss: 0.1654\n",
      "Epoch 2885/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1679 - combined_decoder_loss: 0.1679\n",
      "Epoch 2886/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1699 - combined_decoder_loss: 0.1694\n",
      "Epoch 2887/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1667 - combined_decoder_loss: 0.1666\n",
      "Epoch 2888/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1728 - combined_decoder_loss: 0.1725\n",
      "Epoch 2889/3000\n",
      "1190/1190 [==============================] - 1s 846us/sample - loss: 0.1686 - combined_decoder_loss: 0.1684\n",
      "Epoch 2890/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1670 - combined_decoder_loss: 0.1668\n",
      "Epoch 2891/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1664 - combined_decoder_loss: 0.1664\n",
      "Epoch 2892/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1666 - combined_decoder_loss: 0.1668\n",
      "Epoch 2893/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.1681 - combined_decoder_loss: 0.1683\n",
      "Epoch 2894/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1671 - combined_decoder_loss: 0.1672\n",
      "Epoch 2895/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1684 - combined_decoder_loss: 0.1688\n",
      "Epoch 2896/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1776 - combined_decoder_loss: 0.1770\n",
      "Epoch 2897/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1684 - combined_decoder_loss: 0.1683\n",
      "Epoch 2898/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1687 - combined_decoder_loss: 0.1692\n",
      "Epoch 2899/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1678 - combined_decoder_loss: 0.1677\n",
      "Epoch 2900/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1663 - combined_decoder_loss: 0.1664\n",
      "Epoch 2901/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1667 - combined_decoder_loss: 0.1669\n",
      "Epoch 2902/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1655 - combined_decoder_loss: 0.1654\n",
      "Epoch 2903/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1693 - combined_decoder_loss: 0.1695\n",
      "Epoch 2904/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1669 - combined_decoder_loss: 0.1666\n",
      "Epoch 2905/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1735 - combined_decoder_loss: 0.1735\n",
      "Epoch 2906/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1673 - combined_decoder_loss: 0.1677\n",
      "Epoch 2907/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1665 - combined_decoder_loss: 0.1664\n",
      "Epoch 2908/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1653 - combined_decoder_loss: 0.1649\n",
      "Epoch 2909/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1704 - combined_decoder_loss: 0.1701\n",
      "Epoch 2910/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1683 - combined_decoder_loss: 0.1683\n",
      "Epoch 2911/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1678 - combined_decoder_loss: 0.1681\n",
      "Epoch 2912/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1654 - combined_decoder_loss: 0.1654\n",
      "Epoch 2913/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1706 - combined_decoder_loss: 0.1707\n",
      "Epoch 2914/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.1676 - combined_decoder_loss: 0.1676\n",
      "Epoch 2915/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1708 - combined_decoder_loss: 0.1710\n",
      "Epoch 2916/3000\n",
      "1190/1190 [==============================] - 1s 831us/sample - loss: 0.1649 - combined_decoder_loss: 0.1651\n",
      "Epoch 2917/3000\n",
      "1190/1190 [==============================] - 1s 841us/sample - loss: 0.1653 - combined_decoder_loss: 0.1687\n",
      "Epoch 2918/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1652 - combined_decoder_loss: 0.1656\n",
      "Epoch 2919/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1639 - combined_decoder_loss: 0.1636\n",
      "Epoch 2920/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1796 - combined_decoder_loss: 0.1797\n",
      "Epoch 2921/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1642 - combined_decoder_loss: 0.1643\n",
      "Epoch 2922/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1683 - combined_decoder_loss: 0.1683\n",
      "Epoch 2923/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1654 - combined_decoder_loss: 0.1657\n",
      "Epoch 2924/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1685 - combined_decoder_loss: 0.1681\n",
      "Epoch 2925/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1669 - combined_decoder_loss: 0.1667\n",
      "Epoch 2926/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1722 - combined_decoder_loss: 0.1720\n",
      "Epoch 2927/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1656 - combined_decoder_loss: 0.1659\n",
      "Epoch 2928/3000\n",
      "1190/1190 [==============================] - 1s 845us/sample - loss: 0.1653 - combined_decoder_loss: 0.1651\n",
      "Epoch 2929/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1662 - combined_decoder_loss: 0.1659\n",
      "Epoch 2930/3000\n",
      "1190/1190 [==============================] - 1s 822us/sample - loss: 0.1661 - combined_decoder_loss: 0.1660\n",
      "Epoch 2931/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1688 - combined_decoder_loss: 0.1688\n",
      "Epoch 2932/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1752 - combined_decoder_loss: 0.1752\n",
      "Epoch 2933/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1672 - combined_decoder_loss: 0.1676\n",
      "Epoch 2934/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1670 - combined_decoder_loss: 0.1666\n",
      "Epoch 2935/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1710 - combined_decoder_loss: 0.1709\n",
      "Epoch 2936/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1675 - combined_decoder_loss: 0.1674\n",
      "Epoch 2937/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1721 - combined_decoder_loss: 0.1721\n",
      "Epoch 2938/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1644 - combined_decoder_loss: 0.1666\n",
      "Epoch 2939/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1676 - combined_decoder_loss: 0.1674\n",
      "Epoch 2940/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1627 - combined_decoder_loss: 0.1629\n",
      "Epoch 2941/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1686 - combined_decoder_loss: 0.1687\n",
      "Epoch 2942/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1678 - combined_decoder_loss: 0.1699\n",
      "Epoch 2943/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1690 - combined_decoder_loss: 0.1692\n",
      "Epoch 2944/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1680 - combined_decoder_loss: 0.1683\n",
      "Epoch 2945/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1679 - combined_decoder_loss: 0.1677\n",
      "Epoch 2946/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1661 - combined_decoder_loss: 0.1661\n",
      "Epoch 2947/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1659 - combined_decoder_loss: 0.1666\n",
      "Epoch 2948/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1699 - combined_decoder_loss: 0.1693\n",
      "Epoch 2949/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1671 - combined_decoder_loss: 0.1670\n",
      "Epoch 2950/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1686 - combined_decoder_loss: 0.1683\n",
      "Epoch 2951/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1655 - combined_decoder_loss: 0.1652\n",
      "Epoch 2952/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1667 - combined_decoder_loss: 0.1665\n",
      "Epoch 2953/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1656 - combined_decoder_loss: 0.1659\n",
      "Epoch 2954/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1661 - combined_decoder_loss: 0.1658\n",
      "Epoch 2955/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1680 - combined_decoder_loss: 0.1678\n",
      "Epoch 2956/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1649 - combined_decoder_loss: 0.1652\n",
      "Epoch 2957/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1671 - combined_decoder_loss: 0.1672\n",
      "Epoch 2958/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1689 - combined_decoder_loss: 0.1692\n",
      "Epoch 2959/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1664 - combined_decoder_loss: 0.1666\n",
      "Epoch 2960/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1671 - combined_decoder_loss: 0.1675\n",
      "Epoch 2961/3000\n",
      "1190/1190 [==============================] - 1s 843us/sample - loss: 0.1662 - combined_decoder_loss: 0.1665\n",
      "Epoch 2962/3000\n",
      "1190/1190 [==============================] - 1s 833us/sample - loss: 0.1692 - combined_decoder_loss: 0.1691\n",
      "Epoch 2963/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1652 - combined_decoder_loss: 0.1646\n",
      "Epoch 2964/3000\n",
      "1190/1190 [==============================] - 1s 832us/sample - loss: 0.1660 - combined_decoder_loss: 0.1667\n",
      "Epoch 2965/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1684 - combined_decoder_loss: 0.1681\n",
      "Epoch 2966/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1680 - combined_decoder_loss: 0.1686\n",
      "Epoch 2967/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1692 - combined_decoder_loss: 0.1692\n",
      "Epoch 2968/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1653 - combined_decoder_loss: 0.1655\n",
      "Epoch 2969/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1680 - combined_decoder_loss: 0.1681\n",
      "Epoch 2970/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1685 - combined_decoder_loss: 0.1688\n",
      "Epoch 2971/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1659 - combined_decoder_loss: 0.1656\n",
      "Epoch 2972/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1685 - combined_decoder_loss: 0.1737\n",
      "Epoch 2973/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1671 - combined_decoder_loss: 0.1669\n",
      "Epoch 2974/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.2008 - combined_decoder_loss: 0.2000\n",
      "Epoch 2975/3000\n",
      "1190/1190 [==============================] - 1s 813us/sample - loss: 0.1672 - combined_decoder_loss: 0.1671\n",
      "Epoch 2976/3000\n",
      "1190/1190 [==============================] - 1s 822us/sample - loss: 0.1687 - combined_decoder_loss: 0.1687\n",
      "Epoch 2977/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1664 - combined_decoder_loss: 0.1663\n",
      "Epoch 2978/3000\n",
      "1190/1190 [==============================] - 1s 840us/sample - loss: 0.1661 - combined_decoder_loss: 0.1659\n",
      "Epoch 2979/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1669 - combined_decoder_loss: 0.1674\n",
      "Epoch 2980/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1693 - combined_decoder_loss: 0.1689\n",
      "Epoch 2981/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1642 - combined_decoder_loss: 0.1644\n",
      "Epoch 2982/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1675 - combined_decoder_loss: 0.1674\n",
      "Epoch 2983/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1659 - combined_decoder_loss: 0.1655\n",
      "Epoch 2984/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1668 - combined_decoder_loss: 0.1669\n",
      "Epoch 2985/3000\n",
      "1190/1190 [==============================] - 1s 837us/sample - loss: 0.1676 - combined_decoder_loss: 0.1674\n",
      "Epoch 2986/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1664 - combined_decoder_loss: 0.1662\n",
      "Epoch 2987/3000\n",
      "1190/1190 [==============================] - 1s 848us/sample - loss: 0.1740 - combined_decoder_loss: 0.1737\n",
      "Epoch 2988/3000\n",
      "1190/1190 [==============================] - 1s 853us/sample - loss: 0.1646 - combined_decoder_loss: 0.1645\n",
      "Epoch 2989/3000\n",
      "1190/1190 [==============================] - 1s 841us/sample - loss: 0.1660 - combined_decoder_loss: 0.1659\n",
      "Epoch 2990/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1687 - combined_decoder_loss: 0.1685\n",
      "Epoch 2991/3000\n",
      "1190/1190 [==============================] - 1s 857us/sample - loss: 0.1772 - combined_decoder_loss: 0.1773\n",
      "Epoch 2992/3000\n",
      "1190/1190 [==============================] - 1s 849us/sample - loss: 0.1662 - combined_decoder_loss: 0.1663\n",
      "Epoch 2993/3000\n",
      "1190/1190 [==============================] - 1s 854us/sample - loss: 0.1694 - combined_decoder_loss: 0.1692\n",
      "Epoch 2994/3000\n",
      "1190/1190 [==============================] - 1s 853us/sample - loss: 0.1676 - combined_decoder_loss: 0.1676\n",
      "Epoch 2995/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1678 - combined_decoder_loss: 0.1676\n",
      "Epoch 2996/3000\n",
      "1190/1190 [==============================] - 1s 838us/sample - loss: 0.1657 - combined_decoder_loss: 0.1660\n",
      "Epoch 2997/3000\n",
      "1190/1190 [==============================] - 1s 839us/sample - loss: 0.1699 - combined_decoder_loss: 0.1695\n",
      "Epoch 2998/3000\n",
      "1190/1190 [==============================] - 1s 847us/sample - loss: 0.1679 - combined_decoder_loss: 0.1683\n",
      "Epoch 2999/3000\n",
      "1190/1190 [==============================] - 1s 830us/sample - loss: 0.1671 - combined_decoder_loss: 0.1674\n",
      "Epoch 3000/3000\n",
      "1190/1190 [==============================] - 1s 841us/sample - loss: 0.1664 - combined_decoder_loss: 0.1663\n"
     ]
    }
   ],
   "source": [
    "#5/10/300 --> .2613\n",
    "\n",
    "input_dim = x.shape[-1] # 13\n",
    "timesteps = x.shape[1] # 3\n",
    "batch_size = 1\n",
    "\n",
    "vae2, enc2, gen2 = create_lstm_uvae(input_dim, \n",
    "    timesteps=timesteps, \n",
    "    batch_size=batch_size, \n",
    "    intermediate_dim=32,\n",
    "    latent_dim=100,\n",
    "    epsilon_std=1.)\n",
    "\n",
    "\n",
    "vae2.fit(x, x, epochs=3000)\n",
    "\n",
    "preds2 = vae2.predict(x, batch_size=batch_size)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f28ae68c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jameson\\AppData\\Local\\Temp\\ipykernel_14844\\3386344092.py:5: RuntimeWarning: divide by zero encountered in log\n",
      "  predsigs = np.log(pred_logitsigs / (1 - pred_logitsigs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[plotting...]\n",
      "x: (1190, 30, 7), preds: (1190, 30, 7)\n",
      "3\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if type(preds2) is not np.ndarray:\n",
    "    # pick a column to plot.\n",
    "    predvals = preds2[0]\n",
    "    pred_logitsigs = preds2[1] * .5 + .5\n",
    "    predsigs = np.log(pred_logitsigs / (1 - pred_logitsigs))\n",
    "else:\n",
    "    predvals = preds2\n",
    "    predsigs = predvals * 0.\n",
    "    \n",
    "print(\"[plotting...]\")\n",
    "print(\"x: %s, preds: %s\" % (x.shape, predvals.shape))\n",
    "\n",
    "print(len(preds))\n",
    "plot_col = 5\n",
    "plot_step = 5\n",
    "\n",
    "plt.plot(x[:,plot_step,plot_col], label='data', alpha=.4)\n",
    "plt.plot(predvals[:,plot_step,plot_col], label='predict', alpha=.2)\n",
    "plt.plot(predvals[:,plot_step,plot_col] - np.exp(predsigs[:,plot_step,plot_col]), label='pred_low', alpha=.4)\n",
    "plt.plot(predvals[:,plot_step,plot_col] + np.exp(predsigs[:,plot_step,plot_col]), label='pred_hi', alpha=.4)\n",
    "    \n",
    "    \n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "84631a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_encoder.tfsm\\assets\n"
     ]
    }
   ],
   "source": [
    "enc2.save(\"saved_encoder.tfsm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d1c13e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as ort\n",
    "\n",
    "session = ort.InferenceSession(\"saved_encoder.onnx\")\n",
    "enc2 = session.run(None, {\"input\": x.astype(np.float32)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2eb41c9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1190, 100)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc2[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6035e7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = get_data()\n",
    "x2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ac5d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_dim = x2.shape[-1] # 13\n",
    "timesteps = x2.shape[1] # 3\n",
    "batch_size = 1\n",
    "\n",
    "vae, enc, gen = create_lstm_vae(input_dim, \n",
    "    timesteps=timesteps, \n",
    "    batch_size=batch_size, \n",
    "    intermediate_dim=5,\n",
    "    latent_dim=10,\n",
    "    epsilon_std=1.)\n",
    "\n",
    "vae.fit(x2, x2, epochs=200)\n",
    "\n",
    "preds = vae.predict(x2, batch_size=batch_size)\n",
    "\n",
    "# pick a column to plot.\n",
    "print(\"[plotting...]\")\n",
    "print(\"x: %s, preds: %s\" % (x.shape, preds.shape))\n",
    "plt.plot(x[:,0,3], label='data')\n",
    "plt.plot(preds[:,0,3], label='predict')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cde037b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
